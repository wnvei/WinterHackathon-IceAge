{
  "questions": [
    {
      "id": 1,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "What is a computer network?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "A computer network is a set of devices, often called nodes, connected by communication links, facilitating the sharing of resources and exchange of information between interconnected autonomous computers using a single technology."
    },
    {
      "id": 2,
      "module": null,
      "topic": null,
      "question": "What is middleware?",
      "marks": 2,
      "syllabus_status": "OUT_OF_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 3,
      "module": null,
      "topic": null,
      "question": "What is peer-to-peer communication?",
      "marks": 2,
      "syllabus_status": "OUT_OF_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Peer-to-peer communication is not explicitly defined in the provided notes. However, the notes mention \"peer-to-peer sharing\" in the context of internet services available for home applications."
    },
    {
      "id": 4,
      "module": "MODULE-1",
      "topic": "Uses of computer networks",
      "question": "What is VoIP?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "VoIP (Voice over IP) or IP telephony is when telephone calls between employees may be carried by the computer when Internet technology is used, as mentioned in the Business Applications section."
    },
    {
      "id": 5,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Differentiate between unicasting, multicasting, and broadcasting.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 6,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "What is a routing algorithm?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Not supported by notes"
    },
    {
      "id": 7,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "What is a forwarding algorithm?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "A forwarding algorithm is a process within a router that handles each incoming packet, looking up the outgoing line to use for it in the routing table, according to the notes."
    },
    {
      "id": 8,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "What are subnets?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "NOT_FOUND",
      "answer": "Subnets are the individual smaller networks created as a result of subnetting, allowing a network to be split into several parts for internal use but still act like a single network to the outside world; the main router requires a subnet mask indicating the split between network + subnet number and host."
    },
    {
      "id": 9,
      "module": "MODULE-1",
      "topic": "Internetworks",
      "question": "What is gateway?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "A gateway is used in internetwork which is a combination of two or more networks such as LAN, MAN, and WAN, allowing them to function as one system, and it uses routers, gateways, and switches to connect and manage traffic between networks."
    },
    {
      "id": 10,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "What is a protocol?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "A protocol is an agreement between communicating parties on how communication is to proceed; it is the agreed rules layer n communicates with layer n on another machine."
    },
    {
      "id": 11,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "What is routing?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Routing is the main function of the Network Layer, which involves directing packets from the source machine to the destination machine using processes like forwarding (handling packets as they arrive) and routing (updating routing tables). It should have properties like correctness, simplicity, robustness, stability, fairness, and optimality."
    },
    {
      "id": 12,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "What is addressing or naming?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Addressing or naming is a design issue for the layers where every layer needs a mechanism for identifying senders and receivers, and a process on one machine must specify with whom it wants to talk, requiring some form of addressing."
    },
    {
      "id": 13,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "What is flow control?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Flow control manages the rate of traffic received from a sender, preventing buffer overflow by regulating data transmission to match the receiver's capacity, which helps in handling different data rates and efficiently using network resources by avoiding packet loss and reducing retransmissions."
    },
    {
      "id": 14,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "What is congestion?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Congestion occurs when too many packets are present in a part of the network, leading to packet delay and loss, which degrades performance; the network and transport layers share the responsibility for handling congestion. Congestion control aims to prevent network congestion by regulating the rate at which data is sent from the sender to the receiver, promoting efficient use of network resources."
    },
    {
      "id": 15,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "Write any two principles of the OSI model.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The OSI model principles are: a layer should be created where a different abstraction is needed and each layer should perform a well-defined function."
    },
    {
      "id": 16,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "Differentiate between connection-oriented and connectionless services.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Connection-oriented services establish a connection before data transfer, like a telephone system, ensuring ordered delivery, while connectionless services, like the postal system, send each message independently with its full destination address, potentially leading to out-of-order delivery."
    },
    {
      "id": 17,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Differentiate between TCP and UDP.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 4,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "TCP is connection-oriented, provides reliable data transfer with error, flow, and congestion control, while UDP is connectionless, offering an unreliable service without guaranteed delivery. TCP prioritizes accuracy and order, whereas UDP emphasizes speed and low overhead."
    },
    {
      "id": 18,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Differentiate between store-and-forward switching and cut-through switching.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "PARTIAL",
      "answer": "Store-and-forward switching receives the entire packet at each intermediate router before forwarding, while cut-through switching begins forwarding the packet as soon as the destination address is read, without waiting for the entire packet to arrive.  The notes do not mention 'cut-through switching', so this point is not supported."
    },
    {
      "id": 19,
      "module": "MODULE-1",
      "topic": "Service Primitives",
      "question": "What are two service primitives and their meanings?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Two service primitives are LISTEN, which a server executes to indicate it's prepared to accept incoming connections, and CONNECT, which a client process executes to establish a connection with the server."
    },
    {
      "id": 20,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "In the data link layer, what does the sender do with the input data?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "In the data link layer, the sender is responsible for transmitting a set of bits that are meaningful to the receiver, accomplished through framing and addition of physical addresses (MAC addresses) of the sender and/or receiver in the header of each frame."
    },
    {
      "id": 21,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "What are the devices used in the physical layer?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The devices used in the physical layer are Hub, Repeater, Modem, and Cables."
    },
    {
      "id": 22,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "What devices are used in the data link layer?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the notes, switches and bridges are devices used in the data link layer."
    },
    {
      "id": 23,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "Which layer is the router used in?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the notes, the router is used in the Network Layer (Layer 3) of the OSI model."
    },
    {
      "id": 24,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "In the network layer, what is data referred to as?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "In the network layer, data is referred to as a \"packet\". The sender & receiver’s IP addresses are placed in the header by the network layer."
    },
    {
      "id": 25,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Which address is used for data transmission in the datalink layer?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The datalink layer is responsible for node-to-node delivery of messages, ensuring error-free data transfer between nodes using MAC addresses."
    },
    {
      "id": 26,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "The data is transmitted in the network layer using which address?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "The data is transmitted in the network layer using IP addresses for the sender and receiver, which are placed in the header of the packet by the network layer."
    },
    {
      "id": 27,
      "module": "MODULE-5",
      "topic": "The Application Layer",
      "question": "Mention any two protocols used in the application layer.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Two protocols used in the application layer are Simple Mail Transfer Protocol (SMTP) and Hypertext Transfer Protocol (HTTP).  These protocols facilitate the transfer of mail messages and the exchange of files that make up web pages, respectively."
    },
    {
      "id": 28,
      "module": "MODULE-1",
      "topic": "Uses of computer networks",
      "question": "Briefly describe the uses of computer network.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Computer networks have various uses across different domains:\n\n1.  **Business Applications:** Computer networks facilitate resource sharing (printers, databases, large storage), remote access for employees working from home or branch offices, and implement a client-server model where clients request services and servers provide them. They improve communication through email, collaborative editing, and videoconferencing, and enable e-commerce with direct links to suppliers and customers. Networks like VPNs (Virtual Private Networks) join individual networks at different sites into one extended network. IP telephony or Voice over IP (VoIP) is used for telephone calls between employees, and desktop sharing allows remote workers to interact with a graphical computer screen.\n\n2.  **Home Applications:** The primary use is for internet access, providing connectivity to remote computers for information access (e.g., www), person-to-person communication (e.g., chatting), instant messaging (e.g., Twitter), social networking (e.g., Face Book, Whatsup), access to Wikipedia, interactive entertainment (e.g., IPTV), and electronic commerce (e.g., shopping). It enables ubiquitous computing, where computing is embedded into everyday life. Internet services include online shopping, communication improvements with email and chat rooms, peer-to-peer sharing, interactive entertainment with online games and streaming, and learning at home with telelearning.\n\n3.  **Mobile Users:** Mobile computers, such as notebooks and PDAs, connect to offices or homes remotely, enabling users to send and receive calls, faxes, and emails, surf the Web, and access remote files. Wireless networking is used in university campuses, taxis, conferences, and military settings. Everyday smart uses include parking meters, vending machines, and utility meters. Mobile commerce (m-commerce) includes mobile payments and location-based offers, with wearable devices like smartwatches and health monitors also connected.\n\n4.  **Social Issues:** Networks raise issues of content regulation (censorship debates), privacy versus surveillance (government and company tracking), and rights conflicts (employer vs. employee privacy). They also face cybercrime and misuse, including spam, viruses, identity theft, copyright violations, and information quality concerns, alongside security gaps and software vulnerabilities. Future potential lies in telemedicine, telelearning, and everyday smart devices.\n\nIn essence, computer networks enable connectivity and communication across various settings, enhancing productivity, convenience, and access to information and services."
    },
    {
      "id": 29,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Explain the two technical issues in network hardware design.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, the two technical issues in network hardware design are not explicitly detailed. However, the notes do discuss several aspects of network hardware and related design considerations. From the content, we can infer potential design issues based on the limitations and functionalities of network hardware components. Though the notes do not directly address the two technical issues in network hardware design, information related to design consideration is present.\n\n1.  **Network Congestion**: Congestion occurs when too many packets are present in a part of the network, leading to packet delay and loss, degrading performance. Congestion is discussed extensively in Module 2. Congestion can be caused by:\n\t*   Three or four input lines and only one output line, causing a queue buildup.\n\t*   Insufficient memory to hold all packets, leading to packet loss.\n\t*   Slow processors (routers) that cannot process packets quickly enough.\n\t*   Low bandwidth lines.\n\n2.  **Addressing**: Addressing is critical for identifying senders and receivers at every layer. Every layer needs a mechanism for identifying senders and receivers (Module 1). A process on one machine must specify with whom it wants to talk, requiring some form of addressing. The lack of proper addressing schemes or inefficient address allocation can lead to:\n\t*   Routing inefficiencies.\n\t*   Difficulties in managing network traffic.\n\t*   Address exhaustion (especially in IPv4).\n\n3.  **Fragmentation**: Fragmentation is the process of breaking up packets into smaller units for transmission across networks with different MTUs (Maximum Transmission Units). This is described in Module 3. Fragmentation issues include:\n\t*   Overhead due to additional headers on each fragment.\n\t*   Reassembly complexity at intermediate gateways or the destination host.\n\t*   Potential for increased packet loss if any fragment is lost.\n\n4.  **Multiplexing**: Multiplexing allows multiple conversations to share the same connection, which can be crucial for efficient network usage. Module 4 states that multiplexing and demultiplexing should be transparent to the layers above. Issues related to multiplexing can include:\n\t*   Complexity in managing multiple connections on a single link.\n\t*   Potential for interference between different data streams.\n\t*   Fair allocation of bandwidth and resources among multiplexed connections.\n\n5.  **Quality of Service (QoS)**: Ensuring QoS involves managing various parameters such as reliability, delay, jitter, and bandwidth as mentioned in Module 3. Design issues related to QoS can include:\n\t*   Difficulty in guaranteeing consistent performance for different types of traffic.\n\t*   Complexity in implementing traffic shaping and packet scheduling algorithms.\n\t*   Need for resource reservation mechanisms to ensure adequate bandwidth and buffer space.\n\n6.  **Network Scalability**: Ensuring that network hardware can handle increasing numbers of nodes and connections without significant performance degradation. According to Module 3, scalability is a critical consideration for network design. Scalability issues include:\n\t*   Routing table size and complexity.\n\t*   Address management.\n\t*   Bandwidth limitations.\n\n7.  **Switching and Forwarding**: Efficiently moving data packets between network segments. Module 1, slide 27 mentions switching elements. Issues related to switching and forwarding include:\n\t*   Latency in forwarding decisions.\n\t*   Throughput limitations.\n\t*   Scalability of switching infrastructure.\n\n8.  **Buffering and Flow Control**: Managing data flow to prevent a fast sender from overwhelming a slow receiver. Module 4 has more details of the Data Link layer and Transport Layer. Flow control issues include:\n\t*   Buffer overflow and packet loss.\n\t*   Inefficient use of network resources.\n\t*   Complexity in implementing dynamic buffer allocation strategies."
    },
    {
      "id": 30,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Explain the categories of network with suitable diagram and example.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "The notes provide the following categories of networks:\n\n1.  **Local Area Networks (LANs):** Privately-owned networks within a single building or campus, typically spanning a few kilometers. LANs are commonly used to connect personal computers and workstations in offices and factories. Key characteristics include size, transmission technology, and topology. Refer notes for diagram related to bus, ring and star topology.\n\n2.  **Metropolitan Area Networks (MANs):** These networks cover a city, larger than LANs but smaller than WANs. Cable television networks are a primary example. They originated from community antenna systems and evolved to offer two-way Internet services.\n\n3.  **Wide Area Networks (WANs):** Covering large geographical areas like countries or continents, WANs connect hosts via a communication subnet. This subnet includes transmission lines and switching elements, designed for high-latency, large-scale data transfer. Examples include the Internet and global corporate networks.\n\n4.  **Wireless Networks:** These networks transmit data using radio waves, eliminating the need for physical cables. Wireless networks enable mobility and quick expansion. Technologies include Wi-Fi, Bluetooth, and cellular networks. Wi-Fi networks in public hotspots are a common example.\n\n5.  **Home Networks:** Connecting multiple household devices like computers, entertainment systems, and security equipment. Home networks allow devices to communicate and access the Internet, requiring ease of installation, high performance, affordability, and security.\n\n6.  **Internetworks:** These are combinations of two or more networks, such as LANs, MANs, and WANs, functioning as one system. Routers, gateways, and switches manage traffic between the networks, supporting both similar and different network technologies. A global corporate network connected via the Internet is an example."
    },
    {
      "id": 31,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Differentiate between LAN, WAN, and MAN.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here's a differentiation between LAN, WAN, and MAN:\n\n1.  **LAN (Local Area Network):**\n    *   Privately-owned networks. Confined to a single building or campus.\n    *   Size: Restricted to a few kilometers.\n    *   Used to connect personal computers and workstations in offices and factories.\n    *   Employ a transmission technology consisting of a cable where all machines are attached. Broadcast LANs utilize various topologies.\n    *   Example: Ethernet (IEEE 802.3), IBM token ring (IEEE 802.5).\n\n2.  **MAN (Metropolitan Area Network):**\n    *   Covers a city.\n    *   Size: Larger than a LAN but smaller than a WAN.\n    *   Example: Cable television networks in many cities.\n    *   Originated from community antenna systems, evolved to offer specialized channels and two-way Internet service.\n\n3.  **WAN (Wide Area Network):**\n    *   Covers a large geographical area, such as a country or continent.\n    *   Hosts are connected by a communication subnet.\n    *   The subnet includes transmission lines and switching elements.\n    *   Transmission lines move bits between machines.\n    *   Switching elements are specialized computers connecting three or more transmission lines.\n    *   Designed for high-latency, large-scale data transfer.\n    *   Examples: Internet, global corporate networks."
    },
    {
      "id": 32,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "List and explain the categories of network hardware classification based on scale.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, the classification of network hardware based on scale can be categorized as follows:\n\n1.  **Local Area Networks (LANs):** These are privately-owned networks typically within a single building or campus, spanning a few kilometers. LANs are used to connect personal computers and workstations in offices and factories.\n\n2.  **Metropolitan Area Networks (MANs):** MANs cover a city, being larger than LANs but smaller than Wide Area Networks (WANs). Cable television networks in cities are examples of MANs, evolving from community antenna systems to offering specialized channels and two-way Internet service.\n\n3.  **Wide Area Networks (WANs):** WANs cover large geographical areas, often countries or continents. In WANs, hosts are connected by a communication subnet comprising transmission lines and switching elements. Transmission lines move bits, while switching elements are specialized computers connecting three or more transmission lines. The Internet and global corporate networks are examples.\n\n4.  **Wireless Networks:** These networks transmit data using radio waves instead of cables. Wireless networks enable mobility and quick expansion without new cabling. Technologies include Wi-Fi, Bluetooth, and cellular networks. They are used in airports, offices, and public hotspots.\n\n5.  **Home Networks:** Home networks connect multiple household devices, such as computers, entertainment systems, appliances, and security equipment. These networks allow devices to communicate and access the Internet from anywhere in the home. They must be easy to install, operate, and offer high performance for multimedia.\n\n6.  **Internetworks:** An internetwork combines two or more networks (LAN, MAN, and WAN), allowing them to function as one system. Routers, gateways, and switches connect and manage traffic between these networks, supporting seamless integration of similar and different technologies. Corporate offices connected via the Internet for collaboration are an example."
    },
    {
      "id": 33,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "Write a note on i) Internetworking ii) Protocol Hierarchy.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "```\n{\n\"i) Internetworking\": \"Internetworking is the combination of two or more networks such as LAN, MAN, and WAN, allowing them to function as one system. It facilitates communication and resource sharing between devices on different networks. Routers, gateways, and switches are used to connect and manage traffic between these networks. It supports both similar and different network technologies for seamless integration and can be private (intranet) or public (Internet) for global access. An example is corporate offices worldwide connected via the Internet for collaboration.\",\n\"ii) Protocol Hierarchy\": \"Modern network software is structured as a stack of layers, each built upon the one below it. Each layer offers services to higher layers, hiding implementation details and acting like a virtual machine. Layer n communicates with layer n on another machine using agreed rules called the layer n protocol. This is an agreement between the communicating parties on how communication is to proceed. The entities in corresponding layers on different machines are called peers. Each layer passes data and control information to the layer immediately below it until the lowest layer is reached, with the physical medium below layer 1 enabling actual communication. Between each pair of adjacent layers is an interface defining primitive operations and services available to the upper layer. A set of layers and protocols is called a network architecture, with a protocol stack listing protocols used by a system, one per layer.\"\n}\n```"
    },
    {
      "id": 34,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "List and explain the design issues in network software design.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here are some design issues in network software design, primarily focusing on the layers of network architecture:\n\n1.  **Addressing:** Every layer requires a mechanism to identify senders and receivers. A process on one machine needs to specify whom it wants to communicate with, which necessitates some form of addressing. This is crucial for directing data to the correct destination.\n\n2.  **Data Transfer Rules:** Protocols dictate the directionality of data flow. Some systems allow data transfer only in one direction (simplex), while others support two-way communication (duplex). The protocol must determine the number of logical channels a connection has and their priorities.\n\n3.  **Error Control:** Physical communication circuits are prone to imperfections, making error detection and correction essential. Error-detecting or error-correcting codes are needed. Both ends of the connection must agree on the specific error control method used.\n\n4.  **Sequencing:** Not all channels guarantee the preservation of message order. Protocols must manage the proper reassembly of messages. Numbering message pieces aids in sequencing, but handling out-of-order arrivals is still required.\n\n5.  **Flow Control:** Prevents a fast sender from overwhelming a slow receiver with data. Solutions include feedback from the receiver to the sender or limiting the sender’s transmission rate.\n\n6.  **Message Size Handling:** Protocols must define how long messages are handled. Long messages must be disassembled, transmitted, and reassembled. Small messages can be combined into a single larger one for efficiency.\n\n7.  **Multiplexing:** Addresses how the same connection may carry multiple unrelated conversations. Multiplexing and demultiplexing should be transparent to the layers above.\n\n8.  **Routing:** When multiple paths exist between source and destination, a route must be selected. Routing decisions can be split between high-level policy and low-level traffic-based choices.\n\n9.  **Channel Priorities:** Many networks provide separate channels for normal and urgent data. This allows urgent information to be transmitted without waiting for normal data.\n\n10. **Connection-Oriented vs. Connectionless Services:** Layers can offer either connection-oriented or connectionless services. Connection-oriented services (like the telephone system) involve establishing a connection, using it, and then releasing it. Connectionless services (like the postal system) treat each message independently, with each carrying the full destination address."
    },
    {
      "id": 35,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "Differentiate between connection-oriented and connectionless service.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here is a differentiation between connection-oriented and connectionless services:\n\n1.  **Connection-Oriented Service**: It operates in three phases: connection establishment, data transfer, and connection release, similar to a telephone system.\n2.  A connection setup may include negotiation on parameters like maximum message size or quality of service.\n3.  It acts like a tube, where bits go in at one end and come out at the other, usually in order.\n4.  **Connectionless Service**: It functions like the postal system, where each message carries the full destination address and is routed independently.\n5.  Messages usually arrive in order, but delays can cause out-of-order delivery.\n6.  Quality of service can vary; reliable services never lose data, using acknowledgements for confirmation.\n7.  Reliable services introduce overhead and delay, but are often worth it; sometimes, however, delays are undesirable.\n8.  Acknowledged datagram service provides connectionless transmission but with delivery confirmation (like registered mail with return receipt).\n9.  A request-reply service sends one datagram as a request and receives a reply with the answer.\n10. Connection-oriented service is more reliable than connectionless service."
    },
    {
      "id": 36,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "Explain the service primitives with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Service primitives are operations or functions available to application programs, enabling them to access the transport service. Refer to notes for a diagram related to connection establishment(Figure 7-6). Here's an explanation of how they work:\n\n1.  **LISTEN:** The server executes LISTEN to indicate its readiness to accept incoming connections. The server process remains blocked until a connection request arrives.\n\n2.  **CONNECT:** The client process executes CONNECT to establish a connection with the server, specifying the target to connect to.\n\n3.  Upon receiving a connection request packet, the system verifies the presence of a listener. It unblocks the listener and sends back an acknowledgment. This acknowledgment, in turn, releases the client.\n\n4.  **RECEIVE:** The server executes RECEIVE to prepare for accepting the initial request. Subsequently, the client uses SEND to transmit its request, followed by executing RECEIVE to obtain the reply.\n\n5.  **DISCONNECT:** The client uses DISCONNECT to terminate the connection. Upon receiving this packet, the server also issues a DISCONNECT of its own, acknowledging the client and releasing the connection.\n\nThe process involves the transport layer providing operations to application programs, that is, a transport service interface. Each transport service has its own interface.\n\nIn the transport layer, initial connection establishment is more complicated.A transport protocol element must explicitly specify the destination address, since multiple processes or applications may be communicating.\n\nThere are two styles of terminating a connection: asymmetric release and symmetric release. Asymmetric release is the way the telephone system works: when one party hangs up, the connection is broken. Symmetric release treats the connection as two separate unidirectional connections and requires each one to be released separately.\n\nAfter establishing a connection, the next important task is managing the data flow between the sender and receiver. This involves flow control and buffering — ensuring that data is sent at a rate that the receiver can handle without being overwhelmed.\n\nAfter establishing a connection, the next important task is managing the data flow between the sender and receiver. This involves flow control and buffering — ensuring that data is sent at a rate that the receiver can handle without being overwhelmed.\n\nMultiplexing means sharing one connection or link among multiple conversations.It helps different processes or applications use the same network interface efficiently."
    },
    {
      "id": 37,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "Explain the OSI reference model with a neat diagram, detailing the functions of each layer.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The OSI (Open Systems Interconnection) reference model is a conceptual framework developed by the International Standards Organization (ISO) for understanding and standardizing how different network devices and applications communicate with each other. It divides the communication process into seven distinct layers, each with specific functions and responsibilities. Refer notes for diagram. The OSI model helps in designing, implementing, and troubleshooting network systems. Here's a breakdown of each layer:\n\n1.  **Physical Layer (Layer 1):** This layer deals with the physical connection between devices. It is responsible for transmitting raw bits over a communication channel. Functions include: bit synchronization, bit rate control, physical topologies, and transmission mode (simplex, half-duplex, full-duplex). Devices at this layer include hubs, repeaters, modems, and cables. The physical layer converts data into signals suitable for the transmission medium and vice versa.\n\n2.  **Data Link Layer (Layer 2):** This layer provides node-to-node delivery of messages, ensuring error-free transmission over the physical layer. Key functions include framing, physical addressing (MAC addresses), error control (detecting and retransmitting damaged/lost frames), flow control, and access control. Switches and bridges operate at this layer. Data is transmitted in frames, and the layer encapsulates sender and receiver MAC addresses in the header.\n\n3.  **Network Layer (Layer 3):** The network layer is responsible for transmitting data packets from one host to another across different networks. It handles packet routing and logical addressing (IP addresses). The sender and receiver IP addresses are added to the packet header. Key functions include routing and logical addressing. Routers and some switches operate at this layer. Data units at this layer are called packets.\n\n4.  **Transport Layer (Layer 4):** This layer provides end-to-end delivery of the complete message, offering services to the application layer and taking services from the network layer. It ensures reliable data transmission, acknowledging successful data delivery and retransmitting data if errors occur. Functions include segmentation and reassembly, and service point addressing (port numbers). Protocols such as TCP and UDP operate at this layer. Data units are called segments. It is considered the \"Heart of the OSI model.\"\n\n5.  **Session Layer (Layer 5):** This layer is responsible for establishing, maintaining, and terminating connections (sessions) between applications. It handles authentication and security. Key functions include session establishment, maintenance and termination, synchronization, and dialog control. Protocols used include Point-to-Point Tunneling Protocol (PPTP).\n\n6.  **Presentation Layer (Layer 6):** This layer is also known as the translation layer. It ensures that data is in a usable format for different systems by handling translation, encryption/decryption, and compression. Functions include translation (e.g., ASCII to EBCDIC), encryption/decryption, and compression. FTP (File Transfer Protocol) can be associated with this layer.\n\n7.  **Application Layer (Layer 7):** This is the layer closest to the end-user. It provides network services to applications, allowing them to access the network and display received information. Functions include network virtual terminal, file transfer access and management (FTAM), mail services, and directory services. Protocols include SMTP (Simple Mail Transfer Protocol). It serves as a window for applications to access network services."
    },
    {
      "id": 38,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "Explain the TCP/IP reference model with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The TCP/IP reference model is based on standard protocols and was designed and developed by the Department of Defense (DoD) in the 1960s. It is short for Transmission Control Protocol/Internet Protocol. The main goal of TCP/IP is to transfer data reliably and accurately from one computer to another. To ensure data integrity, the TCP/IP model divides data into packets and reassembles them at the destination.\n\nThe TCP/IP model consists of four layers:\n\n1.  **Network Interface Layer:**\n *   Defines how data is physically sent through the network. It manages the electrical or optical signaling of bits via hardware devices.\n *   Responsible for placing and receiving TCP/IP packets on and off the network medium.\n *   Connects different network types like LAN technologies.\n *   Protocols included are Ethernet, Token Ring, FDDI (Fiber Distributed Data Interface), and Frame Relay.\n\n2.  **Internet Layer:**\n *   Allows hosts to inject packets into any network, enabling them to travel independently to the destination.\n *   Defines the official packet format and protocol known as IP (Internet Protocol).\n *   Responsible for addressing, packaging, and routing functions.\n *   Core protocols include IP, ARP, ICMP, and IGMP.\n    *   **IP (Internet Protocol):** A routable protocol responsible for IP addressing, routing, and packet fragmentation and reassembly.\n    *   **ARP (Address Resolution Protocol):** Resolves Internet layer addresses to Network Interface layer addresses (e.g., hardware addresses).\n    *   **ICMP (Internet Control Message Protocol):** Provides diagnostic functions and error reporting for unsuccessful IP packet delivery.\n    *   **IGMP (Internet Group Management Protocol):** Manages IP multicast groups.\n\n3.  **Transport Layer:**\n *   Allows peer entities on source and destination hosts to carry on a conversation.\n *   Uses protocols like TCP (Transmission Control Protocol) and UDP (User Datagram Protocol).\n    *   **TCP:** A reliable, connection-oriented protocol that ensures byte streams are delivered without error. It fragments the byte stream into discrete messages and passes them to the Internet layer. The receiving TCP process reassembles these messages.\n    *   **UDP:** An unreliable, connectionless protocol for applications.\n\n4.  **Application Layer:**\n *   Provides applications the ability to access the services of other layers.\n *   Includes protocols for user information exchange, such as HTTP (Hypertext Transfer Protocol) for web pages, FTP (File Transfer Protocol) for file transfer, SMTP (Simple Mail Transfer Protocol) for email, and Telnet for remote login.\n *   Also includes protocols like DNS (Domain Name System) for resolving hostnames to IP addresses, RIP (Routing Information Protocol) for exchanging routing information, and SNMP (Simple Network Management Protocol) for monitoring and managing network devices.\n\nRefer notes for diagram. The TCP/IP reference model diagram should illustrate a layered architecture with four distinct layers: Network Interface, Internet, Transport, and Application. Each layer should be depicted with its primary functions and associated protocols. Arrows should show the flow of data between layers, emphasizing the encapsulation and de-encapsulation process as data moves up and down the protocol stack."
    },
    {
      "id": 39,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "Differentiate between the OSI reference model and the TCP/IP model.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "The provided notes do not explicitly present a direct comparison in a table format. However, based on the information available throughout the notes, the key differences can be summarized as follows:\n\n1.  **Layers:** The OSI model has seven layers (Application, Presentation, Session, Transport, Network, Data Link, and Physical), while the TCP/IP model has four layers (Application, Transport, Internet, and Network Interface).\n\n2.  **Model Focus:** The OSI model serves as a theoretical reference model outlining how communication should occur. The TCP/IP model is a practical model, widely implemented in the Internet.\n\n3.  **Protocol Usage:** The notes mention that while the OSI model's protocols are not widely used, the model itself remains valuable for understanding network concepts. Conversely, the TCP/IP model's protocols are extensively used, but the model itself is less emphasized.\n\n4.  **Development Origin:** The OSI model was developed by the International Organization for Standardization (ISO). The TCP/IP model was developed by the Department of Defense (DoD) in the 1960s.\n\n5.  **Addressing:** Both models address the need for identifying senders and receivers. The OSI model provides addressing at each of its seven layers. The TCP/IP model focuses on addressing primarily at the Internet layer (IP addresses) and the Transport layer (ports).\n\n6.  **Connection Orientation:** Both models support connection-oriented and connectionless services. TCP provides a connection-oriented service, ensuring reliable data delivery, whereas UDP offers a connectionless service, prioritizing speed over reliability.\n\n7.  **Error Control:** Both models incorporate error control mechanisms. The OSI model addresses error control at multiple layers. TCP provides robust error detection and correction mechanisms, including checksums and retransmissions.\n\n8.  **Flow Control:** Both models implement flow control to prevent a fast sender from overwhelming a slow receiver. TCP uses a sliding window protocol to manage data flow, ensuring reliable transmission.\n\n9.  **Congestion Control:** TCP includes congestion control mechanisms to manage network congestion by adjusting the transmission rate based on network conditions. The notes discuss congestion control algorithms applicable to both virtual-circuit and datagram subnets, as well as general principles of congestion control.\n\n10. **Reliability:** TCP is designed to provide reliable, ordered, and error-checked delivery of a stream of bytes between applications running on hosts communicating via an IP network. UDP, on the other hand, provides a low-overhead, connectionless service with no guarantee of reliability or order."
    },
    {
      "id": 40,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "What is the difference between routing and forwarding?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Routing is responsible for updating the routing tables, while forwarding handles each packet as it arrives, looking up the outgoing line to use for it in the routing table."
    },
    {
      "id": 41,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "What are the two classes of routing algorithms?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The two classes of routing algorithms are distance vector routing and link state routing, as mentioned in module 2."
    },
    {
      "id": 42,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Define nonadaptive and adaptive algorithms.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 43,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Name any two algorithms for static routing and dynamic routing.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the notes, algorithms for static routing and dynamic routing are not explicitly named. However, the notes mention \"Shortest Path Routing\" and \"Flooding\" algorithms in the context of routing algorithms, which could be considered examples of static and dynamic routing respectively, but it is not explicitly stated."
    },
    {
      "id": 44,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Describe the optimality principle.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The optimality principle states that if router J is on the optimal path from router I to router K, then the optimal path from J to K also falls along the same route, and it implies that the set of optimal routes from all sources to a given destination form a sink tree rooted at the destination."
    },
    {
      "id": 45,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Write the link state packet for node G for the below graph.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Not supported by notes"
    },
    {
      "id": 46,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "What is the count to infinity problem?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The count-to-infinity problem arises in distance vector routing, where bad news (like a link failure) spreads slowly through the network, causing routers to incorrectly believe that a destination is reachable, and gradually increase the distance metric until it reaches infinity. This slow convergence can create routing loops and delays."
    },
    {
      "id": 47,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "What is the definition of congestion in a network?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Congestion in a network occurs when too many packets are present in a part of the network, leading to packet delay and loss which degrades performance; it is primarily handled by the network layer, but also influenced by the transport layer."
    },
    {
      "id": 48,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Solve the following to find the shortest path from A to D using Dijkstra’s algorithm, where any graph can be given.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "I am unable to provide a solution to find the shortest path from A to D using Dijkstra’s algorithm, as the provided notes do not contain a graph or specific instructions on how to apply Dijkstra's algorithm in this context. However, the notes do provide a general overview of Dijkstra's algorithm, also known as the Shortest Path Routing algorithm, found in \"module 2.pptx\".\n\nKey aspects of Shortest Path Routing (Dijkstra’s algorithm) based on the notes:\n\n1.  **Optimality:** The algorithm aims to find the least-cost path, using dynamic programming for optimization.\n2.  **Graph Representation:** A graph represents the subnet, where nodes are routers and arcs are communication links.\n3.  **Algorithm Steps:**\n    *   Start with the local node as the root, assigning a cost of 0 and making it permanent.\n    *   Examine each neighbor of the last permanent node.\n    *   Assign a cumulative cost to each neighbor, marking them as tentative.\n    *   Select the tentative node with the smallest cost and make it permanent.\n    *   If a node can be reached via multiple routes, choose the route with the shortest cumulative cost.\n    *   Repeat until all nodes are permanent.\n4.  **Dijkstra’s Routing Algorithm Pseudocode:**\n    *   **Initialization:**\n        *   N = {A} (A is the root node)\n        *   For all nodes v:\n            *   If v is adjacent to A, then D(v) = c(A, v)\n            *   Else D(v) = infinity\n    *   **Loop:**\n        *   Find w not in N such that D(w) is a minimum.\n        *   Add w to N.\n        *   Update D(v) for all v adjacent to w and not in N:\n            *   D(v) = min(D(v), D(w) + c(w, v))\n        *   Until all nodes are in N.\n\nWhere:\n*   N is the set of visited nodes (starts with the initial node).\n*   D(v) is the current shortest distance from the starting node to node v.\n*   c(w, v) is the cost (or distance) between nodes w and v.\n\nSince a specific graph is not provided, these steps describe the general method. Refer to the notes for a visual representation or diagram of network topologies."
    },
    {
      "id": 49,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Explain any two static algorithms (nonadaptive).",
      "marks": 10,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "PARTIAL",
      "answer": "Two static (nonadaptive) routing algorithms are Flooding and Shortest Path Routing.\n\n1.  **Flooding:** This algorithm sends every incoming packet out on every outgoing line, except the one it arrived on. This generates a vast number of duplicate packets unless measures are taken to damp the process. One measure is a hop counter in the packet header, decremented at each hop, with the packet discarded when the counter reaches zero. Ideally, the hop counter is initialized to the path length from source to destination. A variation is selective flooding, where routers send packets only on lines going approximately in the right direction. Each router remembers the packets it has already sent to discard duplicates, achieved by the source router putting a sequence number in the packet.\n\n    *   **Advantages:**\n        *   Desirable in military applications where routers are destroyed.\n        *   Useful for concurrently updating all databases in distributed database applications.\n        *   Serves as a metric against which other routing algorithms are compared.\n        *   Chooses the shortest path by exploring all possible paths in parallel.\n\n2.  **Shortest Path Routing:** This algorithm builds a graph of the subnet, where each node represents a router and each arc represents a communication line or link. To choose a route between a pair of routers, the algorithm finds the shortest path between them on the graph. Dijkstra’s algorithm is commonly used to implement shortest path routing. The algorithm operates as follows:\n    1.  Start with the local node (router) as the root of the tree. Assign a cost of 0 to this node and make it the first permanent node.\n    2.  Examine each neighbor of the node that was the last permanent node.\n    3.  Assign a cumulative cost to each node and make it tentative.\n    4.  Among the list of tentative nodes:\n        *   Find the node with the smallest cost and make it permanent.\n        *   If a node can be reached from more than one route, then select the route with the shortest cumulative cost.\n    5.  Repeat steps 2 to 4 until every node becomes permanent."
    },
    {
      "id": 50,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Explain Link State Routing in detail.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Link State Routing is a routing algorithm that addresses the slow convergence time often associated with other algorithms when network topology changes. The core idea behind link-state routing involves these key steps:\n\n1.  **Neighbor Discovery:** Routers begin by discovering their immediate neighbors and learning their network addresses. This is usually achieved by sending 'HELLO' packets on each point-to-point line, with neighboring routers expected to reply with their names.\n\n2.  **Cost Metric Setting:** A distance or cost metric is assigned to each link to a neighbor. This cost can be set automatically or manually by a network operator. The cost is often inversely proportional to the link's bandwidth. In geographically spread networks, link delay may also be factored into the cost.\n\n3.  **Link State Packet Construction:** Each router constructs a link-state packet (LSP) containing its identity, a sequence number, age, and a list of its neighbors along with the cost to reach each neighbor.\n\n4.  **LSP Distribution:** These link-state packets are distributed to all other routers in the network through flooding. To manage the flooding, each packet includes a sequence number incremented for each new packet sent. Routers track all (source router, sequence) pairs. When a new LSP arrives, it's checked against seen packets. If new, it's forwarded on all lines except the arrival line. Duplicates are discarded, and packets with sequence numbers lower than the highest seen are rejected.\n\n5.  **Route Computation:** After accumulating a complete set of link-state packets, a router can construct a full network graph. Since every link is represented, Dijkstra’s algorithm is then run locally to compute the shortest paths to all possible destinations.\n\nFurther considerations to keep the flooding in check include:\n\n*   **Packet Aging:** Each packet includes an age field, which is decremented periodically. When the age hits zero, the information from that router is discarded. This ensures old information does not persist indefinitely.\n*   **OSPF Protocol:** OSPF (Open Shortest Path First) is a common link-state protocol, refer to the notes for further information on this protocol.\n\nIn summary, link-state routing allows each router to build a complete map of the network, enabling it to make informed routing decisions based on shortest paths."
    },
    {
      "id": 51,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Explain the dynamic programming algorithm used in Bellman-Ford routing.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "PARTIAL",
      "answer": "Based on the provided notes, the dynamic programming algorithm used in Bellman-Ford routing is not explicitly detailed. However, the notes do discuss other routing algorithms, including Distance Vector Routing, which is closely related to the Bellman-Ford algorithm.\n\nDistance Vector Routing:\n\n1.  **Distributed Bellman-Ford:** Distance vector routing is also referred to as the distributed Bellman-Ford routing algorithm.\n2.  **Routing Table Maintenance:** Each router maintains a routing table. The table is indexed by, and contains one entry for, every other router in the network.\n3.  **Entry Components:** Each entry in the routing table includes two parts: the preferred outgoing line to use for a destination and an estimate of the distance to that destination.\n4.  **Neighbor Awareness:** Each router knows the distance to each of its neighbors. The distance metric could be hops, queue length, or delay, which the router measures directly using ECHO packets.\n5.  **Information Sharing:** Routers share their routing tables with their direct neighbors.\n6.  **Count-to-Infinity Problem:** A significant challenge is the \"count-to-infinity\" problem, where bad news (e.g., a link failure) propagates slowly through the network, potentially causing routing loops.\n7.  **Convergence Time:** One of the main problems with Distance Vector Routing is that it often takes too long to converge after the network topology changes.\n\nAlthough the notes mention Dijkstra’s algorithm, primarily used in Link State Routing, it does not provide a direct explanation of how dynamic programming is used in Bellman-Ford. The distance vector routing description is the closest available concept, relying on iterative updates to determine shortest paths. Split horizon and poisoned reverse are mentioned as attempts to mitigate the count-to-infinity problem."
    },
    {
      "id": 52,
      "module": "MODULE-5",
      "topic": "Write a program to find the shortest path between vertices using the bellman -ford algorithm B",
      "question": "Write the Bellman-Ford Algorithm and explain the algorithm with an example.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 53,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "Explain the different approaches to control congestion.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Congestion control aims to prevent or alleviate network congestion, a state where excessive traffic leads to packet delay and loss, degrading performance. Approaches to congestion control include:\n\n1.  **Open-Loop Congestion Control:** Policies applied to prevent congestion before it occurs. Handled either by the source or the destination. Includes policies like:\n\t*   **Retransmission Policy:** Managing retransmission of lost or corrupted packets. Timers must be designed to prevent further congestion while optimizing efficiency.\n\t*   **Window Policy:** Selective Repeat window is preferred to Go-back-N, as it avoids resending correctly received packets, thus reducing congestion.\n\t*   **Discarding Policy:** Routers may discard corrupted or less sensitive packets to prevent congestion.\n\t*   **Acknowledgment Policy:** Receivers should acknowledge N packets instead of single packets and send acknowledgments only when needed or when a timer expires.\n\t*   **Admission Policy:** Switches should check resource requirements before establishing virtual network connections, denying connections if congestion is likely.\n\n2.  **Closed-Loop Congestion Control:** Techniques used to alleviate congestion after it happens. Includes:\n\t*   **Backpressure:** A congested node stops receiving packets from upstream nodes, propagating congestion backward.\n\t*   **Implicit Signaling:** The source infers congestion based on indications like lack of acknowledgments.\n\t*   **Explicit Signaling:** Congested nodes explicitly send signals to sources or destinations.\n\t\t-   **Forward Signaling:** A signal is sent in the direction of the congestion to warn the destination.\n\t\t-   **Backward Signaling:** A signal is sent in the opposite direction of the congestion to warn the source to slow down.\n\n3.  **Congestion Control in Virtual Circuit Subnets:**\n\t*   **Admission Control:** Avoiding setting up more virtual connections once congestion occurs.\n\t*   **Alternate Approach:** Adding new connections to nodes other than congested nodes.\n\n4.  **Congestion Control in Datagram Subnets:**\n\t*   **Warning Bit:** A bit in the packet header is set by the router to warn the source when congestion is detected. The bit is copied and piggy-backed on the ACK and sent to the sender.\n\t*   **Choke Packet:** A packet sent by a node to the source to inform about congestion, prompting the source to reduce its transmission rate. An example of a choke packet is the ICMP Source Quench Packet.\n\t*   **Hop-by-Hop Choke Packets:** Choke packets are sent hop-by-hop, requiring each hop to reduce its transmission even before the choke packet arrives at the source.\n\n5.  **Load Shedding:** Discarding packets when the buffer is full. Packets with less importance or old packets are often discarded.\n\n6.  **Random Early Detection (RED):** Packets are discarded before the buffer space becomes full. The router maintains a specific queue length for the outgoing lines, and when this average set line is exceeded, it warns for congestion and discards packets.\n\n7.  **Jitter Control:** Jitter is an inconsistent delay in data packets. Jitter can be bounded by computing the expected transit time for each hop along the path. Routers check whether packets are ahead or behind schedule and adjust their transmission accordingly. Buffering at the receiver can also eliminate jitter, although this may not be acceptable for real-time applications."
    },
    {
      "id": 54,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "Write a note on Load Shedding and Jitter.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Load Shedding:\n\n1.  Load shedding is a congestion control technique used when a network is congested, where the buffer is full, packets are discarded.\n2.  The decision of which packets to discard is crucial. Packets of lower importance or older packets are generally discarded.\n3.  To implement an intelligent discard policy, applications can mark packets to indicate their importance. Routers can then discard packets from the least important class first, followed by the next least important class, and so on.\n4.  Random Early Detection (RED) is a technique where packets are discarded *before* the buffer becomes full, controlling congestion earlier.\n5.  With RED, the router maintains a specific queue length for outgoing lines. When this average queue length is exceeded, it warns of congestion and starts discarding packets.\n\nJitter Control:\n\n1.  Jitter is defined as an inconsistent delay in the arrival of data packets.\n2.  Jitter arises due to network congestion, inadequate hardware, or lack of packet prioritization, causing uneven intervals between packets.\n3.  Jitter control aims to bound this delay by estimating the expected transit time for each hop along the path.\n4.  When a packet arrives at a router, the router checks whether the packet is ahead or behind schedule.\n5.  If the packet is early, the router holds it.\n6.  If the packet is late, the router sends it as quickly as possible.\n7.  The algorithm for managing packets vying for an output line can prioritize packets that are furthest behind schedule.\n8.  Packets ahead of schedule are slowed down, while those behind schedule are expedited, thus reducing jitter.\n9.  Buffering can eliminate jitter at the receiver in applications like video on demand by fetching data from the buffer instead of the network in real-time.\n10. However, buffering is less suitable for real-time interactive applications like Internet telephony and video conferencing due to the inherent delay."
    },
    {
      "id": 55,
      "module": "MODULE-2",
      "topic": "Flooding",
      "question": "Explain flooding with its advantages.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Flooding is a routing algorithm where every incoming packet is sent out on every outgoing line except the one it arrived on. This generates vast numbers of duplicate packets. To mitigate this, a hop counter is included in the header of each packet, which is decremented at each hop. When the counter reaches zero, the packet is discarded. Selective flooding is a variation where routers send incoming packets only on lines going approximately in the right direction. Each router remembers packets it has already sent; duplicate copies are discarded.\n\nAdvantages of flooding:\n\n1.  **Military Applications:** Useful in scenarios where large numbers of routers are destroyed.\n2.  **Distributed Databases:** Useful for updating all databases concurrently.\n3.  **Benchmark Metric:** Used as a benchmark to compare other routing algorithms.\n4.  **Shortest Path Selection:** Chooses the shortest path because it explores all possible paths in parallel."
    },
    {
      "id": 56,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Discuss the drawbacks of the distance vector algorithm and how these can be resolved.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here's a discussion of the drawbacks of the distance vector algorithm and potential resolutions:\n\n1.  **Count-to-Infinity Problem:** The notes mention the \"Count-to-Infinity problem\" in distance vector routing. This occurs when a route fails (e.g., a router goes down), and the bad news spreads slowly through the network. Routers may incorrectly believe a destination is reachable through their neighbors, leading to routing loops and increasing distance metrics until they reach infinity, before the route is correctly identified as unreachable. Split horizon and poisoned reverse are mentioned as attempts to mitigate, but not completely solve, this issue.\n\n2.  **Slow Convergence:** One of the primary drawbacks of distance vector routing, as stated in the notes, is that it often takes too long to converge after the network topology changes. This slow convergence is what the Link State Routing tries to solve.\n\n3.  **Hierarchical Routing:** Hierarchical routing is introduced to combat the large number of entries required in routing tables for large networks. In distance vector routing, without hierarchy, each router would need an entry for every other router in the network. The count-to-infinity problem could be viewed as a result of the flat addressing, that this approach solves.\n\n4.  **Link State Routing:** The notes suggest using link-state routing as an alternative to distance vector routing to resolve the slow convergence issues. Link state routing involves:\n\n    *   Discovering neighbors and learning their network addresses.\n    *   Setting the distance/cost metric to each neighbor.\n    *   Constructing and distributing packets containing learned information to all other routers (via flooding).\n    *   Computing the shortest path to every other router (using Dijkstra's algorithm).\n\n5.  **Flooding:** While flooding is mentioned as a component of link-state routing for distributing link state packets, the notes also describe plain flooding, in which every incoming packet is sent out on every outgoing line except the one it arrived on. This generates vast numbers of duplicate packets unless measures are taken to damp the process, such as a hop counter.\n\n6.  **Sequence Numbers and Packet Tracking:** The notes suggest each router remembers the identity of those packets it has already sent out to discard duplicate copies. This is achieved by the source router putting a sequence number in the packet.\n\n7.  **Aging Packets:** Include the age of each packet after the sequence number and decrement it once per second. When the age hits zero, the information from that router is discarded. The Age field is also decremented by each router during the initial flooding process, to make sure no packet can get lost and live for an indefinite period of time.\n\n8.  **Hierarchical Routing:** In cases where the network grows too large, hierarchical routing can be used. Routers are divided into regions, and each router knows all the details about routing packets to destinations within its own region but knows nothing about the internal structure of other regions.\n\n9.  **Autonomous Systems (AS):** Each network in an internetwork is independent of all the others and is often referred to as an Autonomous System (AS).\n\n10. **OSPF (Open Shortest Path First):** OSPF is mentioned as an alternative link-state protocol. A key aspect of this routing protocol is to be able to route real-time traffic one way and other traffic a different way."
    },
    {
      "id": 57,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Explain hierarchical routing in network.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Hierarchical routing is a routing algorithm designed to improve the efficiency and scalability of routing in large networks. In hierarchical routing, routers are organized into a hierarchy of regions, clusters, zones, and groups. Each router knows the details of routing packets to destinations within its own region but has no knowledge of the internal structure of other regions. For very large networks, a two-level hierarchy may not be sufficient, thus requiring the grouping of regions into clusters, clusters into zones, and so on. \n\nThe primary motivation for hierarchical routing is to reduce the size of routing tables. In a large network, it is impractical for every router to maintain an entry for every other router. This is where hierarchical routing becomes essential, as it helps to manage the routing information efficiently.\n\nConsider a subnet with 720 routers. Without hierarchy, each router would require 720 entries. The total number of entries would be 720 x 720. However, with hierarchy, if the subnet is partitioned into 24 regions with 30 routers per region, each router only needs 30 + 23 = 53 entries. This significantly reduces the routing table size and complexity.\n\nIn OSPF (Open Shortest Path First), which supports hierarchical systems, an area is defined as a network or a set of contiguous networks. Every Autonomous System (AS) has a backbone area, called area 0. All areas are connected to the backbone, possibly by tunnels.\n\nOSPF distinguishes four classes of routers:\n\n1.  Internal routers: These are wholly within one area.\n2.  Area border routers: These connect two or more areas.\n3.  Backbone routers: These are on the backbone.\n4.  AS boundary routers: These talk to routers in other ASes."
    },
    {
      "id": 58,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "Explain the congestion control in virtual circuit subnets and datagram subnets.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Congestion control mechanisms differ between virtual-circuit subnets and datagram subnets.\n\n**Congestion Control in Virtual-Circuit Subnets:**\n\n1.  **Admission Control:** A primary technique in virtual-circuit subnets involves admission control. After congestion occurs in the network, no new virtual connections are established until the congestion is resolved. This prevents further exacerbation of the congested state. An alternative approach involves routing new connections through nodes that are not experiencing congestion.\n\n**Congestion Control in Datagram Subnets:**\n\n1.  **Warning Bit:** Routers set a special bit in the packet header to warn the source when congestion is detected. This bit is then copied and piggybacked onto the ACK (acknowledgment) packet, which is sent back to the sender. The sender monitors the number of ACK packets received with the warning bit set and adjusts its transmission rate accordingly.\n2.  **Choke Packets:** A choke packet is a packet sent by a congested node to the source, directly informing it to reduce its traffic flow. This serves as a more direct signal for the source to slow down. The source, upon receiving the choke packet, must decrease its transmission rate by a specific percentage. An example of a choke packet is the ICMP Source Quench Packet.\n3.  **Hop-by-Hop Choke Packets:** For long distances or high-speed networks, simple choke packets might not be effective enough. A more efficient method involves sending choke packets hop-by-hop. This requires each intermediate hop to reduce its transmission rate even before the choke packet arrives at the source.\n"
    },
    {
      "id": 59,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "Explain the congestion prevention policies.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Congestion prevention policies, also known as open-loop congestion control, aim to prevent congestion before it occurs. These policies are typically handled by the source or destination.\n\n1.  **Retransmission Policy:** This policy manages packet retransmissions. If the sender suspects a packet is lost or corrupted, it retransmits the packet. However, excessive retransmission can exacerbate congestion. Retransmission timers must be carefully designed to prevent congestion while maintaining efficiency.\n2.  **Window Policy:** The sender's window policy can impact congestion. Go-back-N window policies re-send multiple packets, even if some were successfully received, increasing congestion. Selective repeat windows, which only re-send lost packets, are preferable.\n3.  **Discarding Policy:** Routers can implement discarding policies to prevent congestion. They may discard corrupted or less sensitive packets to maintain message quality and reduce congestion.\n4.  **Acknowledgment Policy:** Instead of acknowledging each packet individually, the receiver can send acknowledgments for N packets at once. Also, the receiver sends an acknowledgment only when it has data to send or when a timer expires.\n5.  **Admission Policy:** Switches should evaluate the resource requirements of a network flow before allowing it to proceed. If there's a risk of congestion, the router should deny establishing a virtual network connection to prevent further congestion.\n\nThese open-loop techniques aim to proactively manage network traffic to avoid congestion before it starts. Note that these policies work to PREVENT, not control congestion AFTER it happens."
    },
    {
      "id": 60,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "Define quality of service in networking.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Quality of Service (QoS) is determined by reliability, delay, jitter, and bandwidth requirements of a flow of packets from a source to a destination, and determines the needed capacity is available."
    },
    {
      "id": 61,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "What are the primary parameters that define the Quality of Service (QoS)?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The primary parameters that define the Quality of Service (QoS) are reliability, delay, jitter, and bandwidth; these parameters together determine the QoS a flow requires."
    },
    {
      "id": 62,
      "module": "MODULE-3",
      "topic": "Tunneling",
      "question": "What is tunneling?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Tunneling is a technique used to make different networks interwork, especially when the source and destination hosts are on the same type of network with a different network in between; it encapsulates an IP packet within another network layer packet to traverse an intermediate network."
    },
    {
      "id": 63,
      "module": "MODULE-3",
      "topic": "Internetworking",
      "question": "What is an Autonomous System in internetworking?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "An Autonomous System (AS) is a network within an internetwork that is independent of all the others, managed by different organizations using their own internal routing methods; it is also a collection of interconnected networks."
    },
    {
      "id": 64,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "What is Internet Protocol (IP)?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Internet Protocol (IP) defines an official packet format and protocol, responsible for IP addressing, routing, and the fragmentation and reassembly of packets, enabling hosts to inject packets into any network and have them travel independently to the destination."
    },
    {
      "id": 65,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "What is the address length of IPv4?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the notes provided, the IPv4 address length is 32 bits or 4 bytes."
    },
    {
      "id": 66,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "What is the address length of IPv6?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "IPv6 addresses are 16 bytes long."
    },
    {
      "id": 67,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "Calculate the number of hosts that can be connected to the network 198.162.8.1/25.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "The provided notes do not contain information on how to calculate the number of hosts that can be connected to a network given its IP address and subnet mask; therefore, the question cannot be answered."
    },
    {
      "id": 68,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "List and explain the techniques for achieving good Quality of Service.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The notes describe several techniques for achieving good Quality of Service (QoS):\n\n1.  **Overprovisioning:** This involves providing ample router capacity, buffer space, and bandwidth to facilitate smooth packet flow. While effective, it can be an expensive solution.\n2.  **Buffering:** Flows can be buffered on the receiving side before delivery. Buffering smooths out jitter by holding packets and releasing them at uniform intervals. Refer to the notes for a diagram illustrating how buffering mitigates jitter by delaying playback until sufficient packets are buffered, addressing issues caused by delayed packets. Commercial websites use buffering for about 10 seconds before streaming.\n3.  **Traffic Shaping:** This method smooths traffic before it enters the network, regulating the average rate and burstiness of data transmission. It is used in ATM and Integrated Services networks. Traffic policing monitors traffic flow. Two traffic shaping algorithms are mentioned:\n\t*   **Leaky Bucket:** This algorithm enforces a constant output rate, regardless of the input burstiness. It is implemented as a single-server queue with constant service time. Packets are discarded if the bucket overflows. Refer to notes for a diagram.\n\t*   **Token Bucket:** This algorithm allows the output rate to vary, depending on the size of the burst. To transmit a packet, the host must capture and destroy a token. Idle hosts can save tokens to send larger bursts later. Refer to notes for a diagram. It discards tokens, not packets, and packets can be transmitted if enough tokens are available.\n4.  **Resource Reservation:** This involves reserving resources along a specific route for a flow to ensure the needed capacity is available. Resources that can be reserved include bandwidth, buffer space, and CPU cycles.\n5.  **Admission Control:** When a flow is offered to a router, the router decides whether to admit or reject the flow based on its capacity and existing commitments. Flows are described using specific parameters in a flow specification.\n6. **Packet Scheduling:** Packet scheduling includes fair queueing algorithms, wherein routers have separate queues for each output line, one for each flow. When a line becomes idle, the router scans the queues round robin, taking the first packet on the next queue. In this way, with n hosts competing for a given output line, each host gets to send one out of every n packets."
    },
    {
      "id": 69,
      "module": "MODULE-3",
      "topic": "Traffic Shaping",
      "question": "Describe traffic shaping with algorithms.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Traffic shaping regulates the average rate and burstiness of data transmission, often used in ATM and Integrated Services networks. The sender and carrier negotiate a traffic pattern at connection set-up. Monitoring this traffic flow is called traffic policing. Two common traffic shaping algorithms are the Leaky Bucket and the Token Bucket.\n\n1.  **Leaky Bucket (LB) Algorithm**: Enforces a constant output rate regardless of the input's burstiness. Implemented as a single-server queue with a constant service time.  Packets exceeding the bucket's capacity are discarded.  This algorithm smooths out bursts, reducing congestion by injecting one packet per clock tick or allowing a fixed number of bytes per tick, which is beneficial for variable-length packets.\n\n2.  **Token Bucket (TB) Algorithm**:  Allows the output rate to vary depending on burst size. The bucket holds tokens, and to transmit a packet, the host must capture and destroy one token. Tokens are generated at a rate of one every Δt seconds.  Idle hosts can save up tokens to send larger bursts later, up to the bucket's maximum size.\n\n**Key Differences:**\n\n*   **Packet Handling**: LB discards packets when the bucket overflows, whereas TB discards tokens.\n*   **Output Rate**: LB sends packets at an average rate; TB allows for large bursts by speeding up the output.\n*   **Saving**: TB allows saving up tokens to send large bursts, while LB does not."
    },
    {
      "id": 70,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "Differentiate between leaky bucket and token bucket algorithms.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 6,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "The leaky bucket and token bucket algorithms are both traffic shaping mechanisms used to regulate the rate of data transmission, but they differ in how they achieve this:\n\n1.  **Packet Handling:** Leaky Bucket (LB) discards packets if the bucket (buffer) overflows, while Token Bucket (TB) does not discard packets but rather discards tokens.\n2.  **Transmission Condition:** With TB, a packet can only be transmitted if there are enough tokens to cover its length in bytes.\n3.  **Output Rate:** LB sends packets at an average rate, enforcing a constant output rate regardless of the burstiness of the input. TB allows for large bursts to be sent faster by speeding up the output, provided there are enough tokens.\n4.  **Saving Permissions:** TB allows saving up tokens (permissions) to send large bursts. LB does not allow saving, maintaining a consistent outflow.\n5.  **Input Idleness:** Leaky bucket algorithm does nothing when the input is idle. Token bucket can capture and save up tokens during idle periods (up to the maximum size of the bucket) in order to send larger bursts later.\n6. **Conceptual Model**: The Leaky Bucket Algorithm is visualized as a bucket with a small hole at the bottom, ensuring outflow at a constant rate. The Token Bucket Algorithm, holds tokens, where to transmit a packet, the host must capture and destroy one token. Tokens are generated by a clock at a specific rate.\n7. The purpose of traffic shaping is to smooth out the traffic on the server side, rather than on the client side.\n8. Traffic policing is performed by monitoring a traffic flow.\n9. For variable length packets it is better to allow a fixed number of bytes per tick, instead of one packet per tick."
    },
    {
      "id": 71,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "Explain why packet scheduling is required and describe the different strategies for packet scheduling.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "Packet scheduling is required to manage the order in which packets are transmitted, ensuring efficient and fair use of network resources, and to meet the Quality of Service (QoS) requirements of different flows. Different flows have varying needs in terms of reliability, delay, jitter, and bandwidth. Packet scheduling algorithms are used to prioritize and manage these diverse requirements.\n\nDifferent strategies for packet scheduling include:\n\n1.  **Fair Queueing Algorithm:** This algorithm aims to provide fair access to the network for all flows. Routers have separate queues for each output line, one for each flow. When a line becomes idle, the router scans the queues in a round-robin fashion, taking the first packet from each queue. This ensures that with *n* hosts competing for an output line, each host gets to send one out of every *n* packets. Refer notes for diagram illustrating fair queueing algorithm.\n\n2.  **Traffic Shaping:** Traffic shaping smooths out traffic before it enters the network, regulating the average rate and burstiness of data transmission. This technique is used in ATM and Integrated Services networks. Two common traffic shaping algorithms are:\n\n    *   **Leaky Bucket:** This algorithm enforces a constant output rate, regardless of the burstiness of the input. It is implemented as a single-server queue with a constant service time. If the bucket (buffer) overflows, packets are discarded. A host injects one packet per clock tick onto the network, resulting in a uniform flow of packets. For variable-length packets, a fixed number of bytes per tick is allowed.\n    *   **Token Bucket:** This algorithm allows the output rate to vary, depending on the size of the burst. The bucket holds tokens, and to transmit a packet, the host must capture and destroy one token. Tokens are generated by a clock at a certain rate. Idle hosts can save up tokens to send larger bursts later.\n\n3.  **Proportional Routing:** This strategy splits the traffic for each destination over multiple paths, either equally or in proportion to the capacity of the outgoing links, to provide a higher quality of service.\n\n4.  **Buffering:** Flows can be buffered on the receiving side before being delivered. Buffering does not affect reliability or bandwidth but increases the delay and smooths out jitter.\n\n5.  **Admission Control:** When a flow is offered to a router, the router decides whether to admit or reject the flow based on its capacity and commitments to other flows. Flows are described using specific parameters in a flow specification to enable negotiation."
    },
    {
      "id": 72,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "Explain the function of RSVP or Flow based algorithm.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "RSVP (Resource reSerVation Protocol) is a signaling protocol designed by the IETF (Internet Engineering Task Force) to support Quality of Service (QoS) in IP networks. It facilitates the reservation of resources, such as bandwidth, along a communication path. Here's a detailed explanation of its function:\n\n1.  **Purpose:** RSVP is designed to enable the reservation of network resources for specific data flows, ensuring that these flows receive a guaranteed level of service.\n2.  **Operation Over Multicast Routing:** RSVP primarily operates over multicast routing, assigning a group address to each multicast group and sending packets along a spanning tree that connects all members.\n3.  **Control Messages:** Unlike normal multicast, RSVP sends extra control messages to routers, allowing them to maintain the data structures necessary for QoS reservations.\n4.  **Receiver-Oriented Reservations:** Any receiver in a multicast group can send a reservation message toward the sender to request improved reception and avoid congestion. This message travels up the spanning tree using the reverse path forwarding algorithm.\n5.  **Bandwidth Reservation:** Each router along the path reserves the required bandwidth specified in the reservation message. If all routers can reserve the necessary bandwidth, an end-to-end reservation is established. If not, the receiver is informed of the failure.\n6.  **Multiple Senders and Receivers:** RSVP efficiently manages communication between multiple senders and receivers, avoiding network congestion by reserving bandwidth along the paths.\n7.  **Dynamic Group Membership:** RSVP accommodates dynamic group memberships, where users can join or leave a group (like a video conference) in real-time.\n8.  **Shared Paths:** Routers use information from receivers to plan bandwidth efficiently. Shared paths are created only if all receivers agree not to change sources later.\n9.  **Dynamic Source Switching:** In dynamic scenarios, reserved bandwidth is independent of the source, allowing receivers to switch between sources (like different video streams) without requiring a new reservation.\n10. **Heterogeneous Bandwidth Requirements:** The capacity reserved must be large enough to satisfy the greediest receiver, accommodating different bandwidth requirements among receivers (e.g., black-and-white vs. color television).\n11. **Multicast Trees:** Refer to the notes for diagrams illustrating multicast trees for different hosts in a network, showcasing how RSVP manages reservations across these trees.\n12. **Flow-Based Algorithm:** While the context primarily discusses RSVP, it emphasizes that the core function is to manage resources based on \"flows\" or streams of packets from a source to a destination, ensuring guaranteed QoS by reserving bandwidth and managing packet delivery along the path. This flow-based approach helps avoid network congestion and ensures consistent service delivery."
    },
    {
      "id": 73,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "Write a note on Differentiated Services.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Differentiated Services (DiffServ) is not explicitly mentioned in the provided notes. However, the notes do allude to concepts related to prioritizing network traffic and quality of service (QoS), which are fundamental to understanding DiffServ.\n\nBased on the notes, here is the available information relevant to differentiated services:\n\n1.  **Quality of Service (QoS) Requirements:** The notes mention that a flow (a stream of packets from source to destination) can be characterized by reliability, delay, jitter, and bandwidth. These parameters collectively determine the QoS a flow requires (module 3, slide 3).\n2.  **Traffic Shaping:** The notes discuss traffic shaping as a method to smooth out traffic before it enters the network, regulating the average rate and burstiness of data transmission. The leaky bucket and token bucket algorithms are described as traffic shaping techniques (module 3, slides 6-12).\n3.  **Packet Scheduling:** The fair queueing algorithm is mentioned, where routers have separate queues for each output line, one for each flow, ensuring each host gets a fair share of the bandwidth (module 3, slide 16).\n4.  **Admission Control:** Routers decide whether to admit or reject a flow based on their capacity and existing commitments, described using flow specifications (module 3, slide 14).\n5.  **Proportional Routing:** Traffic for each destination can be split over multiple paths, either equally or in proportion to the capacity of the outgoing links (module 3, slide 15).\n6.  **Service Type Field in IPv4:** The IPv4 header includes a service type field, which defines how a datagram should be handled, including bits that define the priority of the datagram and the type of service desired (module 3, slide 51).\n7.  **Traffic Class Field in IPv6:** IPv6 has a traffic class field used to distinguish between packets with different real-time delivery requirements (module 3, slide 95).\n\nWhile these concepts align with the principles of differentiated services (prioritizing and managing network traffic based on different service levels), the term \"Differentiated Services\" or \"DiffServ\" is not directly used in the provided notes."
    },
    {
      "id": 74,
      "module": "MODULE-3",
      "topic": "Internetworking",
      "question": "Write a note on i) tunneling ii) fragmentation.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "{\n \"i) Tunneling\": \"Tunneling is a technique used to make two different networks interwork, especially when the source and destination hosts are on the same type of network but with a different network in between. In tunneling, to send a packet (e.g., an IP packet) to a destination host, the source host constructs the packet, inserts it into a frame (e.g., an Ethernet frame) addressed to a multiprotocol router. The multiprotocol router removes the original packet, inserts it into the payload field of the intermediate network layer packet (e.g., a WAN network layer packet), and addresses this new packet to another multiprotocol router at the destination network. The destination router then removes the original packet and sends it to the destination host inside a frame of the destination network type.\",\n \"ii) Fragmentation\": \"Fragmentation refers to breaking up packets into smaller units called fragments, sending each fragment as a separate internet packet. There are two main strategies for fragmentation: transparent fragmentation and nontransparent fragmentation.\\n  a) Transparent Fragmentation: In transparent fragmentation, gateways interfacing with a small-packet network break oversized packets into fragments. Each fragment is addressed to the same exit gateway, where the fragments are recombined. Subsequent networks are unaware that fragmentation occurred. Problems include the need for a count field or an 'end of packet' bit, all packets must exit via the same gateway, and overhead is incurred by repeated reassembly and refragmentation when passing through multiple small-packet networks.\\n b) Nontransparent Fragmentation: In nontransparent fragmentation, fragments are not recombined at intermediate gateways. Each fragment is treated as an original packet, and recombination occurs only at the destination host. This requires every host to be able to perform reassembly. While it increases overhead due to each fragment needing a header, multiple exit gateways can be used, potentially achieving higher performance.\"\n}"
    },
    {
      "id": 75,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "List and explain the principles of the network layer in the Internet.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The notes outline several principles of the network layer in the Internet:\n\n1.  **Ensure Functionality:** Emphasize practical validation by ensuring multiple prototypes can communicate successfully before finalizing designs.\n2.  **Maintain Simplicity:** Prioritize simple solutions. When faced with multiple options, choose the most straightforward approach.\n3.  **Make Clear Choices:** Select one method when multiple ways exist to accomplish the same task to avoid potential conflicts.\n4.  **Exploit Modularity:** Implement a protocol stack where each layer operates independently to allow changes to one module without affecting others.\n5.  **Expect Heterogeneity:** Design the network to accommodate diverse hardware, transmission facilities, and applications through simplicity, generality, and flexibility.\n6.  **Avoid Static Options:** Negotiate parameters (e.g., maximum packet size) between sender and receiver rather than using fixed values.\n7.  **Prioritize Good Design:** Favor a well-designed system over accommodating edge cases that could compromise the overall architecture, shifting the burden to those with specialized requirements.\n8.  **Be Strict When Sending and Tolerant When Receiving:** Send packets that strictly adhere to standards and be flexible when receiving packets.\n9.  **Think About Scalability:** Design the system to efficiently handle millions of hosts and billions of users by avoiding centralized databases and evenly distributing load.\n10. **Consider Performance and Cost:** Ensure the network provides good performance at a reasonable cost to encourage its adoption and use."
    },
    {
      "id": 76,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "Describe the structure of an IPv4 header and explain all of its fields.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the notes, here is a description of the structure of an IPv4 header and its fields:\n\n1.  **Structure:** An IP datagram consists of a header and a text (data) part. The header has a 20-byte fixed part and a variable-length optional part.\n\n2.  **Version:** This 4-bit field indicates the IP version number. For IPv4, the value is 4 (binary 0100).\n\n3.  **Header Length (HLEN):** This 4-bit field specifies the length of the header in multiples of 4 bytes. The value ranges from 0 to 15, allowing a maximum header size of 60 bytes (15 * 4).\n\n4.  **Service Type:**  This field (renamed as Differentiated Services Code Point (DSCP) and Explicit Congestion Notification (ECN) in later versions) defines how the datagram should be handled, including its priority. It contains bits specifying the type of service desired, such as throughput, reliability, and delay preferences. It includes 3 bits for precedence (priority levels 0-7) and D, T, R flags for Delay, Throughput, and Reliability preferences.\n\n5.  **Total Length:** This 16-bit field defines the total length of the IP datagram, including the header and data, in bytes. The maximum size of an IP datagram is 65,535 bytes.\n\n6.  **Identification:** This field is used for fragmentation. When a datagram is fragmented, all fragments share the same identification number, allowing them to be reassembled at the destination.\n\n7.  **Flags:** This 3-bit field controls fragmentation. Key flags include:\n\n    *   **DF (Don’t Fragment):** Prevents routers from fragmenting the packet.\n    *   **MF (More Fragments):** Indicates that the datagram is not the last fragment.\n\n8.  **Fragmentation Offset:** This 13-bit field indicates the offset of the fragment’s data within the original datagram, measured in units of 8 bytes. It helps in reassembling the fragments in the correct order.\n\n9.  **Time to Live (TTL):** This 8-bit field specifies the maximum number of hops a datagram can travel before being discarded. Each router decrements the TTL by 1. If the TTL reaches 0, the datagram is discarded to prevent routing loops.\n\n10. **Protocol:** This 8-bit field indicates the upper-layer protocol encapsulated in the datagram (e.g., TCP, UDP, ICMP).\n\n11. **Header Checksum:** This 16-bit field is used to detect errors in the header. It is calculated and verified by each router.\n\n12. **Source Address:** This 32-bit field contains the IP address of the sender.\n\n13. **Destination Address:** This 32-bit field contains the IP address of the intended recipient.\n\n14. **Options:** This variable-length field provides additional functionality, including options for routing control, timing, management, and timestamping. The presence and size of this field are accounted for by the HLEN field.\n\nNote: Refer to notes for diagram of IPv4 header"
    },
    {
      "id": 77,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "Explain the classful addressing with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "I am unable to create a diagram, so please refer to the notes for a visual representation of classful addressing. Classful addressing is a historic IP addressing architecture where the IP address space is divided into five fixed classes (A, B, C, D, and E) based on the first few bits of the address. This system, though simple, led to inefficient use of IP addresses and was later replaced by Classless Inter-Domain Routing (CIDR).\n\nKey aspects of classful addressing:\n\n1.  **Address Classes:** The IPv4 address space is divided into five classes: A, B, C, D, and E. Only classes A, B, and C are used for unicast addressing. Class D is for multicast, and Class E is reserved for future use.\n2.  **Address Format:** The first few bits of an IP address determine its class:\n *   Class A: 0 (0.0.0.0 to 127.255.255.255)\n *   Class B: 10 (128.0.0.0 to 191.255.255.255)\n *   Class C: 110 (192.0.0.0 to 223.255.255.255)\n3.  **Network and Host IDs:** Each class defines a default division between the network ID (NID) and host ID (HID):\n *   Class A: NID is the first octet, and HID is the last three octets, allowing for 128 networks with up to 16 million hosts each.\n *   Class B: NID is the first two octets, and HID is the last two octets, allowing for 16,384 networks with up to 64K hosts each.\n *   Class C: NID is the first three octets, and HID is the last octet, allowing for 2 million networks with up to 256 hosts each.\n4.  **Subnetting:** To manage the hosts effectively within an organization, subnetting can be used. Subnetting involves dividing a large network into smaller, more manageable parts (subnets).\n5.  **Inefficiency:** The primary problem with classful addressing is the inefficient use of IP addresses. For example, an organization needing 500 hosts would be assigned a Class B address (supporting 64,000 hosts), leading to a significant waste of unused addresses. This inefficiency led to the development of CIDR. Each class has a number of networks and hosts it can accomodate.\n6.  **ICANN Management:** Network numbers are managed by ICANN to avoid conflicts, ICANN has delegated parts of the address space to various regional authorities, which then dole out IP addresses to ISPs and other companies."
    },
    {
      "id": 78,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "Describe subnet addressing with an example.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Subnet addressing involves dividing a larger network into smaller, more manageable subnetworks (subnets). This is done for several reasons, including improved network organization, enhanced security, and better utilization of IP addresses. \n\n1.  **Concept**: It reduces the total number of network-numbers by assigning a single network-number to many adjacent physical networks. Each adjacent physical network is referred to as subnet.\n\n2.  **Subnet Mask**: To implement subnetting, the main router needs a subnet mask that indicates the split between network + subnet number and host.\n\n3.  **Address Identification**: All nodes on a subnet are configured with a subnet mask. The bitwise AND of IP address and its subnet mask gives the subnet number. The subnet-addressing scheme is hidden to the network outside the organization.\n\n4.  **Address Allocation**:  Inside the organization the network-administrator is free to choose any combination of lengths for the subnet & host ID fields. \n\n5.  **Notation**: Subnet masks are also written in dotted decimal notation, with the addition of a slash followed by the number of bits in the network + subnet part.  An alternative notation is /22 to indicate that the subnet mask is 22 bits long.\n\n6.  **Purpose**: As the network grows, it is allowed a network to be split into several parts for internal use but still act like a single network to the outside world. In the Internet literature, the parts of the network (in this case, Ethernets) are called subnets.\n\n7. **Example**: The notes mention small university with several class C (now called /24) networks.  There are two Ethernets, one in the Computer Science Dept., with IP address 192.31.65.0 and one in Electrical Engineering, with IP address 192.31.63.0. These are connected by a campus backbone ring (e.g., FDDI) with IP address 192.31.60.0. "
    },
    {
      "id": 79,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "Describe Classless Inter-Domain Routing (CIDR) with an example.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Classless Inter-Domain Routing (CIDR) is a system introduced in 1993 to replace the old classful IP addressing system (Classes A, B, and C). It allows for flexible allocation of IP addresses and efficient routing of packets on the internet. CIDR allows variable-length subnet masks, so you can choose exactly how many bits are used for the network and host parts.\n\nKey aspects of CIDR include:\n\n1.  **Variable-Length Subnet Masks (VLSM):** CIDR eliminates the rigid classful structure, allowing network administrators to define subnet masks that precisely fit their needs.  This optimizes IP address utilization.\n2.  **Network Prefix:** CIDR uses a network prefix to identify a range of IP addresses. The prefix indicates the number of bits that define the network address.\n3.  **Address Allocation:** CIDR enables the allocation of IP addresses in variable-sized blocks, without adhering to class-based boundaries.\n4.  **Routing Efficiency:** CIDR helps reduce the size of routing tables and makes more IP addresses available within organizations.\n5.  **CIDR Notation:**  CIDR is written as <IP address>/<prefix length>. The prefix length specifies the number of bits in the network address.\n\n   *Example:*\n   * 192.168.1.0/24\n   * /24 means the first 24 bits are network bits.\n   * Subnet mask = 255.255.255.0\n\nAdvantages of CIDR:\n\n*   Efficient address space utilization:\nCIDR enables allocation of IP addresses in variable-sized blocks, unlike classful addressing, reducing IP address wastage.\n*   Reduced routing table size:\nCIDR aggregates multiple routes into a single entry, simplifying routing and improving network performance.\n*   Flexible network design:\nCIDR allows organizations to divide their address space into smaller subnets, offering greater control and scalability."
    },
    {
      "id": 80,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "For the IP address 200.16.1.0/30, identify the subnet mask, the number of networks that can be created, the number of IP addresses in each network, the number of usable hosts in each network, and the first and last host addresses of the first network.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Based on the provided notes, here's the information regarding the IP address 200.16.1.0/30:\n\n1.  **Subnet Mask:**\nThe notes do not explicitly state how to calculate the subnet mask from the /30 CIDR notation. Therefore, this information is not available within the context.\n\n2.  **Number of Networks:**\nThe notes do not provide a method to determine the number of networks that can be created from a given IP address and CIDR prefix.\n\n3.  **Number of IP Addresses in Each Network:**\nThe notes do not describe how to determine the number of IP addresses in each network based on the IP address and CIDR notation.\n\n4.  **Number of Usable Hosts in Each Network:**\nThe notes do not provide a method to calculate the number of usable hosts in each network.\n\n5.  **First and Last Host Addresses of the First Network:**\nThe notes lack the information needed to identify the first and last host addresses of the first network. There are no examples or explanations about how to find these addresses, or rules to subnetting."
    },
    {
      "id": 81,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "Write a note on i) NAT ii) ARP iii) DHCP.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Here's a note on i) NAT ii) ARP iii) DHCP based on the provided context:\n\ni) NAT (Network Address Translation):\nNAT enables hosts to use the Internet without requiring globally unique IP addresses. It allows an organization to have a large set of internal private addresses and a single external public address. The organization needs only a single connection to the Internet, which is facilitated through a NAT-enabled router. The NAT router acts as an agent between the public internet and the local private network, presenting itself as a single device with a single IP address to the outside world. Private addresses are meaningful only within the internal network.\n\nii) ARP (Address Resolution Protocol):\nARP is used to map IP addresses to physical MAC addresses on a local network, as defined in RFC 826. It simplifies network configuration by requiring only IP addresses and subnet masks to be assigned. When a host sends a packet, ARP helps to find the receiver’s Ethernet address and builds the frame for transmission. Once a mapping is found, it is stored in an ARP cache to avoid repetitive broadcasts. Hosts can learn each other's IP-to-MAC mappings from ARP replies, reducing future broadcasts. When a machine boots, it can broadcast its mapping to fill ARP caches and detect duplicate IP addresses. ARP cache entries expire automatically after a few minutes to allow updates if hardware changes. If the destination is on another network, a router can respond to ARP requests on behalf of remote hosts; this is known as proxy ARP. For distant networks, packets are sent to the default router, which uses routing tables and ARP on other networks to deliver them to the final host.\n\niii) DHCP (Dynamic Host Configuration Protocol):\nDHCP enables the automatic configuration of IP addresses to hosts. It assigns dynamic IP addresses to devices on a network. Dynamic address allocation is required when a host moves from one network to another or when a host is connected to a network for the first time. DHCP automates network-related aspects of connecting a host into a network. DHCP is a client-server protocol. A client is typically a newly arriving host wanting to obtain network configuration information, including an IP address for itself. In the simplest case, each subnet will have a DHCP server. If no server is present on the subnet, a DHCP relay agent (typically a router) that knows the address of a DHCP server for that network will be used. The process includes DHCP server discovery using a DHCP discover message, DHCP server offers with IP addresses, network masks, and lease times, DHCP request messages from the client, and DHCP ACK messages confirming the requested parameters."
    },
    {
      "id": 82,
      "module": "MODULE-3",
      "topic": "The Network Layer in the Internet",
      "question": "What is the structure of the IPv6 header, and explain all of its fields?",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here's a breakdown of the IPv6 header structure and its fields:\n\n1.  **IPv6 Addresses Length**: IPv6 uses 16-byte (128-bit) addresses, designed to support a significantly larger number of hosts compared to IPv4.\n\n2.  **Goals of IPv6**: Primary goals included:\n a) Supporting billions of hosts.\n b) Reducing the size of routing tables.\n c) Simplifying the protocol for faster packet processing.\n d) Providing better security.\n e) Improving support for real-time data.\n f) Aiding multicasting.\n g) Facilitating host roaming without address changes.\n h) Allowing future protocol evolution.\n i) Ensuring coexistence with IPv4 during transition.\n\n3.  **IPv6 Header Fields**: The IPv6 header is streamlined and contains seven fields (compared to thirteen in IPv4), designed for faster processing. These fields are:\n\n4.  **Version**: A 4-bit field indicating the IP version number. It's set to 6 for IPv6.\n\n5.  **Traffic Class**: An 8-bit field used to differentiate packets with different real-time delivery requirements.\n\n6.  **Flow Label**: A 20-bit field enabling sources and destinations to label packet groups that require specific treatment by the network.\n\n7.  **Payload Length**: A 16-bit field specifying the length of the payload following the 40-byte header (i.e., it doesn't include the header length itself).\n\n8.  **Next Header**: An 8-bit field indicating the type of the next header (extension header, if present) or the transport protocol (e.g., TCP, UDP).\n\n9.  **Hop Limit**: An 8-bit field decremented at each hop to prevent packets from circulating indefinitely, similar to IPv4's Time to Live (TTL) field.\n\n10. **Source Address**: A 16-byte (128-bit) field containing the IPv6 address of the sending host.\n\n11. **Destination Address**: A 16-byte (128-bit) field containing the IPv6 address of the intended recipient.\n\n12. **Checksum**: The Checksum field is not present in IPv6 as it was in IPv4. Calculating the checksum greatly reduces performance.\n\n13. **Simplification of Header**: The streamlining of the IPv6 header (fewer fields) facilitates faster processing by routers, which improves overall throughput and reduces delay.\n\n14. **Better Support for Options**: IPv6 handles options more efficiently than IPv4. Optional extension headers allow for functionality without complicating the main header, and routers can easily skip over options not relevant to them, further speeding up packet processing."
    },
    {
      "id": 83,
      "module": "MODULE-4",
      "topic": "The Transport Service",
      "question": "What is the transport entity?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "PARTIAL",
      "answer": "The transport entity is the hardware and/or software within the transport layer that performs the necessary tasks to provide efficient, reliable, and cost-effective service to its users; it can be located in various places such as the operating system kernel, a separate user process, a library package, or on the network interface card."
    },
    {
      "id": 84,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "What are two socket primitives?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Two socket primitives are SOCKET, which creates a new end point, and BIND, which assigns network addresses. The LISTEN call allocates space to queue incoming calls, while ACCEPT blocks waiting for an incoming connection."
    },
    {
      "id": 85,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "What is a Remote Procedure Call?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "A Remote Procedure Call (RPC) is a technique used to call remote programs using the procedural call, where a process on one machine calls a procedure on another, suspending the caller and executing the called procedure, with information transported in parameters and results."
    },
    {
      "id": 86,
      "module": "MODULE-4",
      "topic": "Addressing",
      "question": "What is TSAP?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "I am sorry, but the provided notes do not contain information about TSAP. Thus, I cannot answer your question."
    },
    {
      "id": 87,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "What are the different types of buffers used in the transport layer?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 88,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Describe the header structure for UDP.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The UDP header consists of a source port, destination port, UDP length, and UDP checksum; the two ports identify the endpoints within the source and destination machines, the length includes the header and the data, and the checksum is for extra reliability."
    },
    {
      "id": 89,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Differentiate between Client Stub and Server Stub.",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "A Client Stub is a small library procedure that represents the server procedure in the client’s address space, used in Remote Procedure Calls (RPC), while a Server Stub is the procedure bound with the server that hides the fact that the procedure call from the client to the server is not local."
    },
    {
      "id": 90,
      "module": null,
      "topic": null,
      "question": "What is MTU?",
      "marks": 2,
      "syllabus_status": "OUT_OF_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 91,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "What is the formula to compute the throughput?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 92,
      "module": "MODULE-4",
      "topic": "The Transport Service",
      "question": "Explain the services provided by the transport layer to the upper layers.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "The transport layer provides several key services to the upper layers (application layer), acting as a crucial intermediary between applications and the underlying network. These services aim to provide efficient, reliable, and cost-effective data transport.\n\n1.  **End-to-End Data Transport:** The transport layer provides data transport from a process on a source machine to a process on a destination machine, building upon the network layer's packet delivery.\n\n2.  **Reliability:** The transport layer can offer a desired level of reliability that is independent of the physical networks in use. For connection-oriented transport services, reliability is a key feature, ensuring data is delivered correctly and in order, even over unreliable networks. This is achieved through mechanisms like acknowledgments and retransmissions.\n\n3.  **Efficient Service:** The transport layer aims to provide efficient service to its users, typically processes in the application layer. This efficiency involves managing data flow, segmenting data appropriately, and handling network congestion.\n\n4.  **Cost-Effective Service:** The transport layer seeks to provide services in a cost-effective manner, optimizing resource usage and minimizing overhead.\n\n5.  **Transport Service Interface:** To allow users (application programs) to access transport services, the transport layer offers a transport service interface. This interface provides operations that application programs can use to send and receive data.\n\n6.  **Connection-Oriented Service:** Similar to connection-oriented network services, the transport layer offers connection-oriented services involving three phases: connection establishment, data transfer, and connection release.\n\n7.  **Addressing:** The transport layer provides a mechanism for identifying senders and receivers through transport addresses, also called Transport Service Access Points (TSAPs). In the Internet, these TSAPs are known as ports.  A transport address consists of an IP address and a port number, identifying exactly where the data should go.\n\n8.  **Flow Control and Buffering:** The transport layer manages data flow between sender and receiver, preventing a fast sender from overwhelming a slow receiver. Buffering is used to store data temporarily, and flow control mechanisms (e.g., sliding window protocols) ensure data is sent at a rate the receiver can handle.\n\n9. **Segmentation and Reassembly:** At the sender's side, the transport layer receives formatted data from upper layers and performs segmentation, breaking the message into smaller units called segments. At the receiver's side, it performs sequencing and reassembling of the segmented data to reconstruct the original message.\n\n10. **Multiplexing:** The transport layer supports multiplexing, allowing multiple connections or conversations to share a single network interface efficiently. This includes upward multiplexing (multiple transport connections using the same network address) and downward multiplexing (using multiple network connections to increase bandwidth).\n\n11. **Crash Recovery:** The transport layer includes mechanisms for crash recovery, allowing connections to resume after a host or router crash without restarting the entire process.\n"
    },
    {
      "id": 93,
      "module": "MODULE-5",
      "topic": "The Domain Name System DNS",
      "question": "Explain the Remote Procedure Call (RPC) with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "A Remote Procedure Call (RPC) is a technique used to make request-reply interactions on networks appear as standard procedural calls within a programming language. When a process on one machine calls a procedure on a remote machine, the calling process is suspended, and the called procedure executes on the remote machine. Information is transported between the caller and callee through parameters and procedure results, without the application programmer needing to manage message passing directly.\n\nHere's a detailed breakdown:\n\n1.  **Client and Server Stubs:** To facilitate the remote procedure call, the client program is linked with a client stub, a small library procedure that represents the server procedure in the client's address space. Similarly, the server is linked with a server stub. These stubs hide the underlying complexities of remote communication.\n\n2.  **Steps in an RPC:**\n    *   **Client Call:** The client calls the client stub as if it were a local procedure. Parameters are pushed onto the stack in the normal way.\n    *   **Parameter Marshaling:** The client stub packs the parameters into a message. This process is called marshaling.\n    *   **Message Transmission:** The operating system sends the message from the client machine to the server machine.\n    *   **Message Unmarshaling:** The operating system passes the incoming packet to the server stub.\n    *   **Server Procedure Call:** The server stub calls the server procedure with the unmarshaled parameters.\n    *   The reply then traces the same path back in the opposite direction.\n\n3.  **Client and Server Roles:**  The calling procedure is traditionally known as the client, while the called procedure is known as the server.\n\n4.  **Diagram Description (Refer notes for diagram):**\n\nThe diagram should illustrate the steps involved in a Remote Procedure Call (RPC). It must show:\n    *   Client Application: Initiates the RPC by calling the client stub.\n    *   Client Stub: Marshals the procedure call and parameters, then sends a message to the server.\n    *   Network: Represents the communication channel over which the request and response are transferred.\n    *   Server Stub: Unmarshals the request and calls the appropriate server procedure.\n    *   Server Application: Executes the requested procedure and returns the result to the server stub.\n    *   The reverse path showing the returning result.\n\n5.  **UDP Applications:** RPC is used to call remote programs using procedural calls.\n\n6. **Analogy**: Sending a message to a remote host and getting a reply back is like making a function call in a programming language."
    },
    {
      "id": 94,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "Explain the elements of the transport layer.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The elements of transport protocols, as presented in the notes, include:\n\n1.  **Addressing**: Unlike the data link layer where the destination is implied by the outgoing line, the transport layer must explicitly specify the destination address. This is because multiple processes or applications may be communicating, necessitating a clear designation of the intended recipient.\n\n2.  **Connection Establishment**: Establishing a connection in the transport layer is more complex than in the data link layer. It involves initial handshakes, error checking, and potentially negotiating parameters before communication can commence. A three-way handshake is used for connection establishment.\n\n    *   Host 1 chooses a sequence number, x, and sends a CONNECTION REQUEST TPDU containing it to host 2. Host 2 replies with an ACK TPDU acknowledging x and announcing its own initial sequence number, y. Finally, host 1 acknowledges host 2's choice of an initial sequence number in the first data TPDU that it sends.\n\n3.  **Connection Release**: The transport layer supports two styles of terminating a connection:\n\n    *   *Asymmetric release*: Similar to the telephone system, where hanging up by one party breaks the connection.\n    *   *Symmetric release*: Treats the connection as two separate unidirectional connections, each requiring individual release.\n\n4.  **Flow Control and Buffering**: After establishing a connection, managing the data flow between sender and receiver is crucial.\n\n    *   Flow control prevents a fast sender from overwhelming a slow receiver.\n    *   Buffering ensures smooth data transmission, with strategies varying based on traffic characteristics.\n\n        *   For low-bandwidth, bursty traffic (like interactive terminal sessions), it's better to buffer at the sender.\n        *   For high-bandwidth, steady traffic (like file transfers), it's better to buffer at the receiver.\n\n5.  **Multiplexing**: Multiplexing involves sharing one connection or link among multiple conversations, enabling efficient use of network interfaces. There is upward and downward multiplexing.\n\n6. **Crash Recovery**: When a host crashes, the connection state (like sequence numbers, buffers, etc.) is lost. The system must figure out how to recover the connection without starting everything from the beginning.\n\n*Host crashes are harder to handle than router or network crashes.*\n\nRefer notes for diagrams about the following:\n\n*   Environment of the data link layer vs environment of the transport layer.\n*   Normal operation of three-way handshake and cases with delayed duplicates.\n*   Four protocol scenarios for releasing a connection.\n*   The operation of the flow control and buffering."
    },
    {
      "id": 95,
      "module": "MODULE-4",
      "topic": "The Transport Service",
      "question": "Explain client and server communication using sockets with a diagram, and write a program for socket communication.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Client and server communication using sockets:\n\n1.  **Socket Creation:** On the server side, the `SOCKET` primitive creates a new endpoint and allocates table space for it within the transport entity. A file descriptor is returned for use in succeeding calls. (module 4.pptx, Slide 11)\n2.  **Address Binding:** Newly created sockets do not have network addresses. These are assigned using the `BIND` primitive. Once a server has bound an address to a socket, remote clients can connect to it. (module 4.pptx, Slide 11)\n3.  **Listening:** The `LISTEN` call allocates space to queue incoming calls in case several clients try to connect at the same time. (module 4.pptx, Slide 11)\n4.  **Accepting Connections:** The server executes an `ACCEPT` primitive to block and wait for an incoming connection. When a TPDU (Transport Protocol Data Unit) asking for a connection arrives, the transport entity creates a new socket with the same properties as the original one and returns a file descriptor for it. This file descriptor can be used for reading and writing. (module 4.pptx, Slide 12)\n5.  **Client-Side Socket Creation:** On the client side, a socket is created using the `SOCKET` primitive. The `BIND` primitive is not required on the client side. (module 4.pptx, Slide 13)\n6.  **Connection Establishment (CONNECT):** The `CONNECT` primitive blocks the caller and starts the connection process. When the appropriate TPDU is received from the server, the client process is unblocked, and the connection is established. (module 4.pptx, Slide 13)\n7.  **Data Transmission (SEND/RECV):** Both sides can use `SEND` and `RECV` to transmit and receive data over the full-duplex connection. The standard UNIX `READ` and `WRITE` system calls can also be used if the special options of `SEND` and `RECV` are not required. (module 4.pptx, Slide 13)\n8.  **Connection Release (CLOSE):** Connection release with sockets is symmetric. When both sides have executed a `CLOSE` primitive, the connection is released. (module 4.pptx, Slide 13)\n\nRefer notes for diagram illustrating client-server socket communication (module 4.pptx, Slide 15) showing nodes and arrows representing the data flow and connection establishment, data transfer, and connection termination steps."
    },
    {
      "id": 96,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "Explain the cases of three-way handshake for connection establishment in the transport layer with neat diagrams.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The three-way handshake is a connection establishment protocol used in the transport layer. It allows two hosts to synchronize their connection sequence numbers. Here's a breakdown with cases:\n\n1.  **Normal Operation:**\n    *   Host 1 (client) chooses a sequence number `x` and sends a CONNECTION REQUEST (SYN) TPDU to Host 2 (server). This TPDU contains `x`.\n    *   Host 2 receives the SYN. It replies with an ACK TPDU acknowledging `x` (ACK `x+1`) and announcing its own initial sequence number `y` (SYN `y`).\n    *   Host 1 receives the SYN-ACK. It acknowledges Host 2's choice of `y` (ACK `y+1`) in the first data TPDU that it sends. From now, communication can occur.\n    *   Refer notes for diagram showing SYN, SYN-ACK and ACK being exchanged between host 1 and host 2.\n\n2.  **Old Duplicate CONNECTION REQUEST:**\n    *   A delayed duplicate CONNECTION REQUEST (SYN) from an old connection arrives at Host 2.\n    *   Host 2, unaware of its staleness, responds with an ACK TPDU, requesting verification that Host 1 is indeed trying to establish a new connection (SYN-ACK).\n    *   Host 1 rejects Host 2's attempt, as it did not initiate a connection, the host 2 realizes that it was tricked by a delayed duplicate and abandons the connection.\n    *   Refer notes for diagram showing delayed duplicate SYN, SYN-ACK and RST(reset) being exchanged between host 1 and host 2.\n\n3.  **Duplicate CONNECTION REQUEST and Duplicate ACK:**\n    *   Host 2 receives a delayed CONNECTION REQUEST (SYN) and replies to it (SYN-ACK).\n    *   Realizes that Host 2 has proposed using `y` as the initial sequence number. It expects that no TPDUs containing sequence number `y` or acknowledgments to `y` are still in existence.\n    *   A second delayed TPDU arrives at Host 2 with `z` acknowledged (ACK `z+1`). The fact that `z` has been acknowledged rather than `y` indicates to Host 2 that this is also an old duplicate. Host 2 abandons the connection.\n    *   Refer notes for diagram showing delayed duplicate SYN, SYN-ACK , duplicate ACK and RST(reset) being exchanged between host 1 and host 2.\n"
    },
    {
      "id": 97,
      "module": "MODULE-4",
      "topic": "Connection Release",
      "question": "Explain the cases of the three-way handshake for connection release with diagrams.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The question concerns connection release in TCP, which is best understood as a pair of simplex connections, each released independently. There are two types of release: asymmetric (like a telephone call, where one party hangs up and the connection is broken) and symmetric (where each direction is shut down separately).\n\nWhen a connection is established, data is transferred between Host 1 and Host 2. To release the connection, either party can send a TCP segment with the FIN bit set, indicating that it has no more data to transmit.\n\nNormal Connection Release (Three-Way Handshake):\n\n1.  One user sends a DISCONNECTION REQUEST (DR) Transport Protocol Data Unit (TPDU) to initiate the connection release.\n2.  Upon arrival, the recipient sends back a DR TPDU and starts a timer in case its DR is lost.\n3.  When this DR arrives, the original sender sends back an ACK TPDU and releases the connection.\n4.  Finally, when the ACK TPDU arrives, the receiver also releases the connection.\n\nHandling Loss of Final ACK:\n\n*   If the second DR is lost, the user initiating the disconnection will timeout and restart the process.\n*   If the final ACK TPDU is lost, the timer at the receiver expires, and the connection is released anyway.\n\nAddressing Repeated Retransmission Failures:\n\n*   If all repeated attempts to retransmit the DR fail due to lost TPDUs, after N retries, the sender gives up and releases the connection.\n*   Meanwhile, the receiver times out and also exits.\n\nRefer notes for diagram. The notes mention \"Four protocol scenarios for releasing a connection. (a) Normal case of three-way handshake. (b) Final ACK lost. (c) Response lost. (d) Response lost and subsequent DRs lost.\" The diagram should visually represent these four scenarios of TCP connection release, highlighting the exchange of DR and ACK TPDUs and the handling of lost packets through timers and retransmissions. Each scenario (a, b, c, d) should depict a timeline of events with labeled TPDUs and indications of timeouts and retransmissions where applicable."
    },
    {
      "id": 98,
      "module": "MODULE-5",
      "topic": "The Domain Name System DNS",
      "question": "Explain the example of socket programming.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Socket programming is a method to connect two nodes over a network to establish a means of communication between those two nodes. A node represents a computer or a physical device with an internet connection. A socket is the endpoint used for connecting to a node. The signals required to implement the connection between two nodes are sent and received using the sockets on each node respectively.\n\nThe nodes are divided into two types, server node and client node. The client node sends the connection signal, and the server node receives the connection signal sent by the client node. The connection between a server and client node is established using the socket over the transport layer of the internet.\n\nAfter a connection has been established, the client and server nodes can share information between them using the read and write commands. After sharing of information is done, the nodes terminate the connection.\n\nRefer notes for diagram of Socket Programming Example that contains:\n1.  Server:\n    *   SOCKET creates a new end point and allocates table space.\n    *   BIND assigns a network addresses.\n    *   LISTEN allocates space to queue incoming calls.\n    *   ACCEPT block waiting for an incoming connection. Creates new socket with the same properties as original one and returns file descriptor for it.\n2.  Client:\n    *   SOCKET creates a new end point and allocates table space.\n    *   CONNECT primitive blocks the caller and actively starts the connection process.\n    *   When it completes, the client process is unblocked and the connection is established.\n3.  Both sides use SEND and RECV to transmit and receive data.\n4.  Both sides execute a CLOSE primitive."
    },
    {
      "id": 99,
      "module": "MODULE-4",
      "topic": "The TCP Segment Header",
      "question": "Explain the TCP segment header with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The TCP segment header is a crucial part of the Transmission Control Protocol (TCP), which operates at the transport layer. It facilitates reliable, ordered, and error-checked delivery of data between applications. The TCP segment consists of a 20-byte fixed header followed by optional header options and data bytes (up to 65,495 bytes). Refer to the notes for a diagram of the TCP Segment Header.\n\nKey components of the TCP segment header include:\n\n1.  **Source Port (16 bits):** Identifies the sending port of the connection.\n2.  **Destination Port (16 bits):** Specifies the receiving port of the connection.\n3.  **Sequence Number (32 bits):** Indicates the sequence number of the first data byte in the segment. In TCP, each byte of data is assigned a unique 32-bit sequence number, aiding in ordering and detecting lost or duplicate data.\n4.  **Acknowledgment Number (32 bits):** Contains the sequence number of the next byte expected from the other party, acknowledging all previously received bytes.\n5.  **TCP Header Length (4 bits):** Specifies the length of the TCP header in 32-bit words. This field indicates where the data begins.\n6.  **Control Flags (6 bits):** These flags control connection establishment, termination, and data flow. Key flags include:\n *   **URG (Urgent):** Indicates that the urgent pointer field is significant and contains data that should be processed urgently.\n *   **ACK (Acknowledgment):** Signifies that the acknowledgment number is valid, used to acknowledge received segments.\n *   **PSH (Push):** Advises the receiving TCP entity to push the data to the application layer.\n *   **RST (Reset):** Resets a confused connection or rejects an invalid segment.\n *   **SYN (Synchronize):** Used during connection establishment to synchronize sequence numbers.\n *   **FIN (Finish):** Indicates that the sender has no more data to transmit, used for connection release.\n7.  **Window Size (16 bits):** Specifies the number of bytes the sender is willing to accept, starting from the byte acknowledged, implementing flow control.\n8.  **Checksum (16 bits):** Provides error detection, covering the TCP header, the TCP data, and a pseudo-header composed of parts of the IP header.\n9.  **Urgent Pointer (16 bits):** Indicates the offset from the current sequence number where urgent data ends.\n10. **Options (Variable):** Provides a way to add extra facilities, including Maximum Segment Size (MSS), window scale, and selective acknowledgments.\n\nTCP is a connection-oriented, full-duplex, point-to-point protocol designed to provide reliable data transmission over an unreliable network. TCP assigns a unique 32-bit sequence number to every byte allowing segments to be reassembled into the proper sequence. It uses a sliding window protocol for reliable delivery. TCP includes optimized algorithms such as Checksums to detect errors and handle out-of-order, delayed, and retransmitted segments."
    },
    {
      "id": 100,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "Explain how flow control and buffering are achieved at the transport layer.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Flow control and buffering are achieved at the transport layer as follows:\n\n1.  **Flow Control Concept**: Flow control prevents a fast sender from overwhelming a slow receiver.\n2.  **Mechanisms Used**: Both the data link layer and the transport layer use mechanisms like sliding window protocols for this purpose. In TCP, the sliding window protocol is employed for reliable delivery.\n3.  **Buffering**: Sender must buffer all outgoing Transport Protocol Data Units (TPDUs) until they are acknowledged, in case they need retransmission. The receiver may use:\n    *   Dedicated buffers for each connection, or\n    *   A shared buffer pool for all connections.\n4.  **Buffering in Data Link Layer**: In data link protocols, both sender and receiver routers keep a fixed number of buffers per line.\n5.  **Buffering in Transport Layer**: The sender must buffer all outgoing Transport Protocol Data Units (TPDUs) until they are acknowledged, in case they need retransmission.\n6.  **Buffering Decision**: For low-bandwidth, bursty traffic (like interactive terminal sessions), it's better to buffer at the sender, where buffers are allocated dynamically as needed. For high-bandwidth, steady traffic (like file transfers), it's better to buffer at the receiver, which dedicates a full window of buffers to keep data flowing smoothly.\n7.  **Buffer Size Management**: Types of buffering approaches include:\n    *   Fixed-size buffers: One TPDU per buffer (good for uniform sizes, wastes space when TPDUs are small, needs multiple buffers for large TPDUs).\n    *   Variable-size buffers: Better memory efficiency, but more complex buffer management.\n    *   Circular buffer per connection: Uses memory efficiently for busy connections, but wasteful if some connections are idle.\n8.  **Transmission Policy (Window Management)**: Receiver has a buffer, so TCP uses a sliding window to avoid overflow.\nWhen the window = 0, the sender must stop sending more data.\n9.  **TCP Congestion Control**: Congestion occurs in a network when the amount of data sent is more than what the network can handle, causing packets to be delayed or lost. TCP deals with congestion mainly by slowing down the data transmission rate.\n10. **Congestion Window**: A connection begins with the congestion window set to one MSS (maximum segment size). If ACKs arrive successfully, the congestion window grows exponentially by adding one MSS for each ACK—this is the slow start phase. When a timeout occurs, TCP assumes the network is congested, cuts the congestion window to one MSS, and reduces a threshold value to half of the previous congestion window.\n11. **Sliding Window Protocol**: This protocol allows sharing multiple data frames from the sender before receiving any acknowledgment from the receiver side.\n12. **Advantages of Sliding Window Protocol**: Higher efficiency, reduced waiting time, supports full-duplex communication, and frame management."
    },
    {
      "id": 101,
      "module": "MODULE-4",
      "topic": "TCP Connection Establishment",
      "question": "Explain TCP connection establishment and connection release.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "TCP connection establishment uses a three-way handshake. Here's how it works:\n\n1.  The server passively waits for an incoming connection by executing the LISTEN and ACCEPT primitives.\n2.  The client executes a CONNECT primitive, specifying the IP address and port to which it wants to connect. This sends a TCP segment with the SYN (synchronize) bit on and the ACK (acknowledgment) bit off, and then waits for a response.\n3.  Host 1 chooses a sequence number, x, and sends a CONNECTION REQUEST TPDU containing it to host 2.\n4.  Host 2 replies with an ACK TPDU acknowledging x and announcing its own initial sequence number, y.\n5.  Host 1 acknowledges host 2's choice of an initial sequence number in the first data TPDU that it sends.\n\nTCP connection release:\n\n1.  TCP connections are full duplex, so each direction is released independently.\n2.  To release a connection, either party can send a TCP segment with the FIN (finish) bit set, indicating it has no more data to transmit.\n3.  When the FIN is acknowledged, that direction is shut down for new data, but data may continue to flow in the other direction.\n4.  When both directions have been shut down, the connection is released. Normally, four TCP segments are needed to release a connection: one FIN and one ACK for each direction.\n5.  There are four protocol scenarios for releasing a connection: normal case of three-way handshake, final ACK lost, response lost, and response lost and subsequent DRs lost.\n6. Releasing a connection means that the transport entity removes the information about the connection from its table of currently open connections and signals the connection's owner."
    },
    {
      "id": 102,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "Explain Congestion Control in TCP.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Congestion Control in TCP:\n\n1.  Congestion Definition: Congestion happens when too many packets in a network cause delays and packet loss, which degrades performance.\n2.  Responsibility: Both network and transport layers handle congestion. The network layer experiences congestion directly and decides what to do. The transport layer reduces the load on the network to control congestion.\n3.  Congestion Impact: When traffic is within capacity, delivery is proportional to sending. Approaching capacity, bursts cause buffer overflow and packet loss, reducing delivered packets.\n4.  Factors Leading to Congestion:\n *  Limited output lines cause queues to build up.\n *  Slow processors delay tasks, building queues.\n *  Low bandwidth lines restrict traffic flow.\n5.  Flow Control vs. Congestion Control:\n *  Flow control: Rate of received traffic is controlled by the receiver, preventing buffer overflow and handling different data rates.\n *  Congestion control: Rate of traffic to the network is controlled, preventing network congestion and ensuring fair allocation of resources.\n6.  General Principles:\n *  Open-loop congestion control: Prevents congestion before it happens, handled by the source or destination.\n *  Closed-loop congestion control: Alleviates congestion after it happens.\n7.  Open-Loop Congestion Control Policies:\n *  Retransmission policy: Manages packet retransmission to prevent increased congestion.\n *  Window policy: Selective repeat windows are preferred to avoid duplication and congestion.\n *  Discarding policy: Routers discard corrupted or less sensitive packets.\n *  Acknowledgment policy: Receivers acknowledge N packets together or after a timer expires.\n *  Admission policy: Switches check resource requirements before transmitting to prevent congestion.\n8.  Closed-Loop Congestion Control Policies:\n *  Backpressure: Congested nodes stop receiving packets, propagating congestion upstream.\n *  Implicit signaling: Sources infer congestion from lack of acknowledgment.\n *  Explicit signaling: Congested nodes send signals to sources or destinations.\n  *  Forward Signaling: Warning sent towards the destination.\n  *  Backward Signaling: Warning sent towards the source.\n9.  Congestion Control in Virtual Circuit Subnets:\n *  Admission control: Prevents new virtual connections during congestion.\n *  Alternate approach: Routes new connections away from congested nodes.\n10. Congestion Control in Datagram Subnets:\n  *  Warning bit: Routers set a bit in the packet header to warn sources, piggybacked on ACKs.\n  *  Choke packet: Nodes send packets to sources to reduce transmission rates (e.g., ICMP Source Quench Packet).\n  *  Hop-by-hop choke packets: Intermediate routers reduce transmission before the choke packet reaches the source.\n11. Load Shedding:\n *  Packets are discarded when the buffer is full, prioritizing less important or older packets.\n *  Applications mark packets to indicate importance for intelligent discarding.\n12. Random Early Detection (RED):\n *  Packets are discarded before the buffer is full to control congestion early.\n *  Maintains a specific queue length and warns/discards packets when exceeded.\n13. Jitter Control:\n *  Jitter is inconsistent delay in data packets due to network congestion, etc.\n *  Bounded by computing expected transit time per hop.\n *  Routers hold or expedite packets to maintain schedule.\n *  Buffering at the receiver can eliminate jitter but introduces delay."
    },
    {
      "id": 103,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Explain the TCP transmission policy.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "The TCP transmission policy, also known as window management, is governed by the receiver's buffer size. To prevent receiver overflow, TCP utilizes a sliding window protocol.\n\n1.  **Buffer Advertisement**: The receiver advertises the amount of free buffer space it has available. For instance, if a receiver has a 4096-byte buffer, it informs the sender of this window size.\n2.  **Initial Transmission**: The sender initially transmits a segment of data, for example, 2048 bytes. After successfully receiving this data, the receiver sends an acknowledgment (ACK) back to the sender. Along with the ACK, the receiver advertises the remaining available buffer space (e.g., 2048 bytes).\n3.  **Full Buffer Scenario**: If the sender transmits another 2048 bytes, and the receiver's buffer becomes completely full, the receiver advertises a window size of 0. A window size of 0 indicates to the sender that it must cease transmitting data.\n4.  **Zero Window Handling**: When the sender receives an advertisement of a window size of 0, it is obligated to halt further transmissions. This mechanism prevents the sender from overwhelming the receiver with more data than it can currently manage.\n5.  **Buffer Space Release**: As the receiving application processes data from the buffer, space is freed up. The receiver can then advertise a larger window size to the sender, indicating that it is ready to receive more data.\n6.  **Deadlock Prevention**: To mitigate deadlocks when the advertised window size is 0, the sender retains the capability to transmit urgent data or a 1-byte probe packet. This action forces the receiver to announce its updated window size, even if it remains 0, ensuring the connection does not stall indefinitely.\n7.  **Transmission Efficiency**: TCP allows both the sender and receiver to delay sending data or acknowledgments (ACKs). This delay is designed to aggregate smaller segments into larger, more efficient packets, thereby optimizing bandwidth utilization.\n8.  **Silly Window Syndrome Avoidance**: To prevent the Silly Window Syndrome, where small packets are inefficiently transmitted, the receiver may be configured to advertise a larger window (e.g., Maximum Segment Size (MSS) or half of the buffer size) instead of a small increment like 1 byte. This approach helps maintain transmission efficiency.\n9.  **Interactive Application Considerations**: Interactive applications may generate numerous tiny packets, which can lead to bandwidth wastage. Nagle's algorithm addresses this by sending one byte immediately and buffering subsequent data until the prior transmission is acknowledged, effectively avoiding the proliferation of small packets.\n\nIn essence, TCP's window management strategy employs receiver-advertised window sizes to dynamically control the flow of data, preventing buffer overflows and optimizing network efficiency. Techniques like delayed ACKs and Nagle’s algorithm further refine this policy to address specific scenarios and enhance overall performance."
    },
    {
      "id": 104,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Explain window management in TCP with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Window management in TCP is achieved using the sliding window protocol. This protocol enables the sender to transmit multiple data frames before receiving acknowledgments from the receiver, enhancing channel utilization. The number of frames that can be transmitted is dictated by the window size. Here's a detailed explanation:\n\n1.  **Sliding Window Protocol:** TCP employs the sliding window protocol for reliable data delivery. This protocol ensures that data is transmitted efficiently and reliably between the sender and the receiver.\n\n2.  **Window Size:** The receiver advertises a window size to the sender, indicating the amount of free buffer space available. The sender is then limited to sending only that amount of data before receiving an acknowledgment.\n\n3.  **Sequence Numbers:** Each byte of data sent in a TCP connection is assigned a unique 32-bit sequence number. This helps in ordering, detecting lost data, and eliminating duplicates.\n\n4.  **Transmission Policy (Window Management):** The receiver has a buffer, and TCP utilizes a sliding window to prevent overflow. The sender transmits data up to the advertised window size. After sending the data, the sender waits for acknowledgments (ACKs) from the receiver.\n\n5.  **Acknowledgment and Window Updates:** When the receiver successfully receives data, it sends an ACK back to the sender, confirming the receipt of the data. The ACK also includes an updated window size, indicating any changes in the available buffer space at the receiver.\n\n6.  **Zero Window Size:** If the receiver's buffer becomes full, it advertises a window size of 0. Upon receiving this, the sender must cease transmitting data to avoid overwhelming the receiver.\n\n7.  **Window Probes:** To avoid deadlocks when the window size is 0, the sender may periodically send urgent data or a 1-byte probe to prompt the receiver to announce an updated window size.\n\n8.  **Silly Window Syndrome:** TCP addresses the silly window syndrome by delaying acknowledgments (ACKs) for about 500 ms to consolidate ACK/window updates with outgoing data. Additionally, Nagle's algorithm sends one byte immediately and buffers the rest until the previous data is acknowledged, preventing tiny packets.\n\n9.  **Congestion Control Interaction:** TCP combines flow control (preventing receiver overwhelm) with congestion control (preventing network congestion). The actual amount of data sent is determined by the minimum of the receiver window and the congestion window.\n\n10. **Refer notes for diagram:** The diagram should visually represent the sliding window mechanism, illustrating the sender and receiver, the window size, sequence numbers, and the movement of the window as data is transmitted and acknowledged. It should depict how the window slides forward as acknowledgments are received, allowing more data to be sent. It can also show the receiver advertising the remaining bytes."
    },
    {
      "id": 105,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "Explain the Sliding Window Protocol.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The Sliding Window Protocol allows the sender to transmit multiple data frames before receiving an acknowledgment from the receiver, thus increasing channel utilization.\n\nKey aspects:\n\n1.  **Window Size:** The maximum number of frames that can be transmitted at a time from the sender to the receiver before an acknowledgment is expected is defined by the window size.\n2.  **Sequence Numbers:** Each frame is assigned a sequence number to ensure proper ordering and transmission efficiency.\n3.  **Virtual Sliding Window:** The data frames transmitted but awaiting acknowledgment are considered to be within a virtual sliding window.\n4.  **Sender Actions:**\n    *   The sender transmits data frames to the receiver up to the limit defined by the window size.\n    *   The sliding window virtually encompasses the frames transmitted but not yet acknowledged.\n    *   The sender then waits for acknowledgments from the receiver.\n5.  **Receiver Actions:**\n    *   The receiver utilizes the received data frames.\n    *   After processing a frame, the receiver sends an acknowledgment back to the sender for that specific frame.\n    *   The receiver then prepares to receive the next data frame.\n6.  **Advantages:**\n    *   Higher efficiency due to the transmission of multiple frames before waiting for acknowledgment.\n    *   Reduced waiting time compared to stop-and-wait protocols.\n    *   Support for full-duplex communication, enabling simultaneous sending and receiving.\n    *   Improved frame management through sorting and sequencing at the receiver.\n7.  **Disadvantages:**\n    *   Inefficiency during lost acknowledgments, requiring retransmission of multiple frames.\n    *   Bandwidth wastage due to retransmission of multiple frames upon loss of any single frame.\n    *   Increased system complexity due to the maintenance of sequence numbers, buffers, and sorting mechanisms.\n8.  **Transmission Policy (Window Management):** TCP utilizes a sliding window to prevent receiver buffer overflow.\n9.  **Deadlock Prevention:** To prevent deadlock when the window size is advertised as 0, the sender can send urgent data or a 1-byte probe to prompt the receiver to announce an updated window size.\n10. **Silly Window Syndrome Prevention:** To avoid sending tiny packets, the receiver can delay acknowledgments and advertise a larger window size (Maximum Segment Size (MSS) or half buffer) instead of a single byte, thereby improving efficiency."
    },
    {
      "id": 106,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "What is the World Wide Web (WWW)?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The World Wide Web (WWW) is a global information space where documents (web pages) are spread across the world and connected through links, supporting online shopping, gaming, and on-demand access to media."
    },
    {
      "id": 107,
      "module": "MODULE-5",
      "topic": "Web Search",
      "question": "What is web crawling?",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Web crawling is the process used by all Web search engines to find pages. Each HTML page may contain links to other pages, and everything interesting (or at least searchable) is linked somewhere. This means that it is theoretically possible to start with a handful of pages and find all other pages on the Web by doing a traversal of all pages and links. Web search engine uses Web crawlers."
    },
    {
      "id": 108,
      "module": "OUT_OF_SYLLABUS",
      "topic": null,
      "question": "Write a note on URL.",
      "marks": 2,
      "syllabus_status": "OUT_OF_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf"
      ],
      "importance": "HIGH",
      "notes_validation": "NOT_FOUND",
      "answer": "A web page, as a file, needs to have a unique identifier called a Uniform Resource Locator (URL) to distinguish it from other web pages, comprised of the protocol, host, port, and path, that defines a web page. Refer notes for diagram."
    },
    {
      "id": 109,
      "module": "MODULE-1",
      "topic": "Social Issues",
      "question": "What are statelessness and cookies?",
      "marks": 2,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Statelessness is not explicitly defined in the provided notes, but cookies are mentioned as a means for companies to track users, raising privacy concerns, as seen on slide 20 of module 1.pptx."
    },
    {
      "id": 110,
      "module": "MODULE-5",
      "topic": "The Domain Name System DNS",
      "question": "Describe the different query mechanisms used to resolve names in the Domain Name System (DNS).",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "The Domain Name System (DNS) resolves human-readable domain names into machine-readable IP addresses. Here's a description of the query mechanisms used:\n\n1.  **Hierarchical Structure:** DNS uses a hierarchical naming structure, similar to postal addressing, managed at the top level by ICANN (Internet Corporation for Assigned Names and Numbers).\n\n2.  **Domain Name Space:** The global namespace is organized into a hierarchy of domains, with top-level domains (TLDs) like .com, .edu, .gov, .org, and country codes (e.g., .in, .uk, .jp).\n\n3.  **Zones:** The DNS namespace is divided into nonoverlapping zones, each responsible for storing resource records for its portion of the DNS hierarchy. Zone boundaries are determined by administrators, considering the number and location of name servers and administrative responsibilities.\n\n4.  **Resource Records (RRs):** Every domain contains a set of resource records (RRs) that form the DNS database. These records store information about the domain, such as IP addresses.\n\n5.  **Name Resolution:** The act of mapping a domain name to an IP address is called name resolution. A resolver receives a query and forwards it to a local DNS name server.\n\n6.  **Authoritative vs. Cached Records:** An authoritative record comes from the authority that manages the record and is always correct, as opposed to cached records, which may be out of date.\n\n7.  **Step-by-Step Resolution:**\n * A resolver sends a query to the local name server.\n * The local name server queries a root name server.\n * The root name server responds with the address of the appropriate TLD name server.\n * This process continues down the DNS hierarchy until the authoritative name server for the domain is reached, and the IP address is returned.\n\n8.  **Caching:** Caching speeds up responses and reduces network load. DNS responses, including partial answers, are stored temporarily so future queries for the same or related domains may be resolved faster.\n\n9. **Remote Resolution Process:** Refer to the notes for a diagram illustrating the step-by-step resolution process. The diagram should illustrate the flow of queries and responses between the resolver, local name server, root name server, TLD name server, and authoritative name server.\n"
    },
    {
      "id": 111,
      "module": "MODULE-5",
      "topic": "The Domain Name System DNS",
      "question": "Write a note on i) DNS name space ii) Name servers.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Here's a note on i) DNS name space and ii) Name servers, based on the provided notes:\n\n**i) DNS Name Space**\n\n*   The Domain Name System (DNS) translates human-readable domain names (e.g., www.google.com) into machine-readable IP addresses (e.g., 142.250.190.78).\n*   DNS employs a hierarchical naming structure to manage a large and continuously changing collection of hostnames across the Internet.\n*   ICANN (Internet Corporation for Assigned Names and Numbers) manages the top of the naming hierarchy.\n*   The global namespace is organized into a hierarchy of domains.\n*   At the highest level, there are top-level domains (TLDs), with over 250 TLDs such as .com, .edu, .gov, .org, and country codes (e.g., .in, .uk, .jp).\n*   Each top-level domain is divided into subdomains, which may be further divided to form a tree-like structure.\n*   Top-level domains are divided into Generic Top-Level Domains (gTLDs) and Country Code Top-Level Domains (ccTLDs).\n*   gTLDs include .com, .edu, .gov, .org, and .net. Additional generic domains have been introduced through ICANN.\n*   ccTLDs are two-letter codes based on ISO 3166, with examples including .in (India), .uk (United Kingdom), and .jp (Japan).\n*   In 2010, internationalized domain names (IDNs) were introduced, allowing domains to be written in non-Latin scripts.\n*   DNS assigns names to domains based on their position in a hierarchical naming tree. Each domain name identifies its location in the hierarchy by listing its components from the leaf up to the root, separated by periods (.), read as \"dot\", e.g., eng.cisco.com.\n*   Every domain contains a set of resource records (RRs) that collectively form the DNS database. Resource records store information about a domain, including the IP address of a host.\n*   The format of DNS Resource records are: Domain name, Time to live, Class, Type, Value.\n\n**ii) Name Servers**\n\n*   The DNS namespace is divided into nonoverlapping zones.\n*   Each zone is responsible for storing and maintaining resource records for its portion of the DNS hierarchy.\n*   Administrators determine the placement of zone boundaries based on the number of name servers needed, their locations, and the division of administrative responsibilities.\n*   For example, washington.edu can be a zone that includes eng.washington.edu. However, cs.washington.edu can be a separate zone with its own name servers.\n*   The act of mapping a domain name to an IP address is called name resolution.\n*   Name resolution process:\n    *   A resolver receives a query.\n    *   It forwards the query to a local DNS name server.\n    *   If the name falls within the zone managed by that server, the server returns the answer.\n*   An authoritative record comes from the authority that manages the record and is always correct, in contrast to cached records that may be out of date.\n*   To find the IP address of a domain such as robot.cs.washington.edu, the DNS performs a step-by-step lookup across multiple name servers. If the local server has no cached information available, it follows a remote resolution process.\n*   Caching is used to speed up responses and reduce network load. All DNS responses, including partial answers, are stored temporarily. Future queries for the same domain or related domains may be resolved much faster.\n*   Refer notes for Figure 7-6 which describes the step-by-step resolution with a diagram.\n"
    },
    {
      "id": 112,
      "module": "MODULE-5",
      "topic": "The Domain Name System DNS",
      "question": "Write a note on Resource Records.",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "In DNS, every domain, whether it represents a single host or an entire top-level domain, contains a set of resource records (RRs). These records collectively form the DNS database. Resource records store information about a domain. The most common record stores the IP address of a host, but DNS supports many other record types as well. \n\nWhen a resolver queries DNS with a domain name (example: www.example.com), DNS returns the resource records associated with that name. The format is as follows: Domain name, Time to live, Class, Type, Value. \n\n*   The Domain name tells the domain to which this record applies. \n*   The Time to live field gives an indication of how stable the record is. \n*   The Class is always IN for Internet information. \n*   The Type field tells what kind of record this is. There are many kinds of DNS records."
    },
    {
      "id": 113,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Describe the Hyper Text Transfer Protocol.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The Hypertext Transfer Protocol (HTTP) is the web's application-layer protocol and is at the heart of the Web. HTTP is implemented in two programs: a client program (e.g., a browser) and a server program. The client and server communicate by exchanging HTTP messages, which define the structure of the messages and how they are exchanged.\n\nKey aspects of HTTP:\n\n1.  **Web Pages and Objects:** A web page consists of objects, where an object is a file (e.g., HTML file, JPEG image, Java applet, video clip) addressable by a single Uniform Resource Locator (URL). Most web pages comprise a base HTML file and several referenced objects, with the base HTML file referencing other objects through their URLs.\n\n2.  **Request and Response:** HTTP defines how web clients request web pages from web servers and how servers transfer web pages to clients. When a user requests a web page (e.g., clicks a hyperlink), the browser sends HTTP request messages for the objects in the page to the server. The server receives these requests and responds with HTTP response messages containing the objects.\n\n3.  **TCP as Transport Protocol:** HTTP uses the Transmission Control Protocol (TCP) as its underlying transport protocol. The HTTP client initiates a TCP connection with the server. Once this connection is established, the browser and server processes access TCP through their socket interfaces. HTTP supports both Non-Persistent and Persistent Connections.\n\n4.  **Non-Persistent Connections:** In a nonpersistent connection, a separate TCP connection is made for each request/response. The client opens a TCP connection and sends a request, the server sends the response and closes the connection, and the client reads the data until it encounters an end-of-file marker before closing the connection. This method incurs high overhead, as the server needs N+1 different buffers each time a connection is opened for N different pictures in different files. Round-trip time (RTT) is the time taken for a small packet to travel from client to server and back. Establishing the TCP connection involves a three-way handshake, taking one RTT, and the HTTP request/response adds another RTT.\n\n5.  **Persistent Connections:** HTTP version 1.1 specifies a persistent connection by default to address shortcomings of non-persistent connections. With persistent connections, the server leaves the TCP connection open after sending a response, allowing subsequent requests and responses between the same client and server to be sent over the same connection. Thus, an entire web page can be sent over a single persistent TCP connection, reducing the overhead and delivery delays.\n\n6.  **Request Message Methods:** HTTP defines several methods, including:\n *GET: Used when the browser requests an object, identified in the URL field.\n*POST: Used when the user requests a web page from the server, where the contents depend on user input from form fields.\n*PUT: Used by applications needing to upload objects to web servers.\n*HEAD: Used to retrieve header information for debugging.\n*DELETE: Allows a user or application to delete an object on a web server."
    },
    {
      "id": 114,
      "module": "MODULE-5",
      "topic": "The Domain Name System DNS",
      "question": "Describe the architecture of electronic mail.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The architecture of electronic mail (e-mail) systems is organized into different components that work together to send, receive, and manage messages over a network. The general architecture consists of two main subsystems:\n\n1.  **User Agents (UA):**\n\t*   A user agent is the software that users interact with directly to manage their e-mail. Examples include Gmail, Outlook, Thunderbird, and mobile mail apps.\n\t*   **Functions of a User Agent:**\n\t\t*   Compose new messages\n\t\t*   Read received messages\n\t\t*   Reply to, forward, delete, and organize mail\n\t\t*   Search mail folders and archives\n\t\t*   Provide either a graphical interface (GUI) or a text-based/command-line interface\n\t*   The process of sending a message from the user agent into the mail system for delivery is known as mail submission.\n2.  **Message Transfer Agents (MTA):**\n\t*   A Message Transfer Agent, also called a mail server, is responsible for transferring e-mail messages across the network from the sender to the recipient.\n\t*   Examples include servers using SMTP (Simple Mail Transfer Protocol).\n\t*   The MTA forwards messages through one or more intermediate servers until they reach the destination mail server, where the recipient can retrieve them using a user agent.\n\n*   **SMTP (Simple Mail Transfer Protocol)** handles message transfer between mail servers and provides delivery status and error reporting.\n*   **Mailboxes and Message Access:** E-mail is stored in mailboxes located on mail servers. User agents access mailbox content by sending commands to the server.\n*   Multiple user agents (phone, laptop, webmail) can access the same mailbox, allowing flexible usage.\n*   **Email Message Format** E-mail messages follow a standard structure, as defined in RFC 5322 (updated from RFC 822). Messages are extended using MIME (Multipurpose Internet Mail Extensions) for images, audio/video, non-English text, and attachments.\n\n*   A key idea in the message format is the distinction between the **envelope** and its **contents**. The envelope encapsulates the message and contains all the information needed for transporting the message, such as the destination address, priority, and security level. The message inside the envelope consists of two separate parts: the **header** and the **body**. The header contains control information for the user agents, and the body is entirely for the human recipient.\n*   Refer notes for diagram (Figure 7-7) illustrating the general architecture of an email system."
    },
    {
      "id": 115,
      "module": "MODULE-5",
      "topic": "Electronic Mail",
      "question": "Explain the message format of email.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "The message format of email, as per the notes, follows a standard structure, with a key distinction between the envelope and its contents. This structure is originally defined by RFC 822 and updated by RFC 5322, extended by MIME (Multipurpose Internet Mail Extensions) for images, audio/video, non-English text and attachments.\n\nHere's a breakdown:\n\n1.  **Envelope:** The envelope encapsulates the message and contains information needed for transporting the message, such as the destination address, priority, and security level.\n2.  **Contents:** The message inside the envelope has two parts:\n\n    *   **Header:** Contains control information for user agents (email clients). Relevant header fields include:\n        *   **To:** DNS address of the primary recipient (multiple recipients allowed).\n        *   **Cc:** Addresses of secondary recipients. There's no functional difference in delivery between To and Cc.\n        *   **Bcc:** Addresses of blind carbon copy recipients. This field is removed from copies sent to primary and secondary recipients.\n        *   **From:** Indicates who wrote the message.\n        *   **Sender:** Indicates who sent the message; may differ from the From field (e.g., an assistant sending an email on behalf of an executive).\n        *   **Received:** Added by each message transfer agent (MTA) along the way, containing agent identity, date, time, and debugging information.\n        *   **Return-Path:** Added by the final MTA, intended to indicate how to return to the sender, but often just contains the sender's address.\n    *   **Body:** The actual content of the email for the recipient.\n3.  **MIME Headers:** MIME extends email capabilities by defining five headers to specify transformation parameters for non-ASCII data:\n    *   **MIME-Version:** Version of MIME used (current is 1.1).\n    *   **Content-Type:** Type of data in the message body (e.g., text, image, audio, video), along with subtypes and parameters.\n    *   **Content-Transfer-Encoding:** Method used to encode the message for transport (e.g., 7bit, 8bit, binary, quoted-printable, base64).\n    *   **Content-ID:** Uniquely identifies the whole message in a multiple message environment.\n    *   **Content-Description:** Describes whether the body is image, audio, or video."
    },
    {
      "id": 116,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Explain the server side communication in WWW architecture.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The server-side communication in WWW (World Wide Web) architecture involves several key aspects, primarily focusing on how web servers handle client requests and deliver content.\n\n1.  **Client-Server Model:** The WWW operates on a distributed client-server model. Web browsers (clients) request resources from web servers.\n\n2.  **Web Servers:** Web servers store and manage web pages. These servers respond to client requests by sending the requested files or dynamically generated content.\n\n3.  **HTTP Protocol:** The Hypertext Transfer Protocol (HTTP) is the foundation of data communication on the Web. It defines how clients (browsers) request web pages from Web servers and how servers transfer Web pages to clients.\n\n4.  **Request Messages:** When a user clicks on a hyperlink or enters a URL, the browser sends HTTP request messages to the server.\n\n5.  **Response Messages:** The server receives these requests and responds with HTTP response messages that contain the requested objects (e.g., HTML files, images, etc.).\n\n6.  **TCP Connection:** HTTP uses TCP (Transmission Control Protocol) as its underlying transport protocol. The HTTP client initiates a TCP connection with the server before sending any requests.\n\n7.  **Non-Persistent Connections:** In a non-persistent HTTP connection, a separate TCP connection is established for each request/response. After the server sends the response, it closes the connection.\n\n8.  **Persistent Connections:** HTTP version 1.1 specifies persistent connections by default. The server leaves the TCP connection open after sending a response, allowing subsequent requests and responses to be sent over the same connection.\n\n9.  **Static Documents:** Static documents are fixed-content files stored on the server. When a client requests a static document, the server sends a copy of the file.\n\n10. **Dynamic Documents:** Dynamic documents are created by the web server in response to a client request. The server runs an application or script to generate the document. This allows the content to vary from request to request.\n\n11. **Web Caching (Proxy Servers):** Web caches are network entities that satisfy HTTP requests on behalf of origin web servers. They store copies of recently requested objects to reduce network traffic and improve response times.\n\n12. **Load balancing:** To improve efficiency, servers normally store requested files in a cache in memory; memory is faster to access than a disk. A server can also become more efficient through multi threading or multiprocessing to answer more than one request at a time."
    },
    {
      "id": 117,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Describe MIME—The Multipurpose Internet Mail Extensions—along with its header information.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "MIME (Multipurpose Internet Mail Extensions) is a supplementary protocol that enables the transmission of non-ASCII data through email. It addresses the limitations of the basic email structure, which is confined to 7-bit ASCII, thereby preventing the sending of binary files, video, audio data, and non-English languages. MIME operates by transforming non-ASCII data at the sender's end into NVT ASCII data, which is then dispatched to the client MTA (Mail Transfer Agent) for transmission over the Internet. Upon reaching the receiving end, the message undergoes a reverse transformation to restore it to its original format.\n\nMIME defines five header fields to specify the transformation parameters:\n\n1.  **MIME-Version:** Indicates the version of MIME in use, currently 1.1.\n2.  **Content-Type:** Specifies the data type in the message body, with subtypes separated by a slash. Parameters may be included depending on the subtype. Seven data types are permitted.\n3.  **Content-Transfer-Encoding:** Defines the encoding method used to convert messages into binary format for transport. Five encoding methods are defined.\n4.  **Content-ID:** Uniquely identifies the message in a multiple-message environment.\n5.  **Content-Description:** Specifies whether the body contains image, audio, or video data.\n\nThe MIME headers are added to the original email header section to define the transformation parameters. MIME acts as a set of software functions that converts non-ASCII data to ASCII data and vice versa, allowing for a broader range of content to be sent via email."
    },
    {
      "id": 118,
      "module": "MODULE-5",
      "topic": "The Domain Name System DNS",
      "question": "Compare POP3 and IMAP.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "NOT_FOUND",
      "answer": "POP3 (Post Office Protocol version 3) and IMAP (Internet Message Access Protocol) are both protocols used for retrieving email from a mail server. Here's a comparison based on the provided notes:\n\n1.  **Mailbox Access:** IMAP4 (Internet Mail Access Protocol, version 4) provides more features compared to POP3, like allowing the user to organize their mail on the server with different folders. POP3 does not offer this capability.\n\n2.  **Partial Content Check:** IMAP4 allows users to partially check the contents of emails before downloading them. This means a user can view the email header or search for specific characters within the email before downloading the entire message. POP3 does not allow this.\n\n3.  **Partial Download:** IMAP4 allows users to partially download email content. This is beneficial when bandwidth is limited, and emails contain multimedia with high bandwidth requirements. POP3 lacks this feature.\n\n4.  **Mailbox Management:** With IMAP4, users can create, delete, or rename mailboxes on the mail server. They can also create a hierarchy of mailboxes within a folder for email storage. POP3 does not provide these mailbox management features.\n\n5.  **Power and Complexity:** The notes state that IMAP4 is more powerful and more complex than POP3.\n\n6.  **Flexibility:** IMAP allows Multiple user agents (phone, laptop, webmail) can access the same mailbox, allowing flexible usage.\n\n7.  **Deficiencies of POP3:** The notes explicitly state that POP3 is deficient in several ways compared to IMAP4."
    },
    {
      "id": 119,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Explain RFC 822 header fields.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "CNQuestionBank-22CSE52.docx"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "RFC 822 header fields are not explicitly explained in the provided notes. However, the notes do discuss email message formats, which are closely related to RFC 822.\n\nBased on the notes, here is the available information on email message formats:\n\n1.  Email messages follow a standard structure, originally defined by RFC 822 and updated by RFC 5322.\n2.  The message format distinguishes between the envelope and its contents. The envelope contains information needed for message transport, such as the destination address, priority, and security level.\n3.  The message inside the envelope consists of two parts: the header and the body.\n4.  The header contains control information for user agents (email readers).\n5.  The body is for the human recipient.\n6.  Key header fields related to message transport include:\n *To: The DNS address of the primary recipient. Multiple recipients are allowed.\n *Cc: The addresses of secondary recipients. There is no delivery distinction between primary and secondary recipients.\n *Bcc: (Blind carbon copy) Like Cc, but the Bcc line is deleted from copies sent to primary and secondary recipients.\n *From: Who wrote the message.\n *Sender: Who sent the message (may be different from the writer).\n *Received: Added by each message transfer agent (MTA) along the way. Contains agent identity, date, time, and debugging information.\n *Return-Path: Added by the final MTA. Intended to indicate how to return to the sender.\n7.  MIME (Multipurpose Internet Mail Extensions) is used to send non-ASCII data (images, audio/video, non-English text, attachments) through email.\n8.  MIME defines five headers: MIME-Version, Content-Type, Content-Transfer-Encoding, Content-ID, and Content-Description.\n9. Content-Type defines the type of data used in the body of the message.\n10.SMTP (Simple Mail Transfer Protocol) handles message transfer between mail servers."
    },
    {
      "id": 120,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Explain the parts of the Web model with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The Web model is based on a distributed client-server architecture, where a client (browser) accesses services from servers distributed across many locations (sites). Each site hosts one or more web pages, which can be simple (no links) or composite (containing links to other pages).\n\n**Parts of the Web Model:**\n\n1.  **Web Client (Browser):** Commercial browsers interpret and display web pages. A browser consists of:\n\n    *   **Controller:** Receives input from the keyboard or mouse and uses client programs to access documents.\n    *   **Client Protocols:** Protocols like HTTP or FTP.\n    *   **Interpreters:** Interpreters like HTML, Java, or JavaScript to display documents.\n\n2.  **Web Server:** Stores web pages and sends them to clients upon request. To improve efficiency, servers use:\n\n    *   **Cache:** Stores frequently requested files in memory for faster access.\n    *   **Multithreading/Multiprocessing:** Handles multiple requests simultaneously.\n\n3.  **Web Pages:** These are the documents in the WWW and can be:\n\n    *   **Static Documents:** Fixed-content documents stored on a server and sent as a copy to the client. These are created using languages like HTML, XML, XSL, and XHTML.\n    *   **Dynamic Documents:** Created by a web server upon request, running an application program or script, and returning the result to the browser. The content can vary with each request.\n\n4.  **Uniform Resource Locator (URL):** A unique identifier for each web page file, composed of:\n\n    *   **Protocol:** Method to reach the web page (e.g., HTTP, FTP).\n    *   **Host:** Location where the web page is stored (IP address or domain name).\n    *   **Port:** Specific entry point on the server (e.g., 80 for HTTP, 443 for HTTPS).\n    *   **Path:** Exact location of the web page file within the server.\n\n5.  **HTTP (Hypertext Transfer Protocol):** The application-layer protocol at the core of the Web, implemented in client and server programs. It defines the structure of messages and how they are exchanged.\n\n    *   HTTP uses TCP as its underlying transport protocol.\n    *   Web pages consist of a base HTML file and referenced objects.\n\n6. **Web Caching:** A network entity (proxy server) that satisfies HTTP requests on behalf of an origin web server.\n\n    *   Stores copies of recently requested objects.\n    *   Reduces load on origin servers and network congestion.\n\n**Diagram Description:**\nRefer notes for diagram. A diagram illustrating the Web model should depict the key components and their interactions. It should show:\n\n*   A client (browser) sending a request to a web server.\n*   The web server retrieving the requested web page (static or dynamic) from its storage.\n*   The web server sending the web page back to the client for display.\n*   The components of a URL and their respective roles.\n*   The flow of HTTP messages between the client and server."
    },
    {
      "id": 121,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Explain the different HTTP request methods used in creating an HTTP message.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 3,
      "sources": [
        "CNQuestionBank-22CSE52.docx",
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "HIGH",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, the different HTTP request methods used in creating an HTTP message are:\n\n1.  **GET:** This method is used when the browser requests an object, with the requested object identified in the URL field.\n2.  **POST:** With a POST message, the user is still requesting a Web page from the server, but the specific contents of the Web page depend on what the user entered into the form fields. If the value of the method field is POST, then the entity body contains what the user entered into the form fields.\n3.  **PUT:** The PUT method is used by applications that need to upload objects to Web servers.\n4.  **HEAD:** Used to retrieve header information and is used for debugging purposes.\n5.  **DELETE:** The DELETE method allows a user, or an application, to delete an object on a Web server.\n\nThese methods define the actions a client can request from a web server, forming the basis for interactions on the World Wide Web."
    },
    {
      "id": 122,
      "module": "MODULE-1",
      "topic": "Uses of computer networks",
      "question": "Define computer network and briefly describe its uses.",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "A computer network is a set of devices, often called nodes, connected by communication links. These nodes can be computers, printers, or any device capable of sending and receiving data. Essentially, it's a collection of autonomous computers interconnected via a single technology, enabling them to exchange information for the purpose of sharing resources.\n\nUses of computer networks:\n\n1.  **Business Applications**: Networks enable resource sharing (programs, equipment, and data) among employees, regardless of location. Virtual Private Networks (VPNs) connect individual networks at different sites. IP telephony (VoIP) carries telephone calls over the computer network.\n2.  **Home Applications**: Primarily for internet access, enabling remote information access (www), person-to-person communication (chatting), social networking (Facebook, WhatsApp), interactive entertainment (IPTV), and e-commerce (shopping).\n3.  **Mobile Users**: Mobile computing allows work from anywhere, providing access to calls, emails, and documents. Wireless networking is utilized in universities, taxis, conferences, and military settings. M-commerce facilitates mobile payments and location-based offers.\n4.  **Social Issues**: Networks raise content regulation issues (censorship), privacy concerns (surveillance), and rights conflicts (employer vs. employee privacy)."
    },
    {
      "id": 123,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "What are the two technical issues in network hardware design? Explain.",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, the question about \"two technical issues in network hardware design\" cannot be directly answered, as the context focuses more on network architecture, protocols, and services rather than specific hardware design issues. However, the design issues for the *layers* in network software are covered extensively. The design issues for the layers (network software) are:\n\n1.  **Addressing:** Every layer needs a mechanism for identifying senders and receivers, as a process on one machine must specify with whom it wants to communicate.\n2.  **Data Transfer Rules:** Protocols must determine the directionality of data flow (one-way or two-way) and the number/priorities of logical channels.\n3.  **Error Control:** Due to imperfect physical communication circuits, error-detecting or error-correcting codes are required. Agreement on the error control method is needed.\n4.  **Sequencing:** Protocols must handle proper reassembly of messages, as not all channels preserve message order. Numbering message pieces helps, but handling out-of-order arrivals is still required.\n5.  **Flow Control:** Flow control is essential to prevent a fast sender from overwhelming a slow receiver with data. \n6. **Message Size Handling:** Long messages must be disassembled, transmitted, and reassembled. Small messages can be combined into a single larger one for efficiency.\n7. **Multiplexing:** The same connection may carry multiple unrelated conversations. Multiplexing and demultiplexing should be transparent to the layers above.\n8. **Routing:** When multiple paths exist, a route must be chosen between source and destination. \n9. **Channel Priorities:** Many networks provide separate channels for normal and urgent data. This allows urgent information to be transmitted without waiting for normal data."
    },
    {
      "id": 124,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Differentiate between LAN, WAN, and MAN.",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here's a differentiation between LAN, WAN, and MAN:\n\n*   **LAN (Local Area Network):** Privately-owned networks within a single building or campus, typically spanning a few kilometers. They connect personal computers and workstations in offices and factories. Key characteristics include size restrictions, specific transmission technology (cable-based), and topology.\n*   **MAN (Metropolitan Area Network):** Covers a city; larger than a LAN but smaller than a WAN. An example is cable television networks in many cities which evolved to also offer specialized channels and two-way Internet service.\n*   **WAN (Wide Area Network):** Covers a large geographical area, often a country or continent. Hosts are connected by a communication subnet, which carries messages from host to host. The subnet consists of transmission lines and switching elements. WANs are designed for high-latency, large-scale data transfer. Examples include the Internet and global corporate networks."
    },
    {
      "id": 125,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "List and explain the categories of network hardware based on scale.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, the categories of network hardware based on scale are:\n\n1.  **Local Area Networks (LANs):** These are privately-owned networks within a single building or campus, typically spanning a few kilometers. LANs connect personal computers and workstations in offices and factories. Key characteristics include size, transmission technology, and topology. They commonly use a cable to which all machines are attached, employing various topologies like bus, ring, or star.\n\n2.  **Metropolitan Area Networks (MANs):** MANs cover a city, larger than a LAN but smaller than a WAN. An example is cable television networks. They evolved from community antenna systems, later offering specialized channels and two-way Internet service.\n\n3.  **Wide Area Networks (WANs):** WANs cover large geographical areas, often a country or continent. Hosts are connected by a communication subnet consisting of transmission lines and switching elements. WANs are designed for high-latency, large-scale data transfer, like the Internet or global corporate networks.\n\n4.  **Wireless Networks:** These networks transmit data using radio waves instead of cables, enabling mobility. They include system interconnection (e.g., Bluetooth), wireless LANs (WLANs), and wireless WANs (WWANs). Wireless networks can be expanded quickly without new cables. Wi-Fi networks in public hotspots are an example.\n\n5.  **Home Networks:** Home networks connect multiple household devices, including computers, entertainment systems, appliances, and security equipment. They allow devices to communicate and access the Internet. These networks must be easy to install, high-performing for multimedia, affordable, expandable, secure, and reliable.\n\n6. **Internetwork:** A combination of two or more networks such as LAN, MAN, and WAN, allowing them to function as one system. Facilitates communication and resource sharing between devices on different networks. Uses routers, gateways, and switches to connect and manage traffic between networks. Supports both similar and different network technologies for seamless integration. Can be private (intranet) for internal use or public (Internet) for global access. Example: Corporate offices worldwide connected via Internet for collaboration."
    },
    {
      "id": 126,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "Briefly explain the TCP/IP reference model.",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The TCP/IP reference model, designed and developed by the Department of Defense (DoD) in the 1960s, is based on standard protocols. It contains four layers. The main function of TCP/IP is to transfer data reliably and accurately from one computer to another. To ensure accurate delivery, the model divides data into packets and combines them at the destination.\n\n*   **Network Interface Layer:** Defines how data is physically sent through the network, including electrical or optical signaling by hardware. It is responsible for placing TCP/IP packets on and receiving them from the network medium. Protocols include Ethernet, Token Ring, FDDI, and Frame Relay.\n*   **Internet Layer:** Allows hosts to inject packets into any network for independent travel to the destination. It defines the IP (Internet Protocol) packet format and protocol. This layer handles addressing, packaging, and routing functions. Core protocols are IP, ARP, ICMP, and IGMP.\n*   **Transport Layer:** Enables peer entities on source and destination hosts to carry on a conversation. TCP (Transmission Control Protocol) is a reliable, connection-oriented protocol ensuring error-free delivery of a byte stream. UDP (User Datagram Protocol) is an unreliable, connectionless protocol for applications.\n*   **Application Layer:** Provides applications with the ability to access the services of the other layers. Widely-known protocols include HTTP (for web pages), FTP (for file transfer), SMTP (for email), and Telnet (for remote login)."
    },
    {
      "id": 127,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Define routing and write the difference between routing and forwarding.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Routing and forwarding are distinct processes within the network layer, primarily concerning the movement of data packets from a source to a destination.\n\n**Routing:**\n\n1.  **Definition:** Routing is the process of determining the optimal path for data packets to travel from the source to the destination. It involves the use of routing algorithms to construct and update routing tables. These tables guide the forwarding process.\n2.  **Objective:** The primary goal of routing algorithms is to discover and utilize sink trees for all routers, ensuring efficient paths to destinations.\n3.  **Algorithms:** Various routing algorithms exist, such as: the Optimality Principle, Shortest Path Routing (e.g., Dijkstra's algorithm), Flooding, Distance Vector Routing, Link State Routing, and Hierarchical Routing.\n4.  **Properties:** Routing algorithms should possess properties like correctness, simplicity, robustness, stability, fairness, and optimality.\n5.  **Hierarchical Routing:** In large networks, hierarchical routing divides routers into regions to reduce the size of routing tables. Routers know details within their region but not the internal structure of other regions.\n\n**Forwarding:**\n\n1.  **Definition:** Forwarding refers to the process of handling each packet as it arrives at a router. It involves looking up the outgoing line to use for the packet in the routing table.\n2.  **Mechanism:** Forwarding decisions are made based on the destination address in the packet header and the information stored in the routing table.\n3.  **Store-and-Forward:** In wide area networks (WANs), forwarding often uses a store-and-forward mechanism, where the packet is received in its entirety, stored until the output line is free, and then forwarded.\n\n**Differences Between Routing and Forwarding:**\n\n1.  **Scope:** Routing is a network-wide process that determines paths, while forwarding is a local process that handles individual packets at each router.\n2.  **Time Scale:** Routing is a slower process that updates routing tables periodically or when network topology changes. Forwarding is a fast, per-packet process that occurs in real-time.\n3.  **Responsibility:** The routing process is responsible for filling in and updating the routing tables. The forwarding process uses these tables to direct packets.\n4.  **Algorithms vs. Tables:** Routing algorithms determine the content of routing tables. Forwarding uses the routing tables to make decisions.\n5.  **Control vs. Action:** Routing is about control and planning of the network's data paths. Forwarding is about taking action to move data packets along those paths."
    },
    {
      "id": 128,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Describe the optimality principle and solve the given problem to find the shortest path from A to D using Dijkstra’s algorithm.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The optimality principle states that if router J is on the optimal path from router I to router K, then the optimal path from J to K also falls along the same route. A set of optimal routes from all sources to a given destination forms a tree rooted at the destination, which is called a sink tree. The goal of all routing algorithms is to discover and use the sink trees for all routers.\n\nDijkstra’s algorithm is a shortest path routing algorithm, based on dynamic programming for optimization. It involves building a graph of the subnet, where each node represents a router and each arc represents a communication link. To find the shortest path between a pair of routers, the algorithm finds the shortest path between them on the graph. The steps are as follows:\n\n1.  Start with the local node (router) as the root of the tree. Assign a cost of 0 to this node and make it the first permanent node.\n2.  Examine each neighbor of the node that was the last permanent node.\n3.  Assign a cumulative cost to each node and make it tentative.\n4.  Among the list of tentative nodes:\n a. Find the node with the smallest cost and make it Permanent.\n b. If a node can be reached from more than one route then select the route with the shortest cumulative cost.\n5.  Repeat steps 2 to 4 until every node becomes permanent.\n\nRefer to the notes for the Dijkstra’s Routing algorithm in pseudocode. The pseudocode initializes a set N with the starting node A and calculates the initial distances D(v) to all other nodes v. It then iteratively finds the node w outside of N with the minimum distance, adds it to N, and updates the distances to all neighbors of w that are not in N.\n\n**Note**: The notes do not provide a specific problem instance to solve using Dijkstra’s algorithm. Refer to the provided notes for the algorithm details and apply them to a given network topology to find the shortest path from A to D."
    },
    {
      "id": 129,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Explain how broadcasting is achieved in Reverse Path Forwarding, and write the advantages and disadvantages.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "NOT_FOUND",
      "answer": "Reverse Path Forwarding is not explicitly detailed in the provided notes. However, based on the general principles of networking and routing algorithms discussed, here's an explanation that incorporates related concepts:\n\n1.  **Broadcasting Context:** The notes mention flooding as a routing algorithm where every incoming packet is sent out on every outgoing line except the one it arrived on (module 2.pptx, Slide 12). This relates to broadcasting as it ensures the packet reaches every node in the network.\n\n2.  **Hop Counter:** Flooding generates vast numbers of duplicate packets. To manage this, a hop counter in the packet header is decremented at each hop. The packet is discarded when the counter reaches zero (module 2.pptx, Slide 12). This mechanism prevents infinite loops.\n\n3.  **Selective Flooding:** A variation of flooding, selective flooding, is mentioned, where routers send packets only on lines going approximately in the right direction (module 2.pptx, Slide 12).\n\n4.  **Duplicate Packet Handling:** Routers remember the identity of packets they've already sent to discard duplicates, achieved using sequence numbers placed by the source router (module 2.pptx, Slide 12).\n\n5.  **Advantages of Flooding (related to broadcasting):**\n    *   Useful in military applications where routers may be destroyed (robustness).\n    *   Applicable in distributed database updates where concurrent updates are needed.\n    *   Serves as a metric for comparison against other routing algorithms.\n    *   Chooses the shortest path by exploring all possible paths in parallel (module 2.pptx, Slide 13).\n\n6.  **Disadvantages of Flooding (related to broadcasting):**\n    *   Generates a large number of duplicate packets, potentially overwhelming the network (module 2.pptx, Slide 12).\n    *   Not practical in most applications due to the high overhead and potential for network congestion (module 2.pptx, Slide 12).\n\nWhile these notes do not specifically detail Reverse Path Forwarding, they provide a basis for understanding how broadcasting can be achieved and the trade-offs involved in flooding-based approaches which share conceptual similarities.\nTherefore, the advantages and disadvantages of flooding can be considered in the context of broadcasting techniques like RPF:\n\n**Advantages in context to Broadcasting (Flooding):**\n\n1.  **Robustness:** Suitable for networks prone to failures.\n2.  **Concurrency:** Useful for concurrent updates in distributed systems.\n3.  **Shortest Path Discovery:** Explores all paths in parallel.\n\n**Disadvantages in context to Broadcasting (Flooding):**\n\n1.  **Duplicate Packets:** High potential for network congestion due to numerous duplicates.\n2.  **Impracticality:** Not suitable for most general applications due to overhead."
    },
    {
      "id": 130,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Write and explain the Bellman-Ford algorithm with an example.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The Bellman-Ford algorithm is not explicitly described in the provided notes. However, Distance Vector Routing is, and it is sometimes called the distributed Bellman-Ford routing algorithm (Slide 14 Module 2.pptx).\n\nDistance Vector Routing:\n1.  **Overview**: Each router maintains a table containing the best-known distance to each destination and the link to use to get there (Slide 14 Module 2.pptx).\n2.  **Routing Table**: Each router's routing table is indexed by, and contains one entry for each router in the network. This entry has two parts: the preferred outgoing line to use for that destination and an estimate of the distance to that destination (Slide 14 Module 2.pptx).\n3.  **Neighbor Knowledge**: The router knows the distance to each of its neighbors. The distance can be hops, queue length or delay (Slide 14 Module 2.pptx).\n4.  **Example**: J's neighbors delays are JA=8, JI=10, JH=12, JK=6. \n5.  **New Route Calculation**: J can determine the delay to G via different neighbors. For example, if A can get to G in 18ms, and J can get to A in 8ms, then J can get to G via A in 26ms (Slide 15 Module 2.pptx).\n6.  **Delay calculation via neighbors**: Similarly, the delay to G via I, H and K are calculated as (31 +10) =41, (6+12)=18, (31+6)=37 m sec. \n7.  **Best Value Selection**: The best of these values is 18, so it makes an entry in its routing table that the delay to G is 18 m sec and that route is via H (Slide 15 Module 2.pptx).\n8.  **Count-to-Infinity Problem**: The count-to-infinity problem is an issue in distance vector routing, where routers share information to find the best path to a destination (Slide 16 Module 2.pptx).\n9.  **Good News Spreads Quickly**: When a new, shorter path is available, routers update routes quickly (Slide 16 Module 2.pptx).\n10. **Bad News Travels Slowly**: When a route goes down, the bad news spreads slowly, causing delays and confusion (Slide 16 Module 2.pptx).\n11. **Example scenario of Count to Infinity Problem**: Routers keep increasing the distance to A, believing A is reachable, which isn't true (Slide 17 Module 2.pptx).\n12. **Split horizon and poisoned reverse**: Attempts to solve this problem aren’t perfect and don’t solve the problem completely in all cases (Slide 18 Module 2.pptx).\n\nBecause distance vector routing is sometimes referred to as the distributed Bellman-Ford routing algorithm, this explanation can be used for understanding and describing Bellman-Ford."
    },
    {
      "id": 131,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "Define congestion in a network and describe the different approaches to control congestion.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "Congestion in a network occurs when too many packets are present in a part of the network, leading to packet delay and loss, which degrades performance. The network and transport layers share the responsibility for handling congestion. While the network layer directly experiences congestion and determines how to manage excess packets, the most effective control comes from reducing the load placed on the network by the transport layer.\n\nApproaches to Congestion Control:\n\n1.  **Open Loop Congestion Control**: These policies aim to prevent congestion before it happens. The congestion control is handled either by the source or the destination.\n\n    *   **Retransmission Policy**: Deals with retransmission of packets. If a sender thinks a packet is lost, retransmission can increase congestion. Retransmission timers must be designed to optimize efficiency and prevent congestion.\n    *   **Window Policy**: The type of window at the sender's side affects congestion. Selective repeat windows are preferred over Go-back-N because they re-send only lost packets, avoiding unnecessary duplication.\n    *   **Discarding Policy**: Routers may prevent congestion by discarding corrupted or less sensitive packets while maintaining message quality.\n    *   **Acknowledgment Policy**: The receiver should acknowledge N packets at once, instead of acknowledging each packet individually. Also, acknowledgments should be sent only when a packet needs to be sent or when a timer expires.\n    *   **Admission Policy**: Switches check the resource requirements of a network flow before transmission. If congestion is likely, new virtual network connections are denied to prevent it.\n2.  **Closed Loop Congestion Control**: These techniques treat or alleviate congestion after it occurs.\n\n    *   **Backpressure**: A congested node stops receiving packets from upstream nodes, potentially causing congestion to propagate backward.\n    *   **Implicit Signaling**: The source infers congestion based on network behavior, such as a lack of acknowledgments.\n    *   **Explicit Signaling**: A congested node explicitly sends a packet to the source or destination to inform about congestion.\n        *   **Forward Signaling**: A signal is sent in the direction of congestion to warn the destination.\n        *   **Backward Signaling**: A signal is sent in the opposite direction of the congestion to warn the source to slow down.\n3.  **Congestion Control in Virtual Circuit Subnets**:\n\n    *   **Admission Control**: Once congestion occurs, new virtual connections are not set up until the congestion is resolved. Alternatively, new connections can be routed to nodes other than the congested node.\n4.  **Congestion Control in Datagram Subnets**:\n\n    *   **Warning Bit**: A special bit in the packet header is set by the router to warn the source when congestion is detected. The bit is copied onto the ACK packet.\n    *   **Choke Packet**: A packet sent by a node to the source to inform about congestion.  The source reduces its transmission rate upon receiving a choke packet.\n    *   **Hop-by-Hop Choke Packets**: Choke packets are sent hop-by-hop to improve effectiveness over long distances. Each hop reduces its transmission rate before the choke packet arrives at the source.\n5.  **Load Shedding**: Packets are discarded when the buffer is full. Intelligent discard policies are implemented based on packet importance, where less important or older packets are discarded first. Applications mark their packets to indicate their importance.\n6.  **Random Early Detection (RED)**: Packets are randomly discarded before the buffer becomes full to control congestion earlier. The router maintains a queue length, and when this length is exceeded, packets are discarded.\n7.  **Jitter Control**: Jitter, or inconsistent delay in data packets, is addressed by computing expected transit times for each hop. Routers check whether packets are ahead or behind schedule, holding early packets and expediting late packets to reduce jitter. Buffering at the receiver can eliminate jitter, but this is not always acceptable for real-time applications.\n"
    },
    {
      "id": 132,
      "module": "MODULE-2",
      "topic": "Load Shedding",
      "question": "Write a note on Load Shedding and flooding.",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, I can generate a note on Load Shedding, but I cannot provide specific information about flooding, as the context does not directly discuss it.\n\n**Load Shedding:**\n\nLoad shedding is a congestion control technique. It is defined as an approach of discarding packets when the buffer is full. The selection of packets to discard is an important task, and many times packets with less importance and old packets are discarded.\n\nTo implement an intelligent discard policy, applications must mark their packets to indicate to the network how important they are. Then, when packets have to be discarded, routers can first drop packets from the least important class, then the next most important class, and so on."
    },
    {
      "id": 133,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Write a note on multicast routing and routing in ad-hoc networks.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here is a discussion on multicast routing and routing in ad-hoc networks. Note that the notes do not explicitly discuss routing in ad-hoc networks but some details on routing protocols and related concepts may be applicable.\n\n**Multicast Routing**\n\nWhile the notes don't directly address multicast routing, some concepts are relevant:\n\n1.  **RSVP and Multicast (Module 3):** The Resource reSerVation Protocol (RSVP) was designed to support streaming multimedia, such as video and audio, over the Internet for both unicast and multicast communication. In multicast, users can join or leave a group dynamically.\n\n2.  **Efficiency Considerations (Module 3):** Due to changing group memberships in multicast, pre-reserving bandwidth for all receivers is impractical, especially for large audiences. RSVP addresses this by allowing receivers to send reservation messages toward the sender to request better reception and avoid congestion.\n\n3.  **Reverse Path Forwarding (Module 3):** RSVP leverages reverse path forwarding.  The reservation message travels up the spanning tree, and each router along the way reserves the required bandwidth. An end-to-end reservation is established if all routers can reserve the needed bandwidth; otherwise, the receiver is informed of the failure.\n\n4.  **Bandwidth Management (Module 3):** When making a reservation, a receiver can specify the source(s) and whether these sources are fixed or can be changed later. Routers use this to plan bandwidth efficiently, and reserved bandwidth is independent of the source in dynamic cases, allowing receivers to switch between sources without a new reservation.\n\n5.  **IGMP (Module 2):** The Internet Group Management Protocol (IGMP) is responsible for the management of IP multicast groups.\n\n**Routing in Ad-Hoc Networks**\n\nWhile the notes don't directly discuss routing in ad-hoc networks, there are general routing algorithm concepts that are applicable:\n\n1.  **Routing Algorithms Goal (Module 2):** The goal of all routing algorithms is to discover and use sink trees for all routers.\n\n2.  **Different routing algorithms(Module 2)**\n*   Optimality principle\n*   Shortest path algorithm\n*   Flooding\n*   Distance vector routing\n*   Link state routing\n*   Hierarchical Routing\n\n3.  **Distance Vector Routing (Module 2):** Distance vector routing involves each router maintaining a table that gives the best-known distance to each destination and which link to use to get there. Routers share information with each other to find the best path to a destination. Good news spreads quickly, while bad news travels slowly.\n\n4.  **Link State Routing (Module 2):** The primary problem is that the algorithm often took too long time to converge after the network topology changed. The idea behind link state routing is: Discover its neighbors and learn their network addresses, Set the distance or cost metric to each of its neighbors, Construct a packet telling all it has just learned, Send this packet to and receive packets from all other routers, Compute the shortest path to every other router. Then Dijkstra’s algorithm can be run at each router to find the shortest path to every other router.\n\n5.  **Flooding(Module 2)**:\n*Every incoming packet is sent out on every outgoing line except the one it arrived on\n*Generates vast numbers of duplicate packets, in fact, an infinite number unless some measures are taken to damp the process. \n*One such measure is to have a hop counter contained in the header of each packet, which is decremented at each hop, with the packet being discarded when the counter reaches zero.\n\n6.  **Hierarchical Routing (Module 2):** Routers are divided into regions. Each router knows the details of how to route packets to destinations within its own region but knows nothing about the internal structure of other regions. A two-level hierarchy may be insufficient; it may be necessary to group the regions into clusters, the clusters into zones, the zones into groups, and so on. Useful for very large networks.\n\nIn summary, while the notes provide general concepts on routing, the specifics of routing in ad-hoc networks are not detailed. Multicast routing is touched upon in the context of RSVP and bandwidth management."
    },
    {
      "id": 134,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Describe the steps involved in sending packets in mobile networks.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "NOT_FOUND",
      "answer": "Not supported by notes"
    },
    {
      "id": 135,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Explain the steps involved in the Link state algorithm.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The Link state algorithm, also known as Shortest Path First (SPF), involves a series of steps to enable routers to discover the network topology and compute the best paths. Based on the notes, here are the steps involved:\n\n1.  **Discover Neighbors and Learn Addresses:** When a router boots up, its first task is to identify its immediate neighbors. It achieves this by sending 'HELLO' packets on each of its point-to-point lines. The neighboring routers are expected to reply with their names.\n2.  **Setting Link Costs:** The link state algorithm requires each link to have a cost metric for finding the shortest paths. These costs to reach neighbors can be set automatically or configured by the network operator. Common practice involves setting the cost inversely proportional to the link's bandwidth. Additionally, if the network is geographically spread out, the delay of the links may be factored into the cost so that paths over shorter links are better choices.\n3.  **Building Link State Packets (LSPs):** After gathering the necessary information, each router constructs a packet containing the collected data. This packet includes the sender's identity, a sequence number, age, and a list of neighbors along with the cost to reach each neighbor.\n4.  **Distributing Link State Packets:** The algorithm employs flooding to distribute the link state packets to all routers in the network. To manage the flooding, each packet includes a sequence number that increments with each new packet sent. Routers keep track of seen (source router, sequence) pairs. When a new LSP arrives, it's checked against the list of already seen packets. If new, the packet is forwarded on all lines except the one it arrived on; duplicates are discarded. Packets with sequence numbers lower than the highest one seen are rejected, as the router possesses more recent data.\n5.  **Aging Link State Packets:** Include the age of each packet after the sequence number and decrement it once per second. When the age hits zero, the information from that router is discarded. The Age field is also decremented by each router during the initial flooding process, to make sure no packet can get lost and live for an indefinite period of time.\n6.  **Computing the New Routes:** Once a router has accumulated a complete set of link state packets, it can construct the entire network graph. Each link is represented twice, once for each direction. Dijkstra’s algorithm can be run locally to construct the shortest paths to all possible destinations. OSPF (Open Shortest Path First) is the other main link state protocol.\n7. **Run Dijkstra’s algorithm:** Once a router has received all Link State Packets (LSPs), it uses Dijkstra’s algorithm to compute the shortest path to every other router in the network. The resulting shortest-path tree is used to construct the routing table."
    },
    {
      "id": 136,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "Define quality of service in networking and explain the primary parameters which define the QOS.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "Quality of Service (QoS) in networking refers to the ability to provide different priorities to different applications, users, or data flows, or to guarantee a certain level of performance to a data flow. It ensures that specific requirements for reliability, delay, jitter, and bandwidth are met for various network applications.\n\nThe primary parameters which define the QoS, based on the notes, are:\n\n1.  **Reliability:** Ensuring data is delivered without errors or loss. This is crucial for applications where data integrity is paramount.\n2.  **Delay:** Minimizing the time it takes for data to travel from source to destination. Low delay is essential for real-time applications like VoIP and video conferencing.\n3.  **Jitter:** Reducing the variation in delay. Consistent delay is important for maintaining the quality of streaming media.\n4.  **Bandwidth:** Guaranteeing sufficient data transmission capacity. Adequate bandwidth is necessary for applications that require high data throughput, such as video streaming and large file transfers.\n\nThe notes also mention techniques for achieving good quality of service:\n\n*   **Overprovisioning:** Providing ample router capacity, buffer space, and bandwidth to facilitate smooth packet flow.\n*   **Buffering:** Storing flows on the receiving side to mitigate jitter, although this increases delay.\n*   **Traffic Shaping:** Regulating traffic flow at the server side to smooth out bursts, using algorithms like Leaky Bucket and Token Bucket.\n*   **Resource Reservation:** Reserving bandwidth, buffer space, and CPU cycles along a route to ensure capacity is available.\n*   **Admission Control:** Deciding whether to accept or reject a flow based on capacity and commitments.\n*   **Proportional Routing:** Splitting traffic over multiple paths based on their capacity.\n*   **Packet Scheduling:** Using algorithms like fair queueing to manage output lines and ensure fair allocation of resources.\n"
    },
    {
      "id": 137,
      "module": "MODULE-3",
      "topic": "Quality of Service",
      "question": "List and explain the techniques for achieving good quality of service.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, here are some techniques for achieving good quality of service:\n\n1.  **Overprovisioning:** Providing abundant router capacity, buffer space, and bandwidth to facilitate smooth packet flow. However, this is an expensive solution.\n\n2.  **Buffering:** Storing flows on the receiving side before delivery. This method reduces jitter by smoothing out variations in arrival times. Buffering increases delay, but it does not affect reliability or bandwidth.\nRefer notes for diagram describing buffering process to eliminate jitter in multimedia content playback.\n\n3.  **Traffic Shaping:** Regulating traffic before it enters the network to smooth out bursts and control congestion. Two traffic shaping algorithms mentioned are:\n\n    *   **Leaky Bucket (LB):** Enforces a constant output rate, regardless of input burstiness. It does nothing when the input is idle and discards packets if the bucket overflows. Implemented as a single-server queue with constant service time.\n    *   **Token Bucket (TB):** Allows output rate to vary based on burst size. The bucket holds tokens, and a host needs to capture and destroy a token to transmit a packet. Tokens are generated at a constant rate, allowing idle hosts to save tokens for later bursts. Packets transmitted only if tokens available.\n\n    LB discards packets while TB discards tokens. TB allows for large bursts by speeding up the output by accumulating tokens.\n\n4.  **Resource Reservation:** Reserving specific resources along a route to ensure availability. These resources can include:\n\n    *   Bandwidth\n    *   Buffer space\n    *   CPU cycles: Ensuring timely processing of each packet by preventing CPU overload.\n\n5.  **Admission Control:** Deciding whether to accept or reject a new flow based on the router's capacity and existing commitments. Accurately describing flows with specific parameters that can be negotiated using a flow specification.\n\n6.  **Packet Scheduling:** Using algorithms such as fair queueing where routers maintain separate queues for each output line and serve them in a round-robin fashion to ensure fair allocation of bandwidth. With n hosts competing, each host gets to send one out of every n packets.\n"
    },
    {
      "id": 138,
      "module": "MODULE-3",
      "topic": "Packet Scheduling",
      "question": "Explain why packet scheduling is required and describe the different strategies for packet scheduling.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Packet scheduling is required to manage the flow of data packets in a network and ensure quality of service (QoS). When multiple flows compete for network resources, scheduling algorithms determine the order in which packets are transmitted. This is crucial for optimizing network performance, minimizing delay and jitter, and fairly allocating bandwidth.\n\nDifferent strategies for packet scheduling include:\n\n1.  **Fair Queueing:** Routers maintain separate queues for each output line, one for each flow. When a line becomes idle, the router scans the queues round robin, taking the first packet on the next queue. With 'n' hosts competing for an output line, each host sends one out of every 'n' packets.\n\n2.  **Traffic Shaping:** This technique smooths out traffic before it enters the network, regulating the average rate and burstiness of data transmission. Two common traffic shaping algorithms are:\n\n    *   **Leaky Bucket:** Enforces a constant output rate, regardless of the input burstiness. It uses a bucket with a small hole; the outflow is constant when there is water in the bucket, and zero when empty. Excess packets are discarded if the bucket overflows.\n    *   **Token Bucket:** Allows the output rate to vary depending on the size of the burst. Tokens are added to the bucket at a fixed rate, and a host must capture and destroy a token to transmit a packet. Idle hosts can save tokens to send larger bursts later.\n\n3.  **Proportional Routing:** Aims to provide higher QoS by splitting traffic for each destination over multiple paths. This can be done equally or in proportion to the capacity of the outgoing links.\n\n4. **Resource Reservation:** Once a specific route for a flow is known, it becomes possible to reserve resources along that route to make sure the needed capacity is available. Three different kinds of resources can potentially be reserved: Bandwidth, Buffer space and CPU cycles.\n\nThese strategies ensure that network resources are managed effectively to meet the diverse requirements of different applications and users."
    },
    {
      "id": 139,
      "module": "MODULE-4",
      "topic": "Connection Establishment",
      "question": "Explain the three-way handshake protocol used for connection establishment and connection release with neat diagrams.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The three-way handshake protocol is used in connection-oriented transport services like TCP to establish a reliable connection between two hosts. It ensures that both sender and receiver are ready to communicate before data transmission begins.\n\n**Connection Establishment (Three-Way Handshake):**\n\n1.  **SYN (Synchronize):** The client sends a TCP segment with the SYN (synchronize) bit set to 1 to the server. This segment indicates the client's intention to establish a connection and includes the client's initial sequence number (x).\n2.  **SYN-ACK (Synchronize-Acknowledge):** The server, upon receiving the SYN segment, responds with a SYN-ACK segment. This segment has both the SYN bit and the ACK (acknowledgment) bit set. It acknowledges the client's sequence number (x) by including `x+1` in the acknowledgment number field, and it also includes the server's initial sequence number (y).\n3.  **ACK (Acknowledgment):** The client receives the SYN-ACK segment and sends an ACK segment back to the server. This segment acknowledges the server's sequence number (y) by including `y+1` in the acknowledgment number field. At this point, the connection is established, and data transfer can begin.\n\nRefer notes for diagram illustrating normal three-way handshake, including sequence numbers.\n\n**Connection Release:**\n\nTCP connections are full-duplex, which means that each direction of the connection is handled independently. Connection release involves a four-way handshake (can be reduced to three segments in some cases).\n\n1.  **FIN (Finish):** One of the parties (client or server) sends a TCP segment with the FIN (finish) bit set to 1, indicating that it has no more data to send.\n2.  **ACK (Acknowledgment):** The receiving party acknowledges the FIN segment by sending an ACK segment back to the sender.\n3.  **FIN (Finish):** After acknowledging the FIN, the receiving party (which is now also done sending data) sends a FIN segment to the original sender, indicating it is closing the connection in its direction.\n4.  **ACK (Acknowledgment):** The original sender acknowledges the FIN segment from the other party with an ACK segment. After receiving this ACK, the connection is fully closed.\n\nRefer notes for diagram illustrating four protocol scenarios for releasing a connection: normal three-way handshake, final ACK lost, response lost, and response lost with subsequent DRs lost.\n\nThere are two styles of terminating a connection: asymmetric release and symmetric release. Asymmetric release is the way the telephone system works: when one party hangs up, the connection is broken. Symmetric release treats the connection as two separate unidirectional connections and requires each one to be released separately."
    },
    {
      "id": 140,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Explain TCP IP socket programming.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "TCP/IP socket programming is a method to connect two nodes over a network to establish a means of communication between those two nodes. A node represents a computer or a physical device with an internet connection. \n\nA socket is the endpoint used for connecting to a node. The signals required to implement the connection between two nodes are sent and received using the sockets on each node respectively.\n\n**Berkeley Sockets:**\nThe socket primitives used in Berkeley UNIX for TCP are widely used for Internet programming. The nodes are divided into two types, server node and client node.\n\n**Server-Side Primitives:**\n\n1.  **SOCKET:** Creates a new endpoint and allocates table space for it within the transport entity. A successful call returns an ordinary file descriptor.\n2.  **BIND:** Assigns a network address to the newly created socket. Remote clients can then connect to it.\n3.  **LISTEN:** Allocates space to queue incoming calls in case several clients try to connect simultaneously.\n4.  **ACCEPT:** Blocks waiting for an incoming connection. When a TPDU asking for a connection arrives, the transport entity creates a new socket with the same properties as the original one and returns a file descriptor for it. ACCEPT returns a normal file descriptor, which can be used for reading and writing in the standard way, the same as for files.\n\n**Client-Side Primitives:**\n\n1.  **SOCKET:** A socket is created using the SOCKET primitive.\n2.  **CONNECT:** Blocks the caller and actively starts the connection process. When it completes (i.e., when the appropriate TPDU is received from the server), the client process is unblocked, and the connection is established.\n3.  Both sides can use **SEND** and **RECV** to transmit and receive data over the full-duplex connection. The standard UNIX **READ** and **WRITE** system calls can also be used if none of the special options of SEND and RECV are required.\n4.  Connection release with sockets is symmetric. When both sides have executed a **CLOSE** primitive, the connection is released.\n\n**Example:** The client node sends the connection signal and the server node receives the connection signal sent by the client node. The connection between a server and client node is established using the socket over the transport layer of the internet. After a connection has been established, the client and server nodes can share information between them using the read and write commands. After sharing of information is done, the nodes terminate the connection."
    },
    {
      "id": 141,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Explain the User Datagram Protocol with its header format.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "CONFIRMED",
      "answer": "The User Datagram Protocol (UDP) is a connectionless transport protocol that provides a way for applications to send encapsulated IP datagrams without establishing a connection. UDP transmits segments consisting of an 8-byte header followed by the payload. The UDP segment header contains the following fields:\n\n1.  **Source Port:** Identifies the sending port.\n2.  **Destination Port:** Identifies the receiving port. These ports serve to identify the endpoints within the source and destination machines.\n3.  **UDP Length:** Specifies the length of the UDP header and the data (payload) in bytes. This field includes the 8-byte header.\n4.  **UDP Checksum:** An optional 16-bit field used for error detection over the entire UDP segment (header and data). It includes the UDP header and the UDP data, padded out to an even number of bytes if necessary.\n\nWhen a UDP packet arrives, its payload is delivered to the process attached to the destination port. UDP does not guarantee reliable delivery, meaning packets may be lost, arrive out of order, or be duplicated. UDP is suitable for applications that require simple request-response communication with minimal overhead and can tolerate some degree of unreliability.\n\nRefer notes for diagrams of UDP Header Format."
    },
    {
      "id": 142,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "Explain how flow control and error control are achieved at the transport layer.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Flow control and error control are achieved at the transport layer through several mechanisms. \n\n1.  **Segmentation and Reassembly:** The transport layer receives data from the session layer and divides it into smaller units called segments. At the destination, the transport layer reassembles these segments back into the original message.\n\n2.  **Flow Control:** Flow control prevents a fast sender from overwhelming a slow receiver. Both the data link layer and transport layer use mechanisms like sliding window protocols for this purpose. The transport layer handles many simultaneous connections, so dynamic buffer allocation and more sophisticated flow control mechanisms are needed. The sender must buffer all outgoing Transport Protocol Data Units (TPDUs) until they are acknowledged, in case they need retransmission.\n\n3.  **Error Control:** The transport layer provides acknowledgment of successful data transmission and re-transmits data if an error is found. Checksums are used to detect errors.\n\n4.  **Sliding Window Protocol:** TCP uses the sliding window protocol for reliable delivery, implementing flow and error control. The sender sends segments and starts a timer. If an acknowledgment (ACK) arrives before the timeout, it's considered successful. If the timeout happens, TCP retransmits the segment.\n\n5.  **Retransmission:** If the sender feels that a sent packet is lost or corrupted, the packet needs to be retransmitted. Retransmission timers must be designed to prevent congestion and also able to optimize efficiency. TCP implements timeouts and retransmissions to ensure reliability.\n\n6.  **Acknowledgment Policy:** The receiver should send acknowledgments for N packets rather than sending acknowledgment for a single packet. The receiver should send an acknowledgment only if it has to send a packet or a timer expires.\n\n7.  **Sequencing:** TCP assigns a unique 32-bit sequence number to every byte, which helps in ordering and detecting lost or duplicate data.\n\n8.  **Checksum:** The checksum field in the TCP segment header is used for error detection.\n\n9.  **Selective Acknowledgments:** TCP includes selective acknowledgments to improve performance. The sliding window protocol helps implement both flow control and error control by managing the amount of data in transit and ensuring reliable delivery through acknowledgments and retransmissions.\n\n10. **Congestion Control:** TCP deals with congestion mainly by slowing down the data transmission rate, because reducing speed is the only way to avoid overwhelming the routers. TCP follows the idea similar to “conservation of packets,” meaning the sender should inject a new packet into the network only after an old packet has successfully left, helping avoid overload. Each TCP sender maintains two limits: one from the receiver (receiver window) and one based on network conditions (congestion window). The actual amount sent is the minimum of these two windows."
    },
    {
      "id": 143,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Explain TCP connection establishment.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "TCP connection establishment, also known as the three-way handshake, is a process used to establish a reliable connection between a client and a server. Here's a detailed explanation:\n\n1.  **Passive Open (Server Side):** The server passively waits for an incoming connection by executing the `LISTEN` and `ACCEPT` primitives. It specifies a specific source or accepts connections from any source.\n\n2.  **CONNECT Primitive (Client Side):** The client actively initiates the connection by executing a `CONNECT` primitive. It specifies the IP address and port number of the server to which it wants to connect.\n\n3.  **SYN Segment:** The `CONNECT` primitive triggers the client to send a TCP segment with the SYN (synchronize) bit set to 1 and the ACK (acknowledgment) bit set to 0. This segment indicates the client's intention to establish a connection and includes the client's initial sequence number (ISN).\n\n4.  **SYN-ACK Segment (Server Response):** Upon receiving the SYN segment, the server responds with a SYN-ACK segment. This segment has both the SYN bit and the ACK bit set to 1. It acknowledges the client's SYN segment by including the client's ISN + 1 in the acknowledgment number field. The server also includes its own initial sequence number (ISN) for the server-to-client communication.\n\n5.  **ACK Segment (Client Response):** The client, upon receiving the SYN-ACK segment, sends an ACK segment back to the server. The ACK segment acknowledges the server's SYN-ACK by including the server's ISN + 1 in the acknowledgment number field. The SYN bit is set to 0 in this segment.\n\n6.  **Connection Established:** After the client sends the ACK segment, the TCP connection is established. Both the client and server can now send and receive data.\n\n**Call Collision:**\n\n*   If two hosts simultaneously try to establish a connection, it results in a call collision. Both hosts send SYN segments to each other.\n*   Each host receives a SYN segment while simultaneously having sent a SYN segment. Each host transitions to the SYN-RECEIVED state.\n*   The connection is established after both hosts send ACK segments to acknowledge the SYN segments they received."
    },
    {
      "id": 144,
      "module": "MODULE-2",
      "topic": "Congestion Control Algorithms",
      "question": "Explain how congestion can be avoided in TCP.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 2,
      "sources": [
        "QB.pdf",
        "Question Bank - CN.docx"
      ],
      "importance": "MEDIUM",
      "notes_validation": "PARTIAL",
      "answer": "Congestion in TCP can be avoided using both open-loop and closed-loop congestion control mechanisms. Open-loop congestion control aims to prevent congestion before it occurs, while closed-loop congestion control reacts to congestion after it has been detected.\n\n**Open-Loop Congestion Control:**\n1.  **Retransmission Policy:** Setting appropriate retransmission timers is crucial. If a sender assumes a packet is lost and retransmits it too quickly, it can exacerbate congestion. Timers should be optimized to balance efficiency and congestion prevention.\n2.  **Window Policy:** Using a selective repeat window is preferable to a Go-back-N window. In Go-back-N, multiple packets are resent even if some were successfully received, increasing congestion. Selective repeat retransmits only the lost packets.\n3.  **Discarding Policy:** Routers can implement intelligent discarding policies, such as prioritizing the discarding of corrupted or less important packets to maintain the quality of service and prevent congestion from worsening.\n4.  **Acknowledgment Policy:** Instead of sending an acknowledgment for every packet, the receiver can send one acknowledgment for N packets. Also, acknowledgments can be sent only when the receiver has data to send or when a timer expires.\n5.  **Admission Policy:** Before establishing a virtual network connection, switches should check the resource requirements. If congestion is likely, the router should deny the connection to prevent further congestion.\n\n**Closed-Loop Congestion Control:**\n1.  **Backpressure:** A congested node stops receiving packets from upstream nodes, which may, in turn, cause those nodes to become congested and reject data from their upstream nodes. This is a node-to-node technique that propagates congestion information in the opposite direction of the data flow.\n2.  **Implicit Signaling:** The source infers congestion based on indirect signs, such as the absence of acknowledgments for sent packets. If a sender detects no ACKs for a while it assumes congestion and slows down.\n3.  **Explicit Signaling:** Congested nodes explicitly send signals to the source or destination to inform them about the congestion.\n *   **Forward Signaling:** A signal is sent in the direction of congestion to warn the destination, and the receiver adopts policies to prevent further congestion.\n *   **Backward Signaling:** A signal is sent in the opposite direction of the congestion to warn the source, and the source needs to reduce its transmission rate.\n\n**Congestion Control in Datagram Subnets**\n1.  **Warning Bit:** A router sets a bit in the packet header to warn the source when congestion is detected. This bit is copied and piggybacked on the ACK back to the sender, who then adjusts its transmission rate accordingly.\n2.  **Choke Packet:** A node sends a choke packet to the source to inform it about congestion, directly telling the source to slow down. An example is the ICMP Source Quench Packet.\n3.  **Hop-by-Hop Choke Packets:** To improve effectiveness over long distances, choke packets are sent hop-by-hop, requiring each hop to reduce its transmission even before the choke packet arrives at the source.\n\n**Other Techniques**\n*   **Random Early Detection (RED):** Routers randomly discard packets before the buffer is full to signal congestion early.\n*   **Load Shedding:** Discarding packets when the buffer is full, prioritizing less important or older packets for discarding. To implement an intelligent discard policy, applications must mark their packets to indicate to the network how important they are. Then, when packets have to be discarded, routers can first drop packets from the least important class, then the next most important class, and so on."
    },
    {
      "id": 145,
      "module": "MODULE-5",
      "topic": "Mail Services : Provide email service.",
      "question": "Describe the architecture of electronic mail and explain SMTP.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The architecture of electronic mail systems consists of two main subsystems: User Agents (UA) and Message Transfer Agents (MTA).\n\n1.  **User Agents (UA):**\n    *   A user agent is the software that users interact with directly to manage their email. Examples include Gmail, Outlook, Thunderbird, and mobile mail apps.\n    *   Functions of a User Agent:\n        *   Compose new messages\n        *   Read received messages\n        *   Reply to, forward, delete, and organize mail\n        *   Search mail folders and archives\n        *   Provide either a graphical interface (GUI) or a text-based/command -line interface\n    *   The process of sending a message from the user agent into the mail system for delivery is known as mail submission.\n\n2.  **Message Transfer Agents (MTA):**\n    *   A Message Transfer Agent, also called a mail server, is responsible for transferring email messages across the network from the sender to the recipient.\n    *   Examples include servers using SMTP (Simple Mail Transfer Protocol).\n    *   The MTA forwards messages through one or more intermediate servers until they reach the destination mail server, where the recipient can retrieve them using a user agent.\n\n**SMTP (Simple Mail Transfer Protocol):**\n\n*   SMTP handles message transfer between mail servers.\n*   Defined initially in RFC 821 and updated to RFC 5321.\n*   Provides delivery status and error reporting\n*   The formal protocol that defines the MTA client and server in the Internet is called Simple Mail Transfer Protocol (SMTP)\n*   SMTP uses commands and responses to transfer messages between an MTA client and an MTA server. The command is from an MTA client to an MTA server; the response is from an MTA server to the MTA client. Each command or reply is terminated by a two character (carriage return and line feed) end-of-line token.\n\n**Mail Transfer Phases:**\n\n1.  **Connection Establishment:** After a client has made a TCP connection to the well-known port 25, the SMTP server starts the connection phase. This phase involves the following three steps:\n    1.  The server sends code 220 (service ready) to tell the client that it is ready to receive mail. If the server is not ready, it sends code 421 (service not available).\n    2.  The client sends the HELO message to identify itself, using its domain name address. This step is necessary to inform the server of the domain name of the client.\n    3.  The server responds with code 250 (request command completed) or some other code depending on the situation.\n2.  **Message Transfer:** After connection has been established between the SMTP client and server, a single message between a sender and one or more recipients can be exchanged. This phase involves eight steps. Steps 3 and 4 are repeated if there is more than one recipient.\n    1.  The client sends the MAIL FROM message to introduce the sender of the message. It includes the mail address of the sender (mailbox and the domain name). This step is needed to give the server the return mail address for returning errors and reporting messages.\n    2.  The server responds with code 250 or some other appropriate code.\n    3.  The client sends the RCPT TO (recipient) message, which includes the mail address of the recipient.\n    4.  The server responds with code 250 or some other appropriate code.\n    5.  The client sends the DATA message to initialize the message transfer.\n    6.  The server responds with code 354 (start mail input) or some other appropriate message.\n    7.  The client sends the contents of the message in consecutive lines. Each line is terminated by a two-character end-of-line token (carriage return and line feed). The message is terminated by a line containing just one period.\n    8.  The server responds with code 250 (OK) or some other appropriate code.\n3.  **Connection Termination:** After the message is transferred successfully, the client terminates the connection. This phase involves two steps.\n    1.  The client sends the QUIT command.\n    2.  The server responds with code 221 or some other appropriate code."
    },
    {
      "id": 146,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Explain the server side communication in WWW architecture.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Server-side communication in WWW (World Wide Web) architecture involves several key aspects, according to the provided notes:\n\n1.  **Distributed Client-Server Service:** The WWW operates as a distributed client-server service where clients (browsers) access services from servers distributed across various locations (sites). Each site hosts one or more web pages.\n\n2.  **Web Pages:** Web pages can be simple (without links) or composite (containing links to other pages). Each page is a file with a unique name and address.\n\n3.  **Web Client (Browser):** A web client, or browser, interprets and displays web pages. It typically consists of a controller, client protocols, and interpreters.\n\n4.  **Controller:** The controller receives input from the user (keyboard or mouse) and uses client programs to access documents.\n\n5.  **Client Protocols:** These include HTTP (Hypertext Transfer Protocol) or FTP (File Transfer Protocol) for accessing documents.\n\n6.  **Interpreters:** Interpreters, such as HTML, Java, or JavaScript, display the document on the screen based on its type.\n\n7.  **Web Server:** The web server stores web pages and sends the corresponding document to the client upon request.\n\n8.  **Caching:** To enhance efficiency, servers often store frequently requested files in a cache in memory for faster access.\n\n9.  **Multi-threading/Multi-processing:** Servers can use multi-threading or multi-processing to handle multiple requests simultaneously, improving performance.\n\n10. **Uniform Resource Locator (URL):** Web pages are identified using URLs, which include the protocol, host, port (if non-standard), and path to the file on the server.\n\n11. **Web Documents:** These can be static or dynamic. Static documents are fixed-content files stored on the server. Dynamic documents are created by the server in response to a request, often using application programs or scripts.\n\n12. **AJAX (Asynchronous JavaScript and XML):** AJAX is used to create responsive web applications with seamless access to data on remote servers. It combines HTML, CSS, DOM, XML, asynchronous data retrieval, and JavaScript.\n\n13. **HTTP (Hypertext Transfer Protocol):** HTTP is the application-layer protocol at the core of the Web, defining how clients request and servers transfer web pages. It uses TCP as its transport protocol.\n\n14. **Non-Persistent and Persistent Connections:** HTTP can use non-persistent connections (one TCP connection per request/response) or persistent connections (keeping the TCP connection open for multiple requests/responses).\n\n15. **Web Caching (Proxy Server):** Web caches satisfy HTTP requests on behalf of origin web servers, storing copies of recently requested objects to reduce network load and improve response times. Browsers can be configured to direct requests to the web cache.\n\n16. **Web Search:** Web search engines use web crawlers to traverse the web, indexing pages to allow users to search for information. Search engines rank pages based on factors like the number of links pointing to them.\n\nRefer to notes for any diagrams. "
    },
    {
      "id": 147,
      "module": "MODULE-5",
      "topic": "Electronic Mail",
      "question": "Describe MIME (Multipurpose Internet Mail Extensions) along with its header information.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "MIME (Multipurpose Internet Mail Extensions) allows non-ASCII data to be sent through email. It transforms non-ASCII data at the sender's site to NVT ASCII data and delivers it to the client MTA (Message Transfer Agent) to be sent through the Internet. At the receiving site, the message is transformed back to the original data. MIME defines five header fields to define the transformation parameters:\n\n1.  **MIME-Version:**  Defines the version of MIME used (currently 1.1).\n2.  **Content-Type:** Defines the type of data used in the body of the message. The content type and subtype are separated by a slash. Depending on the subtype, the header may contain other parameters. MIME allows seven different types of data.\n3.  **Content-Transfer-Encoding:** Defines the method used to encode the messages into 0s and 1s for transport. The five types of encoding methods are listed in a table in the notes (Refer notes for table).\n4.  **Content-ID:** Uniquely identifies the whole message in a multiple message environment.\n5.  **Content-Description:** Defines whether the body is image, audio, or video."
    },
    {
      "id": 148,
      "module": "MODULE-5",
      "topic": "The World Wide Web",
      "question": "Explain the parts of the Web model with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "QB.pdf"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The Web model is a distributed client-server service where a client (browser) accesses services from servers distributed across many locations (sites). Each site contains one or more web pages, which can be simple (no links) or composite (with links to other pages). The key ideas are distributed content and linked resources using hypertext, now extended to hypermedia (text, images, audio, video).\n\nRefer notes for diagram. The diagram should illustrate:\n1.  **Web Client (Browser):** Consists of a controller (handles input), client protocols (HTTP, FTP), and interpreters (HTML, Java, JavaScript).\n2.  **Web Server:** Stores web pages and uses caching to improve efficiency. Implements multithreading or multiprocessing.\n\n**Components of the Web Model:**\n\n1.  **Web Client (Browser):**\n *   **Controller:** Receives input from keyboard or mouse and uses client programs to access documents.\n *   **Client Protocols:** Uses protocols like HTTP or FTP.\n *   **Interpreters:** Uses interpreters like HTML, Java, or JavaScript to display the document on the screen.\n\n2.  **Web Server:**\n*   Stores web pages. Each time a request arrives, the corresponding document is sent to the client.\n*   Improves efficiency by storing requested files in a cache in memory.\n*   Can become more efficient through multithreading or multiprocessing to answer more than one request at a time.\n\n3.  **Uniform Resource Locator (URL):** A unique identifier for a web page, consisting of:\n *   **Protocol:** The method to reach the web page (e.g., HTTP, FTP).\n*   **Host:** The IP address or domain name where the web page is stored.\n*   **Port:** The specific entry point on the server (e.g., 80 for HTTP, 443 for HTTPS).\n*   **Path:** The exact location of the web page file on the server.\n\n4. **Web Documents:**\n* Static Documents: Fixed-content documents stored on a server. Prepared using HTML, XML, XSL, and XHTML.\n* Dynamic Documents: Created by a web server whenever a browser requests them. The server runs an application program or script, and the results are returned to the browser."
    },
    {
      "id": 150,
      "module": "MODULE-1",
      "topic": "Network hardware",
      "question": "Differentiate between LAN, WAN, and MAN, and explain the categories of network hardware based on scale.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "LAN (Local Area Network), MAN (Metropolitan Area Network), and WAN (Wide Area Network) are categories of network hardware distinguished by their size and geographical coverage.\n\n1.  **LAN (Local Area Network):**\n *   Privately-owned networks within a single building or campus.\n *   Size: Up to a few kilometers.\n *   Commonly used to connect personal computers and workstations in offices and factories.\n *   Key characteristics: size, transmission technology, and topology.\n\n2.  **MAN (Metropolitan Area Network):**\n *   Covers a city.\n *   Larger than a LAN but smaller than a WAN.\n *   Example: Cable television networks in many cities.\n *   Originated from community antenna systems and evolved to offer two-way Internet service.\n\n3.  **WAN (Wide Area Network):**\n *   Covers a large geographical area, often a country or continent.\n *   Hosts are connected by a communication subnet comprising transmission lines and switching elements.\n *   Transmission lines move bits between machines.\n *   Switching elements are specialized computers connecting three or more transmission lines.\n *   Designed for high-latency, large-scale data transfer.\n *   Examples: Internet, global corporate networks.\n\n**Categories of Network Hardware Based on Scale (Size/Coverage):**\n\nThe notes also mention other types of networks based on scale/hardware:\n\n1.  **Wireless Networks:**\n *   Transmit data using radio waves.\n *   Enable mobility.\n *   Includes Wi-Fi, Bluetooth, and cellular networks.\n\n2.  **Home Networks:**\n *   Connect multiple household devices.\n *   Allow devices to communicate and access the Internet.\n *   Focus on ease of use, high performance, affordability, and security.\n\n3.  **Internetwork:**\n *   Combination of two or more networks (LAN, MAN, WAN).\n *   Uses routers, gateways, and switches to connect and manage traffic.\n *   Supports similar and different network technologies."
    },
    {
      "id": 151,
      "module": "MODULE-1",
      "topic": "Network software",
      "question": "Write a note on the Internetworking Protocol Hierarchy List and explain the design issues in network software design.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The Internetworking Protocol Hierarchy is structured in layers, each built upon the one below it. Each layer offers services to the higher layers, hiding the implementation details and acting like a virtual machine. Layer n communicates with layer n on another machine using agreed-upon rules called the layer n protocol. A protocol is an agreement between communicating parties on how communication should proceed. Entities in corresponding layers on different machines are called peers.\n\nHere are the design issues in network software design:\n\n1.  **Addressing:** Every layer requires a mechanism to identify senders and receivers. A process needs to specify who it wants to communicate with, which necessitates some form of addressing.\n2.  **Data Transfer Rules:** Systems vary in their data transfer capabilities; some allow only one-way communication, while others support two-way communication. Protocols must define the number of logical channels a connection has and their respective priorities.\n3.  **Error Control:** Physical communication circuits are not perfect; thus, error-detecting or error-correcting codes are essential. Both ends of the connection must agree on the error control method used.\n4.  **Sequencing:** Since not all channels maintain message order, protocols must manage proper reassembly. Numbering pieces helps, but handling out-of-order arrivals is still necessary.\n5.  **Flow Control:** This prevents a fast sender from overwhelming a slow receiver. Solutions include feedback from the receiver to the sender or limiting the sender’s transmission rate.\n6.  **Message Size Handling:** Long messages need to be disassembled, transmitted, and reassembled. Small messages can be combined into a single larger one for efficiency.\n7.  **Multiplexing:** A single connection may carry multiple unrelated conversations. Multiplexing and demultiplexing should be transparent to the layers above.\n8.  **Routing:** When multiple paths exist, a route must be chosen between the source and destination. Routing decisions can be split between high-level policy and low-level traffic-based choices.\n9.  **Channel Priorities:** Many networks offer separate channels for normal and urgent data, allowing urgent information to be transmitted without waiting for normal data."
    },
    {
      "id": 152,
      "module": "MODULE-1",
      "topic": "Reference Models",
      "question": "Differentiate between TCP and UDP. With a neat diagram, explain the OSI reference model and the functions of each layer.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Differentiating between TCP and UDP:\n\n1.  **TCP (Transmission Control Protocol):** It is a connection-oriented protocol designed to provide a reliable end-to-end byte stream over an unreliable network. TCP adapts dynamically to the properties of the internetwork and is robust in the face of many kinds of failures.\n2.  **Connection-Oriented:** TCP is connection-oriented, requiring a three-way handshake (SYN, SYN-ACK, ACK) to establish a connection before data transfer can begin.\n3.  **Reliability:** TCP provides reliability through retransmissions, ensuring that lost packets are retransmitted.\n4.  **Error Control:** TCP uses checksums to detect errors and retransmits damaged segments.\n5.  **Flow Control:** TCP implements flow control using a sliding window protocol to prevent a fast sender from overwhelming a slow receiver.\n6.  **Congestion Control:** TCP incorporates congestion control mechanisms (e.g., slow start, congestion avoidance) to manage network congestion by adjusting the transmission rate.\n7.  **UDP (User Datagram Protocol):** It is a connectionless protocol that provides a way for applications to send encapsulated IP datagrams without having to establish a connection.\n8.  **Connectionless:** UDP is connectionless, meaning it does not establish a dedicated connection before sending data.\n9.  **Unreliable Service:** UDP does not provide error control, making it an unreliable service. It's suitable for processes that require simple request-response communication with little concern for flow and error control, or processes with internal flow- and error-control mechanisms.\n10. **Multicasting:** UDP is a suitable transport protocol for multicasting, with multicasting capability embedded in the UDP software.\n\nExplanation of the OSI Reference Model and Functions of Each Layer: Refer notes for diagram\nThe OSI model has seven layers:\n\n1.  **Physical Layer (Layer 1):** Responsible for the actual physical connection between devices. It contains information in the form of bits. This layer gets the signal received and converts it into 0s and 1s and sends them to the Data Link layer. Functions include:\n    *   Bit synchronization: Providing synchronization of bits.\n    *   Bit rate control: Defining the transmission rate.\n    *   Physical topologies: Specifying how devices/nodes are arranged in a network.\n    *   Transmission mode: Defining how data flows between connected devices (Simplex, half-duplex, full-duplex).\n2.  **Data Link Layer (Layer 2):** Responsible for node-to-node delivery of messages. Ensures error-free data transfer from one node to another over the physical layer. Divides packets from the Network layer into frames. Functions include:\n    *   Framing: Providing a way for a sender to transmit meaningful bits to the receiver.\n    *   Physical addressing: Adding MAC addresses of the sender and/or receiver in the header of each frame.\n    *   Error control: Detecting and retransmitting damaged or lost frames.\n    *   Flow Control: Coordinating the amount of data sent before receiving an acknowledgment.\n    *   Access control: Determining which device has control over the channel.\n3.  **Network Layer (Layer 3):** Works for the transmission of data from one host to another located in different networks. It also takes care of packet routing. The sender & receiver’s IP addresses are placed in the header by the network layer. Functions include:\n    *   Routing: Determining the suitable route from source to destination.\n    *   Logical Addressing: Defining an addressing scheme to uniquely identify each device on the Internet.\n4.  **Transport Layer (Layer 4):** Provides services to the application layer and takes services from the network layer. Responsible for End to End Delivery of the complete message. Also provides acknowledgment of successful data transmission and re-transmits data if an error is found. Functions include:\n    *   Segmentation and Reassembly: Breaking messages into smaller units (segments) and reassembling them at the destination.\n    *   Service Point Addressing: Including service point address or port address in the transport layer header to deliver the message to the correct process.\n    *   Connection-Oriented Service: including Connection Establishment, Data Transfer and Termination/disconnection\n    *   Connectionless service: including Data Transfer.\n5.  **Session Layer (Layer 5):** Responsible for the establishment of connection, maintenance of sessions, authentication, and security. Functions include:\n    *   Session establishment, maintenance, and termination: Allowing two processes to establish, use, and terminate a connection.\n    *   Synchronization: Identifying errors and re-synchronizing data properly.\n    *   Dialog Controller: Allowing two systems to start communication in half-duplex or full-duplex.\n6.  **Presentation Layer (Layer 6):** Also called the Translation layer. Extracts data from the application layer and manipulates it as per the required format for network transmission. Functions include:\n    *   Translation: For example, ASCII to EBCDIC.\n    *   Encryption/Decryption: Translating data into another form or code for security.\n    *   Compression: Reducing the number of bits transmitted on the network.\n7.  **Application Layer (Layer 7):** Implemented by network applications. Serves as a window for application services to access the network and for displaying received information to the user. Functions include:\n    *   Network Virtual Terminal: Allowing users to log on to a remote host.\n    *   FTAM- File transfer access and management: Accessing files in a remote host, retrieving files, and managing/controlling files from a remote computer.\n    *   Mail Services: Providing email service.\n    *   Directory Services: Providing distributed database sources and access for global information about various objects and services.\n\nThe diagram should depict the seven layers of the OSI model, with arrows indicating the flow of data between adjacent layers. Each layer should be labeled with its name and a brief description of its function, similar to the above listed functions."
    },
    {
      "id": 153,
      "module": "MODULE-2",
      "topic": "Routing algorithms",
      "question": "Define routing, write the difference between routing and forwarding, describe the optimality principle, and solve the problem to find the shortest path from A to D using Dijkstra’s algorithm, given a graph.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "## Routing\n\nRouting, in the context of the network layer, is the process of directing packets from a source machine to a destination machine. It involves two key processes within a router:\n\n1.  **Forwarding:** This handles each packet as it arrives, looking up the outgoing line to use for it in the routing table.\n2.  **Routing Algorithm:** This is responsible for filling in and updating the routing tables. The algorithm should possess properties such as correctness, simplicity, robustness, stability, fairness, and optimality.\n\n## Routing vs. Forwarding\n\n| Feature           | Routing                                                                                                                                           | Forwarding                                                                      |\n| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |\n| **Function**      | Updating routing tables                                                                                                                      | Packet handling using the routing table                           |\n| **Scope**         | Network-wide                                                                                                                                    | Router-specific, packet by packet                                                 |\n| **Time scale**    | Slower, reacting to network changes                                                                                                          | Faster, for each incoming packet                                                  |\n\n## Optimality Principle\n\nThe optimality principle states that if router `J` is on the optimal path from router `I` to router `K`, then the optimal path from `J` to `K` also falls along the same route. The goal of all routing algorithms is to discover and use the sink trees for all routers. A sink tree is a set of optimal routes from all sources to a given destination, forming a tree rooted at the destination.\n\n## Shortest Path Routing with Dijkstra's Algorithm\n\nDijkstra’s algorithm is used to find the shortest path between nodes in a graph. Here's how it works, applied to finding the shortest path from A to D:\n\n1.  **Initialization**:\n    *   `N = {A}` (A is the root node)\n    *   For all nodes `v`:\n        *   If `v` is adjacent to `A`, then `D(v) = c(A, v)` where `c(A, v)` is the cost from A to v.\n        *   Else `D(v) = infinity`\n\n2.  **Loop**:\n    *   Find `w` not in `N` such that `D(w)` is a minimum.\n    *   Add `w` to `N`.\n    *   Update `D(v)` for all `v` adjacent to `w` and not in `N`:\n        *   `D(v) = min(D(v), D(w) + c(w, v))`\n    *   Repeat until all nodes are in `N`.\n\nRefer to the notes for a visual depiction or graph example to follow this algorithm to solve for the shortest path. The algorithm iteratively explores the graph, updating shortest path estimates until the shortest path from the starting node to all other nodes is known. The shortest path from A to D is determined by the final value of D(D) after the algorithm completes.\n"
    },
    {
      "id": 154,
      "module": "MODULE-2",
      "topic": "Link state Routing",
      "question": "Explain the steps involved in the Link State algorithm.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Based on the provided notes, the steps involved in the Link State algorithm, particularly in the context of routing, are as follows:\n\n1.  **Discover Neighbors and Learn Network Addresses:** A router's initial task upon booting is to identify its immediate neighbors. This is achieved by sending a special HELLO packet on each of its point-to-point lines. The neighboring routers are expected to respond with a packet containing their names or network addresses.\n\n2.  **Set Link Costs:** The Link State Routing algorithm requires assigning a cost or distance metric to each link. These costs can be set automatically (e.g., inversely proportional to the link's bandwidth) or manually by the network operator. Factors like link delay may also be included in the cost calculation, favoring shorter paths.\n\n3.  **Build Link State Packets (LSPs):** After gathering necessary information, each router constructs a Link State Packet (LSP) containing its identity, a sequence number, an age parameter, and a list of its neighbors along with the cost to reach each neighbor.\n\n4.  **Distribute Link State Packets (Flooding):** The LSPs are distributed to all other routers in the network using a flooding mechanism. To control the flooding, each packet includes a sequence number that increments with each new packet sent. Routers track the source router and sequence number of received packets to avoid forwarding duplicates. New packets are forwarded on all lines except the one they arrived on, while duplicates or outdated packets (based on sequence number) are discarded.\n\n5.  **Age Parameter:** Each LSP includes an age field that is decremented over time. When the age reaches zero, the information from that router is considered invalid and is discarded. This ensures that outdated information does not persist indefinitely in the network.\n\n6.  **Compute New Routes (Dijkstra's Algorithm):** Once a router has collected a complete set of LSPs, it can construct a full network graph. Each link is represented twice to account for both directions. Dijkstra’s algorithm is then run locally to calculate the shortest paths to all possible destinations.\n\n7.  **OSPF (Open Shortest Path First):**  The notes mention OSPF as another main link-state protocol."
    },
    {
      "id": 155,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Explain Border Gateway Protocol (BGP) and Open Shortest Path First (OSPF).",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "Border Gateway Protocol (BGP):\n\n1.  **Function:** BGP is used to exchange routing information between different Autonomous Systems (ASes) on the Internet. It is an Exterior Gateway Protocol (EGP), operating between organizations or administrative domains, not within them.\n2.  **Policy-Based Routing:** BGP manages routing between organizations that have their own policies, taking into account political, economic, and security considerations when selecting routes between different networks.\n3.  **Autonomous Systems:** From a BGP router’s perspective, the Internet is a graph of multiple ASes interconnected through border routers. Two ASes are connected if there is a physical or logical link between their border routers.\n4.  **Network Categories:** BGP networks are categorized into stub, multiconnected, and transit networks.\n\t*   Stub networks have a single connection to another AS and cannot carry traffic for other networks.\n\t*   Multiconnected networks have multiple external connections but do not allow transit traffic.\n\t*   Transit networks allow data from other networks to pass through, often for commercial reasons.\n5.  **TCP Connections:** BGP routers exchange routing information using TCP connections, ensuring reliable delivery and error-free communication.\n6.  **Path Advertisement:** Unlike distance vector protocols, BGP advertises the entire AS path to a destination, aiding in loop detection.\n7.  **Scoring System:** BGP uses a scoring system based on local administrative preferences to select the best path. Routes violating policy are assigned infinite cost and discarded.\n8.  **Loop Detection:** BGP routers can detect loops due to their knowledge of complete paths, avoiding the count-to-infinity problem.\n\nOpen Shortest Path First (OSPF):\n\n1.  **Purpose:** OSPF is an Interior Gateway Protocol (IGP) used for routing within an Autonomous System (AS). It replaced RIP due to its limitations in larger networks.\n2. **Requirements:** OSPF needed to be publicly available, support various distance metrics, adapt dynamically to topology changes, support routing based on type of service, perform load balancing, support hierarchical systems, and provide some level of security.\n3.  **Area Structure:** OSPF divides the network into areas, with a backbone area (area 0) connecting all other areas. Routers within an area exchange information about their neighbors and costs.\n4.  **Router Classes:**\n\t *Internal routers: Wholly within one area.\n\t *Area border routers: Connect two or more areas.\n\t *Backbone routers: Are on the backbone.\n\t *AS boundary routers: Talk to routers in other ASes.\n5. **Link State Advertisement**: Using flooding, each router informs all the other routers in its area of its neighbors and costs.\n6.  **Shortest Path Calculation:** OSPF represents the network as a directed graph, using link costs to determine the most efficient routes. Each router constructs a graph for its area and computes the shortest path using Dijkstra's algorithm.\n7.  **Routing Types:** OSPF supports intra-area (within an area), interarea (between areas), and inter-AS (between different autonomous systems) routing."
    },
    {
      "id": 156,
      "module": "MODULE-4",
      "topic": "The Internet Transport Protocols (UDP and TCP)",
      "question": "Differentiate between TCP and UDP, and explain the TCP segment header with a neat diagram.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are the two main transport layer protocols in the Internet protocol suite. They serve different purposes and have distinct characteristics.\n\n**Differences between TCP and UDP:**\n\n1.  **Connection-oriented vs. Connectionless:** TCP is connection-oriented, requiring a three-way handshake (SYN, SYN-ACK, ACK) to establish a connection before data transfer. UDP is connectionless, sending data without establishing a connection.\n2.  **Reliability:** TCP provides reliable data transfer through acknowledgments, retransmissions, and error checking. UDP is unreliable, offering no guarantee of delivery or order.\n3.  **Ordering:** TCP ensures data is delivered in the correct order using sequence numbers. UDP does not guarantee the order of delivery.\n4.  **Flow Control:** TCP implements flow control mechanisms (e.g., sliding window) to prevent a fast sender from overwhelming a slow receiver. UDP does not have built-in flow control.\n5.  **Congestion Control:** TCP includes congestion control algorithms (e.g., slow start, congestion avoidance) to manage network congestion and avoid packet loss. UDP does not have congestion control.\n6.  **Overhead:** TCP has higher overhead due to connection establishment, acknowledgments, and other control mechanisms. UDP has lower overhead, making it suitable for applications where speed is more important than reliability.\n7.  **Use Cases:** TCP is suitable for applications requiring reliable data transfer, such as web browsing (HTTP), file transfer (FTP), and email (SMTP). UDP is suitable for applications where some data loss is acceptable, such as streaming media, online gaming, and DNS queries.\n8.  **Byte Stream vs. Datagram:** TCP provides a byte stream service, treating data as a continuous flow of bytes. UDP provides a datagram service, where data is sent in discrete packets.\n\n**TCP Segment Header:**\n\nThe TCP segment header is a 20-byte (minimum) header that precedes the data payload in a TCP segment. Key fields in the TCP segment header include:\n\n1.  **Source Port (16 bits):** The port number of the sending application.\n2.  **Destination Port (16 bits):** The port number of the receiving application.\n3.  **Sequence Number (32 bits):** The sequence number of the first byte of data in the segment. TCP assigns a unique 32-bit sequence number to every byte. This helps in ordering, reliability, and detecting lost or duplicate data.\n4.  **Acknowledgment Number (32 bits):** The sequence number of the next byte expected from the other party, providing acknowledgment of received data. When the ACK bit is set to 1, this field is valid.\n5.  **TCP Header Length (4 bits):** Indicates the length of the TCP header in 32-bit words. This also accounts for options, if any.\n6.  **Flags (6 bits):** Control bits that indicate the purpose and status of the segment. Important flags include:\n    *   **SYN (Synchronize):** Used to initiate a connection.\n    *   **ACK (Acknowledgment):** Indicates acknowledgment of received data.\n    *   **FIN (Finish):** Used to terminate a connection.\n    *   **RST (Reset):** Used to reset a connection.\n    *   **PSH (Push):** Indicates that the data should be pushed to the application immediately.\n    *   **URG (Urgent):** Indicates that the Urgent pointer field is in use.\n7.  **Window Size (16 bits):** Specifies the size of the receive window, indicating the amount of data the sender can transmit without receiving an acknowledgment. It implements the sliding window protocol.\n8.  **Checksum (16 bits):** A checksum field is also provided for extra reliability. Used for error detection in the header and data.\n9.  **Urgent Pointer (16 bits):** Points to the end of urgent data, if the URG flag is set.\n10. **Options (Variable):** Optional fields for additional features, such as Maximum Segment Size (MSS).\n\n**Refer notes for diagram:** The TCP segment header diagram should show each field in the header with its size and description. It should visually represent the structure of the TCP header."
    },
    {
      "id": 157,
      "module": "MODULE-4",
      "topic": "Elements of Transport Protocols",
      "question": "Explain how flow control and error control are achieved at the transport layer and describe TCP connection establishment.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "At the transport layer, flow control prevents a fast sender from overwhelming a slow receiver. Error control ensures reliable data transmission by providing acknowledgment of successful data transmission and re-transmitting data if errors are found.\n\nTCP Connection Establishment:\n\n1.  To establish a TCP connection, one side (the server) passively waits for an incoming connection by executing the LISTEN and ACCEPT primitives.\n2.  The other side (the client) executes a CONNECT primitive, specifying the IP address and port to which it wants to connect. The CONNECT primitive sends a TCP segment with the SYN bit on and ACK bit off and waits for a response.\n3.  The connection establishment in TCP is called a three-way handshake.  The server program tells its TCP that it is ready to accept a connection. This request is called a passive open.\n4.  TCP can now start the three-way handshaking process. Refer notes for diagram showing TCP Connection establishment in the normal case and call collision.\n5.  Three-way handshake establishment protocol does not require both sides to begin sending with the same sequence number, so it can be used with synchronization methods other than the global clock method."
    },
    {
      "id": 158,
      "module": "MODULE-5",
      "topic": "HTTP (Hypertext Trans fer Protocol), Web Search",
      "question": "Describe the Hyper Text Transfer Protocol, give the architecture of electronic mail, and explain SMTP.",
      "marks": 8,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "The Hypertext Transfer Protocol (HTTP) is the application-layer protocol at the heart of the Web. It is implemented in two programs: a client program and a server program. The client program and server program, executing on different end systems, talk to each other by exchanging HTTP messages. HTTP defines the structure of these messages and how the client and server exchange the messages. HTTP uses TCP as its underlying transport protocol. The HTTP client first initiates a TCP connection with the server. Once the connection is established, the browser and the server processes access TCP through their socket interfaces.\n\nThe architecture of electronic mail systems consists of two main subsystems:\n1.  **User Agents (UA):** A user agent is the software that users interact with directly to manage their email. Examples include Gmail, Outlook, Thunderbird, and mobile mail apps. Functions of a User Agent include composing new messages, reading received messages, replying to, forwarding, deleting, and organizing mail, and searching mail folders and archives.\n2.  **Message Transfer Agents (MTA):** A Message Transfer Agent, also called a mail server, is responsible for transferring email messages across the network from the sender to the recipient. Examples include servers using SMTP (Simple Mail Transfer Protocol). The MTA forwards messages through one or more intermediate servers until they reach the destination mail server, where the recipient can retrieve them using a user agent. Refer notes for diagram 7-7\n\nSMTP (Simple Mail Transfer Protocol) handles message transfer between mail servers, defined initially in RFC 821 and updated to RFC 5321. It provides delivery status and error reporting. The process of transferring a mail message occurs in three phases: connection establishment, mail transfer, and connection termination. After a client has made a TCP connection to the well-known port 25, the SMTP server starts the connection phase. In the message transfer phase, a single message between a sender and one or more recipients can be exchanged, and the content of the message is sent in consecutive lines. After the message is transferred successfully, the client terminates the connection."
    },
    {
      "id": 159,
      "module": "MODULE-5",
      "topic": "The Application Layer",
      "question": "Write a note on URL, describe MIME - The Multipurpose Internet Mail Extensions along with its header information.",
      "marks": 5,
      "syllabus_status": "IN_SYLLABUS",
      "repeat_count": 1,
      "sources": [
        "Question Bank - CN.docx"
      ],
      "importance": "LOW",
      "notes_validation": "CONFIRMED",
      "answer": "A Uniform Resource Locator (URL) is a unique identifier for a web page, distinguishing it from others. Four key components define a web page's location:\n\n1.  **Protocol:** Specifies the method to access the web page, typically HTTP (Hypertext Transfer Protocol) for web pages or FTP (File Transfer Protocol) for other access types.\n2.  **Host:** Indicates the storage location using either an IP address (e.g., 64.23.56.17) or a domain name (e.g., example.com), making server identification easier.\n3.  **Port:** Designates a specific entry point on the server, like port 80 for HTTP or port 443 for HTTPS. Standard ports usually don't need explicit mention.\n4.  **Path:** Provides the precise location of the web page file on the server, including folders and the file name (e.g., /folder1/folder2/filename), guiding the server to the exact file.\n\n**MIME (Multipurpose Internet Mail Extensions):**\n\nMIME is a supplementary protocol that enables the transmission of non-ASCII data via email, overcoming the limitations of the original 7-bit ASCII format. It transforms non-ASCII data into NVT ASCII data at the sender's end for Internet transmission and converts it back to the original format at the receiver's end.\n\n**MIME Headers:**\n\nMIME defines several headers to specify transformation parameters, added to the email header section:\n\n*   **MIME-Version:** Indicates the MIME version in use, currently 1.1.\n*   **Content-Type:** Defines the data type in the message body, with a content type and subtype separated by a slash. Parameters may vary based on the subtype. Seven different data types are available (refer to notes for table).\n*   **Content-Transfer-Encoding:** Specifies the encoding method for transporting messages as 0s and 1s. Five encoding methods exist (refer to notes for table).\n*   **Content-ID:** Uniquely identifies the entire message in a multiple-message environment.\n*   **Content-Description:** Indicates whether the body is an image, audio, or video."
    }
  ]
}
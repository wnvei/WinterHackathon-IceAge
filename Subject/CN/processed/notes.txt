
================================================================================
FILE: module 1.pptx
================================================================================

--- Slide 1 ---
Computer NetworksIntroduction

--- Slide 2 ---
Course Outcomes
Identify various uses of networks, Design issue of network layers, and summarize its quality-of-service requirements. 
Illustrate various routing and congestion control algorithms. 
Outline the internet protocol’s structure and demonstrate the working of internet protocols. 
Identify transport layer services and show the working of transport layer protocols. 
Appraise application layer protocols. 
Apply modern networking tools. 


--- Slide 3 ---

Module-1 Introduction(08 hours)	
Uses of computer networks: Business Applications, Home Application, Mobile Users, Social Issues; Network hardware: Local Area Networks, Metropolitan Area Networks, Wide Area Networks, Wireless Networks, Home Networks, Internetworks; Network software: Protocol Hierarchies, Design Issues for the Layers, Connection-Oriented and Connectionless Services, Service Primitives. Reference Models: OSI Reference Model and TCP/IP Reference Model.
Chapter 1: 1.1-1.3, 1.4.1, 1.4.2	


--- Slide 4 ---
Computer Networks-definition
A network is a set of devices (often referred to as nodes) connected by communication links. A node can be a computer, printer, or any other device capable of sending and/or receiving data generated by other nodes on the network.
A computer network is a set of computers connected together for the purpose of sharing resources. Ex: Internet. 
“Computer Network” to mean a collection of autonomous computers interconnected by a single technology. Two computers are said to be interconnected if they are able to exchange information.
When we communicate, we are sharing information. This sharing can be local or remote. 
Local communication between individuals, usually occurs face to face
Remote communication takes place over distance


--- Slide 5 ---
Performance:
Number of users
Type of transmission medium
Hardware
Software
Reliability
Frequency of failure
Recovery time of a network after a failure.
Security
Unauthorized access
Viruses

Factors that affect the Quality

--- Slide 6 ---
Data transfer methods

--- Slide 7 ---
Components
A data communications system has five components.

--- Slide 8 ---
Physical Structures
Type of Connection
Point-to-Point :A point-to-point connection provides a dedicated link between two devices. 
Multipoint :A multipoint (also called multi drop) connection is one in which more than two specific devices share a single link.

--- Slide 9 ---
Physical Topology
The term physical topology refers to the way in which a network is laid out physically. 
One or more devices connect to a link; two or more links form a topology. 
The topology of a network is the geometric representation of the relationship of all the links and linking devices (usually called nodes) to one another. 

--- Slide 10 ---
Mesh: 
In a mesh topology, every device has a dedicated point-to-point link to every other device. The term dedicated means that the link carries traffic only between the two devices it connects

--- Slide 11 ---
Star Topology: 
In a star topology, each device has a dedicated point-to-point link only to a central controller, usually called a hub.

--- Slide 12 ---
Bus Topology: 
A bus topology, on the other hand, is multipoint. One long cable acts as a backbone to link all the devices in a network

--- Slide 13 ---
Ring Topology:
 In a ring topology, each device has a dedicated point-to-point connection with only the two devices on either side of it.

--- Slide 14 ---
Uses of computer Networks 
Business Applications 
The aim of networking is to make all programs, equipment’s, and data available to anyone on the network 
Each computer has worked in isolation from the others, but at some point they are connected to extract and correlate information about the entire company. 
Networks called VPNs (Virtual Private Networks) may be used to join the individual networks at different sites into one extended network.
Client server 
Telephone calls between employees may be carried by the computer is called IP telephony or Voice over IP (VoIP) when Internet technology is used
Desktop Sharing is remote workers see and interact with a graphical computer screen. 


--- Slide 15 ---

Resource sharing:
Printers, databases, large storage.
Remote access:
Employees work from home or branch offices.
Client–Server Model:
Clients request services, servers provide them.
Examples: web servers, file servers.
Communication improvements:
Email, collaborative editing, videoconferencing.
E-commerce:
Direct links with suppliers and customers.

--- Slide 16 ---
Client Server 

--- Slide 17 ---

Home Applications 
The main usage of networks in home is internet. Internet access provides home users with connectivity to remote computers.
Access to remote information       Ex: www
Person-to-person communication    Ex: chating
Instant Message           Ex: Twitter 
Social Networking           Ex: Face Book, Whatsup 
Wikipedia
Interactive entertainment        Ex: IPTV
Electronic commerce         Ex: shopping
ubiquitous computing, in which computing is embedded into everyday life

--- Slide 18 ---

Internet services:
Information access, entertainment, online shopping.
Communication:
Email, instant messaging, chat rooms.
Peer-to-peer sharing.
Interactive entertainment:
Online games, streaming video/music.
E-commerce:
Online banking, shopping, auctions.
Learning at home:
Telelearning, e-books, digital libraries.


--- Slide 19 ---
Mobile Users 
Mobile computers, such as notebook computers and personal digital assistants (PDAs) are connected to the office or home even when away from home. 
People on the road use their portable electronic equipment to send and receive telephone calls, faxes, and electronic mail, surf the Web, access remote files, and log on to remote machines. 
Mobile computing benefits:
Work from anywhere: access calls, emails, documents.
Wireless networking uses:
University campuses, taxis, conferences, military.
Fixed wireless for areas without cables, Wireless hotspots
Everyday smart uses:
Parking meters, vending machines, utility meters.
M-commerce:
Mobile payments, location-based offers.
Wearable devices:
Smartwatches, health monitors, smart dust, pacemakers



--- Slide 20 ---
Social Issues
Content regulation:
Offensive or politically sensitive material → censorship debates.
Different countries have conflicting laws.
Privacy vs. surveillance:
Governments monitoring emails (e.g., Carnivore/DCS1000).
Companies tracking users via cookies.
Rights conflicts:
Employer vs. employee privacy.
Anonymous communication: whistleblowing vs. legal rights.








--- Slide 21 ---

Cybercrime & misuse:
Spam, viruses, identity theft.
Copyright violations (music, videos).
Information quality:
Not all online info is accurate.
Security gaps:
Lack of encryption/authentication.
Buggy software adds vulnerabilities.
Future outlook:
Networks will keep growing in scope and uses.
Potential in telemedicine, telelearning, and everyday smart devices.

--- Slide 22 ---
Network Hardware 
LAN
MAN
WAN
Wireless network
Home network
Internetwork

--- Slide 23 ---
Network Hardware 
Local Area Networks 
Local area networks, called LANs, are privately-owned networks within a single building or campus of up to a few kilometers in size. 
They are widely used to connect personal computers and workstations in company offices and factories 
LANs are distinguished by three characteristics: (1) size, (2) transmission technology (3) topology. 
LANs are restricted in size. LANs use a transmission technology consisting of a cable to which all the machines are attached. Various topologies are used for broadcast LANs. 


--- Slide 24 ---


--- Slide 25 ---

 In a bus network, at any instant at most one machine is the master and is allowed to transmit. All other machines are required to refrain from sending. 
Eg: IEEE 802.3(Ethernet). 
 In the ring system each bit propagates around on its own, not waiting for the rest of the packet to which it belongs. 
Eg: IEEE 802.5 (the IBM token ring). 

--- Slide 26 ---

Metropolitan Area Networks 
Covers a city; larger than a LAN but smaller than a WAN.
Example: Cable television networks in many cities.
Originated from community antenna systems in areas with poor TV reception.
Initially ad hoc, later city-wide systems contracted by governments.
Evolved from TV-only service to also offering specialized channels (news, sports, cooking, etc.).
Upgraded to provide two-way Internet service using unused parts of the cable spectrum.


--- Slide 27 ---

Wide Area Networks
A wide area network, or WAN, covers large geographical area, often a country or continent. 
The hosts are connected by a communication subnet. The job of the subnet is to carry messages from host to host. 
In most wide area networks, the subnet consists of two distinct components: transmission lines and switching elements. 
 Transmission lines move bits between machines. 
Switching elements are specialized computers that connect three or more transmission lines. 
Designed for high-latency, large-scale data transfer.
Examples: Internet, global corporate networks.


--- Slide 28 ---
When a packet is sent from one router to another via one or more intermediate routers, the packet is received at each intermediate router in its entirety, stored there until the required output line is free, and then forwarded. This is called store-and-forward or packet-switched subnet. 
If the packets are small and all the same size, they are called cells. 


--- Slide 29 ---

Wireless Networks 
Wireless networks can be divided into three main categories: 
1. System interconnection. 2. Wireless LANs. 3. Wireless WANs. 
System interconnection is all about interconnecting the components of a computer using short-range radio. EX: short-range radio wireless networks called Bluetooth 
Transmits data using radio waves instead of cables, removing the need for physical wiring.
Enables mobility, allowing users to connect and move devices freely within coverage.
Includes technologies like Wi-Fi, Bluetooth, and cellular mobile networks.
Can be quickly expanded without installing new cables or network lines.
Speed and range vary depending on the wireless standard and frequency used.
Example: Wi-Fi networks in airports, offices, cafes, and public hotspots.



--- Slide 30 ---

Home Networks 
Computers (desktop PC). Entertainment (TV, DVD). Telecommunications (telephone, mobile telephone). Appliances (microwave, refrigerator). Telemetry (utility meter, smoke/burglar alarm). 
Connects multiple household devices like computers, entertainment systems, appliances, and security equipment.
Allows devices to communicate with each other and access the Internet from anywhere in the home.
Must be easy to install and operate, as most users are non-technical and expect reliability from day one.
Needs high performance for multimedia streaming, remote monitoring, and interactive applications.
Should be affordable, expandable, and based on stable interfaces to avoid frequent upgrades.
Security and reliability are critical to prevent unauthorized access and protect connected devices.

--- Slide 31 ---
Internetwork
Combination of two or more networks such as LAN, MAN, and WAN, allowing them to function as one system.
Facilitates communication and resource sharing between devices on different networks.
Uses routers, gateways, and switches to connect and manage traffic between networks.
Supports both similar and different network technologies for seamless integration.
Can be private (intranet) for internal use or public (Internet) for global access.
Example: Corporate offices worldwide connected via Internet for collaboration.

--- Slide 32 ---
Network software 
Protocol Hierarchies 
The first computer networks were hardware-focused, with software as an afterthought  a strategy that no longer works.
Modern network software is highly structured, forming a key concept in networking.
Most networks are organized as a stack of layers, each built upon the one below it.
Each layer offers services to higher layers, hiding implementation details, acting like a virtual machine.
This concept is similar to information hiding, abstract data types, data encapsulation, and object-oriented programming.
Layer n communicates with layer n on another machine using agreed rules called the layer n protocol. a protocol is an agreement between the communicating parties on how communication is to proceed.


--- Slide 33 ---

The entities in corresponding layers on different machines are called peers, which may be processes, devices, or even humans.
In reality, no data are directly transferred from layer n on one machine to layer n on another machine.
Each layer passes data and control information to the layer immediately below it until the lowest layer is reached.
Below layer 1 is the physical medium through which actual communication occurs.
Virtual communication is shown by dotted lines and physical communication by solid lines.




--- Slide 34 ---

Between each pair of adjacent layers is an interface defining primitive operations and services available to the upper layer.
Clean interfaces require each layer to perform a specific set of well-understood functions and allow replacing the implementation of one layer with a different one without affecting higher layers.
A set of layers and protocols is called a network architecture, with enough information for correct implementation.
A list of protocols used by a system, one per layer, is called a protocol stack.




--- Slide 35 ---



--- Slide 36 ---


--- Slide 37 ---
Design Issues for the Layers 
1. Addressing
Every layer needs a mechanism for identifying senders and receivers.
A process on one machine must specify with whom it wants to talk, requiring some form of addressing.
2. Data Transfer Rules
Some systems allow data only in one direction, while others allow two-way communication.
The protocol must determine how many logical channels a connection has and their priorities.
3. Error Control
Physical communication circuits are imperfect, so error-detecting or error-correcting codes are needed.
Both ends of the connection must agree on which error control method is used.
4. Sequencing
Not all channels preserve the order of messages, so protocols must handle proper reassembly.
Numbering pieces helps, but handling out-of-order arrivals is still required.

--- Slide 38 ---

5. Flow Control
Prevents a fast sender from swamping a slow receiver with data.
Solutions include feedback from receiver to sender or limiting the sender’s transmission rate.
6. Message Size Handling
Long messages must be disassembled, transmitted, and reassembled.
Small messages can be combined into a single larger one for efficiency.
7. Multiplexing
The same connection may carry multiple unrelated conversations.
Multiplexing and demultiplexing should be transparent to the layers above.
8. Routing
When multiple paths exist, a route must be chosen between source and destination.
Routing decisions can be split between high-level policy and low-level traffic-based choices.
9. Channel Priorities
Many networks provide separate channels for normal and urgent data.
This allows urgent information to be transmitted without waiting for normal data.


--- Slide 39 ---
Connection-Oriented and Connectionless Services 
Layers can offer two types of service
Connection-oriented and connectionless.
Connection-oriented service is like the telephone system: 
establish connection → use connection → release connection.
In connection-oriented service, the connection acts like a tube, bits go in at one end and come out at the other, usually in order.
Sometimes, a connection setup includes negotiation on parameters like maximum message size or quality of service.
Connectionless service is like the postal system, each message carries the full destination address and is routed independently.
In connectionless service, messages usually arrive in order, but delays can cause out-of-order delivery.


--- Slide 40 ---

Quality of service can vary — reliable services never lose data, using acknowledgements for confirmation.
Reliable services introduce overhead and delay, but are often worth it; sometimes, however, delays are undesirable.
Example: 
File transfer needs reliable connection-oriented service to ensure correct and ordered delivery of all bits.
Remote login (SSH, Telnet) needs every keystroke must arrive correctly, otherwise commands fail.
digitized voice or video conferencing, prefer speed over reliability to avoid delays from acknowledgements.
junk email, only need a single message sent without setting up a connection — unreliable connectionless service (datagram service).
Acknowledged datagram service provides connectionless transmission but with delivery confirmation (like registered mail with return receipt).
Request-reply service sends one datagram as a request and receives a reply with the answer.

--- Slide 41 ---


--- Slide 42 ---
Service Primitives 

--- Slide 43 ---
The server executes LISTEN to indicate that it is prepared to accept incoming connections. server process is blocked until a request for connection appears. 
The client process executes CONNECT to establish a connection with the server. The CONNECT call needs to specify who to connect to. 
When the system sees that the packet is requesting a connection, it checks to see if there is a listener.
  it does two things: unblocks the listener and sends back an acknowledgement. The arrival of this acknowledgement then releases the client. 
 The server executes RECEIVE to prepare to accept the first request. Then the client executes SEND to transmit its request followed by the execution of RECEIVE to get the reply. 
The client use DISCONNECT to terminate the connection. When the server gets the packet, it also issues a DISCONNECT of its own, acknowledging the client and releasing the connection. 

--- Slide 44 ---


--- Slide 45 ---
Reference Models
two important network architectures, the OSI reference model and the TCP/IP reference model. 
Although the protocols associated with the OSI model are rarely used any more, the model itself is actually quite general and still valid, and the features discussed at each layer are still very important. 
The TCP/IP model has the opposite properties: the model itself is not of much use but the protocols are widely used.

--- Slide 46 ---
OSI(open system interconnection) Model
This model is based on a proposal developed by the International Standards Organization (ISO) as a first step toward international standardization of the protocols used in the various layers (Day and Zimmermann, 1983). 
It was revised in 1995 (Day, 1995). The model is called the ISO OSI (Open Systems Interconnection) Reference Model because it deals with connecting open systems—that is, systems that are open for communication with other systems

--- Slide 47 ---

The OSI model has seven layers. 
The principles that were applied to arrive at the seven layers can be briefly summarized as follows: 
1. A layer should be created where a different abstraction is needed. 
2. Each layer should perform a well-defined function. 
3. The function of each layer should be chosen with an eye toward defining internationally standardized protocols. 
4. The layer boundaries should be chosen to minimize the information flow across the interfaces. 
5. The number of layers should be large enough that distinct functions need not be thrown together in the same layer out of necessity and small enough that the architecture does not become unwieldy. 


--- Slide 48 ---


--- Slide 49 ---
Physical Layer – Layer 1
It is responsible for the actual physical connection between the devices. 
The physical layer contains information in the form of bits.
When receiving data, this layer will get the signal received and convert it into 0s and 1s and send them to the Data Link layer

Hub, Repeater, Modem, and Cables are Physical Layer devices.

--- Slide 50 ---
Functions of the Physical Layer
Bit synchronization: The physical layer provides the synchronization of the bits 
Bit rate control: The Physical layer also defines the transmission rate i.e. the number of bits sent per second.
Physical topologies: Physical layer specifies how the different, devices/nodes are arranged in a network i.e. bus, star, or mesh topology.
Transmission mode: Physical layer also defines how the data flows between the two connected devices. The various transmission modes possible are Simplex, half-duplex and full-duplex.


--- Slide 51 ---
Data Link Layer (DLL) – Layer 2
The data link layer is responsible for the node-to-node delivery of the message. 
The main function of this layer is to make sure data transfer is error-free from one node to another, over the physical layer. 
When a packet arrives in a network, it is the responsibility of the DLL to transmit it to the Host using its MAC address. 
The packet received from the Network layer is further divided into frames depending on the frame size . 
DLL also encapsulates Sender and Receiver’s MAC address in the header.

Switch & Bridge are Data Link Layer devices. Packet in the Data Link layer is referred to as Frame.


--- Slide 52 ---
Functions of the Data Link Layer
Framing: Framing is a function of the data link layer. It provides a way for a sender to transmit a set of bits that are meaningful to the receiver.
 Physical addressing: After creating frames, the Data link layer adds physical addresses (MAC addresses) of the sender and/or receiver in the header of each frame.
Error control: The data link layer provides the mechanism of error control in which it detects and retransmits damaged or lost frames.
Flow Control: flow control coordinates the amount of data that can be sent before receiving an acknowledgment.
Access control: MAC sub-layer of the data link layer helps to determine which device has control over the channel at a given time.


--- Slide 53 ---
Network Layer – Layer 3
The network layer works for the transmission of data from one host to the other located in different networks.
 It also takes care of packet routing
The sender & receiver’s IP addresses are placed in the header by the network layer.

--- Slide 54 ---
Functions of the Network Layer
Routing: The network layer protocols determine which route is suitable from source to destination. 
Logical Addressing: To identify each device on Internet work uniquely, the network layer defines an addressing scheme. The sender & receiver’s IP addresses are placed in the header by the network layer. 

Segment in the Network layer is referred to as Packet. 
Network layer is implemented by networking devices such as routers and switches. 


--- Slide 55 ---
Transport Layer – Layer 4
The transport layer provides services to the application layer and takes services from the network layer. 
It is responsible for the End to End Delivery of the complete message. 
The transport layer also provides the acknowledgment of the successful data transmission and re-transmits the data if an error is found

Data in the Transport Layer is called Segments. 
The transport layer is called as Heart of the OSI model. 
Device or Protocol Use : TCP, UDP 


--- Slide 56 ---

At the sender’s side: 
The transport layer receives the formatted data from the upper layers, performs Segmentation, and also implements Flow & Error control to ensure proper data transmission. 
It also adds Source and Destination port numbers in its header and forwards the segmented data to the Network Layer. 

At the receiver’s side: 
Transport Layer reads the port number from its header and forwards the Data which it has received to the respective application.
 It also performs sequencing and reassembling of the segmented data.

--- Slide 57 ---
Functions of the Transport Layer 
Segmentation and Reassembly: This layer accepts the message from the session layer, and breaks the message into smaller units. Each of the segments produced has a header associated with it. The transport layer at the destination station reassembles the message.
Service Point Addressing: To deliver the message to the correct process, the transport layer header includes a type of address called service point address or port address. 

--- Slide 58 ---
Services
1. Connection-Oriented Service: It is a three-phase process that includes
Connection Establishment
Data Transfer
Termination/disconnection

2. Connectionless service: It is a one-phase process and includes Data Transfer. 
In this type of transmission, the receiver does not acknowledge receipt of a packet. 

Connection-oriented service is more reliable than connectionless Service.

--- Slide 59 ---
Session Layer – Layer 5
This layer is responsible for the establishment of connection, maintenance of sessions, and authentication, and also ensures security



Protocols used: Point-to-Point Tunneling Protocol (PPTP)

--- Slide 60 ---
Functions of the Session Layer
Session establishment, maintenance, and termination: The layer allows the two processes to establish, use and terminate a connection.
Synchronization: synchronization points help to identify the error so that the data is re-synchronized properly, and ends of the messages are not cut prematurely and data loss is avoided.
Dialog Controller: The session layer allows two systems to start communication with each other in half-duplex or full-duplex


--- Slide 61 ---
Presentation Layer – Layer 6
The presentation layer is also called the Translation layer. 
The data from the application layer is extracted here and manipulated as per the required format to transmit over the network.


Device or Protocol Use :  FTP(FileTransfer Protocol)


--- Slide 62 ---
Functions of the Presentation Layer
Translation: For example, ASCII to EBCDIC(Extended Binary Coded Decimal Interchange Code).
Encryption/ Decryption: Data encryption translates the data into another form or code. 
The encrypted data is known as the ciphertext and the decrypted data is known as plain text. A key value is used for encrypting as well as decrypting data.
Compression: Reduces the number of bits that need to be transmitted on the network.


--- Slide 63 ---
Application Layer – Layer 7
This Application layer is implemented by the network applications. 
This layer also serves as a window for the application services to access the network and for displaying the received information to the user. 


Device or Protocol Use :  SMTP(Simple Mail Transfer Protocol)

--- Slide 64 ---
Functions of the Application Layer
Network Virtual Terminal: It allows a user to log on to a remote host.
FTAM- File transfer access and management : This application allows a user to access file in a remote host, retrieve files in remote host and manage or control files from a remote computer.
Mail Services : Provide email service.
Directory Services : This application provides distributed database sources and access for global information about various objects and services.


--- Slide 65 ---
The TCP/IP Reference Model 
TCP/IP was designed and developed by the Department of Defense (DoD) in the 1960s and is based on standard protocols. 
It stands for Transmission Control Protocol/Internet Protocol. 
It contains four layers, unlike the seven layers in the OSI model.

The main work of TCP/IP is to transfer the data of a computer from one device to another. 
The Aim is to make data reliable and accurate so that the receiver will receive the same information which is sent by the sender. 
To ensure that, each message reaches its final destination accurately, the TCP/IP model divides its data into packets and combines them at the other end.

--- Slide 66 ---


--- Slide 67 ---
The Network Interface Layer 
Network Access layer defines details of how data is physically sent through the network, including how bits are electrically or optically signaled by hardware devices . 

The layer is responsible for placing TCP/IP packets on the network medium and receiving TCP/IP packets off the network medium. 

It is used to connect different network types like LAN technologies

The protocols included are Ethernet, Token Ring, FDDI(Fiber Distributed Data Interface), Frame Relay


--- Slide 68 ---
The Internet Layer 
This layer permits hosts to inject packets into any network and have them travel independently to the destination. 

It defines an official packet format and protocol called IP (Internet Protocol). 

The job of the internet layer is to deliver IP packets where they are supposed to go. 

The Internet layer is responsible for addressing, packaging, and routing functions. 

The core protocols of the Internet layer are IP, ARP, ICMP, and IGMP. 


--- Slide 69 ---

The Internet Protocol (IP) is a routable protocol responsible for IP addressing, routing, and the fragmentation and reassembly of packets. 

The Address Resolution Protocol (ARP) is responsible for the resolution of the Internet layer address to the Network Interface layer address such as a hardware address. 

 The Internet Control Message Protocol (ICMP) is responsible for providing diagnostic functions and reporting errors due to the unsuccessful delivery of IP packets. 

The Internet Group Management Protocol (IGMP) is responsible for the management of IP multicast groups. 


--- Slide 70 ---
The Transport Layer 
It is designed to allow peer entities on the source and destination hosts to carry on a conversation. 

TCP (Transmission Control Protocol), is a reliable connection-oriented protocol that allows a byte stream originating on one machine to be delivered without error on any other machine in the internet. 
It fragments the incoming byte stream into discrete messages and passes each one on to the internet layer. 
At the destination, the receiving TCP process reassembles the received messages

UDP (User Datagram Protocol), is an unreliable, connectionless protocol for applications


--- Slide 71 ---


--- Slide 72 ---
The Application Layer 
The Application layer provides applications/ the ability to access the services of the other layers

The most widely-known Application layer protocols are those used for the exchange of user information: 
The Hypertext Transfer Protocol (HTTP) is used to transfer files that make up the Web pages of the World Wide Web. 
 The File Transfer Protocol (FTP) is used for interactive file transfer. 
The Simple Mail Transfer Protocol (SMTP) is used for the transfer of mail messages and attachments. 
Telnet, a terminal emulation protocol, is used for logging on remotely to network hosts. 


--- Slide 73 ---

The Domain Name System (DNS) is used to resolve a host name to an IP address. 
The Routing Information Protocol (RIP) is a routing protocol that routers use to exchange routing information on an IP internetwork. 
The Simple Network Management Protocol (SNMP) is used monitor and manage network devices connected over an IP. SNMP is used for communication between routers, switches, firewalls,  servers, CCTV cameras, and wireless devices.


================================================================================
FILE: module 2.pptx
================================================================================

--- Slide 1 ---
Module 2-Network Layer

--- Slide 2 ---

Routing algorithms: The Optimality Principle, Shortest Path Routing, Flooding, Distance Vector Routing, Link state Routing, Hierarchical Routing. 
Congestion Control Algorithms: General Principles of Congestion Control, Congestion Prevention Policies, Congestion Control in Virtual-Circuit Subnets, Congestion Control in Datagram Subnets, Load Shedding, Jitter Control. 
Chapter 5: 5.2, 5.3 	


--- Slide 3 ---
Routing Algorithms 
The main function of NL (Network Layer) is routing packets from the source machine to the destination machine. 
There are two processes inside router: 
a) One of them handles each packet as it arrives, looking up the outgoing line to use for it in the routing table. This process is forwarding. 
b) The other process is responsible for filling in and updating the routing tables. That is where the routing algorithm comes into play. This process is routing. 
It should process properties, like correctness, simplicity, robustness, stability, fairness, and optimality. 


--- Slide 4 ---

Different Routing Algorithms 
Optimality principle 
Shortest path algorithm 
Flooding 
Distance vector routing 
Link state routing 
Hierarchical Routing 

--- Slide 5 ---
Optimality principle 
One can make a general statement about optimal routes without regard to network topology or traffic. This statement is known as the optimality principle
Optimality principle: if router J is on optimal path from router I to router K, then optimal path from J to K also falls along same route

--- Slide 6 ---
Set of optimal routes from all sources to a given destination form a tree rooted at the destination. Such a tree is called a sink tree
The goal of all routing algorithms is to discover and use the sink trees for all routers.

--- Slide 7 ---
Shortest Path Routing(Dijkstra’s) 
It is really the least-cost path routing, based on dynamic programming for optimisation
The idea is to build a graph of the subnet, with each node of the graph representing a router and each arc of the graph representing a communication line or link. 
To choose a route between a given pair of routers, the algorithm just finds the shortest path between them on the graph 

--- Slide 8 ---

1. Start with the local node (router) as the root of the tree. Assign a cost of 0 to this node and make it the first permanent node. 
2. Examine each neighbor of the node that was the last permanent node. 
3. Assign a cumulative cost to each node and make it tentative 
4. Among the list of tentative nodes 
a. Find the node with the smallest cost and make it Permanent 
b. If a node can be reached from more than one route then select the route with the shortest cumulative cost. 
5. Repeat steps 2 to 4 until every node becomes permanent 


--- Slide 9 ---


--- Slide 10 ---
Dijkstra’s Routing algorithm
 Initialization
N = {A}     // A is a root node.
for all nodes v
if v adjacent to A
then D(v) = c(A,v)
else D(v) = infinity
loop
find w not in N such that D(w) is a minimum.
Add w to N
Update D(v) for all v adjacent to w and not in N:
D(v) = min(D(v) , D(w) + c(w,v))
Until all nodes in N


--- Slide 12 ---
Flooding
Another algorithm is flooding, in which every incoming packet is sent out on every outgoing line except the one it arrived on. 
Flooding obviously generates vast numbers of duplicate packets, in fact, an infinite number unless some measures are taken to damp the process. 
One such measure is to have a hop counter contained in the header of each packet, which is decremented at each hop, with the packet being discarded when the counter reaches zero. 
Ideally, the hop counter should be initialized to the length of the path from source to destination. 
A variation of flooding that is slightly more practical is selective flooding, where the routers do not send every incoming packet out on every line, only on those lines that are going approximately in the right direction. 
Each router remembers the identity of those packets it has already sent  out. When duplicate copies of the packet arrives back, they are discarded. This is achieved by source router putting a sequence number in the packet.
Flooding is not practical in most applications. 

--- Slide 13 ---
Advantages
1) In military applications, where large numbers of routers are blown, flooding is desirable.
2) In Distributed database applications, it is some times necessary to update all the databases concurrently, in which flooding is useful.
3) It is used as a metric against which other routing algorithms are compared.
4) Flooding chooses the shortest path, because it chooses all possible path in parallel.

--- Slide 14 ---
Distance Vector Routing
A distance vector routing algorithm operates by having each router maintain a table giving the best known distance to each destination and which link to use to get there. 
The distance vector routing algorithm is sometimes called by other names, most commonly the distributed Bellman-Ford routing algorithm,
In distance vector routing, each router maintains a routing table indexed by, and containing one entry for each router in the network. This entry has two parts: the preferred outgoing line to use for that destination and an estimate of the distance to that destination.
The router is assumed to know the distance to each of its neighbors. If the metric is hops, the distance is just one hop. If the metric is queue length, the router examines each queue. If the metric is delay the router can measure it directly with a special ECHO packets.

--- Slide 15 ---
Fig.(a) shows the subnet and fig.(b) shows the vectors of J for its neighbors. Let JA delay is 8, JI delay is 10, JH is 12, JK is 6.The new route to G from J can be calculated as follows: J can get A in 8 m sec. A can get G in 18 m sec(from table). Hence J can get G in (8+18) 26 m sec.Similarly the delay to G via I,H and K is (31 +10) =41, (6+12)18, (31+6)37 m sec.The best of these values is 18, so it makes an entry in its routing table that the delay to G is 18 m sec and that route is via H.

--- Slide 16 ---
Count-to-Infinity problem
The Count-to-Infinity problem is an issue in a network routing method called distance vector routing, where routers share information with each other to find the best path to a destination. Here’s a simpler breakdown:
Good News Spreads Quickly: When a new, shorter path to a destination is available, routers quickly update their routes. For example, if one router learns there is now a faster way to reach a certain location, it immediately starts using that path. This information spreads fast.
Bad News Travels Slowly: However, when a route goes down (for example, if a router or connection fails), the "bad news" about this problem spreads very slowly. This can cause delays and confusion in the network.


--- Slide 17 ---
Imagine a network of five routers in a line, named A, B, C, D, and E. The routers know the shortest way to reach each other. But suddenly, A goes down (stops working):
B notices that A is down, but C still thinks it can reach A through B. So C tells B it has a path to A.
B doesn’t realize C’s path actually goes through itself, so B believes it can still reach A through C, even though that’s incorrect.
Over time, each router keeps increasing the "distance" to A, but they still believe A is reachable, which isn't true.
This process continues, with the routers counting up to a high number (counting to "infinity") before they finally realize A is unreachable. This happens because each router only knows what its neighbors tell it, without knowing if it’s part of a looped path.


--- Slide 18 ---

Why It’s Hard to Fix?
Attempts to solve this problem, like split horizon and poisoned reverse, help reduce it by stopping routers from sharing paths back to where they came from. However, these methods aren’t perfect and don’t solve the problem completely in all cases.
In short, the Count-to-Infinity problem shows that when a route goes down, distance vector routing can be slow to recognize it, creating delays and possible routing loops.


--- Slide 19 ---
Link State Routing
The primary problem is that the algorithm often took too long time to converge after the network topology changed.
The idea behind link state routing is:
1. Discover its neighbors and learn their network addresses.
2. Set the distance or cost metric to each of its neighbors.
3. Construct a packet telling all it has just learned.
4. Send this packet to and receive packets from all other routers.
5. Compute the shortest path to every other router.

Then Dijkstra’s algorithm can be run at each router to find the shortest path to every other router.

--- Slide 20 ---
Learning about the Neighbors
When a router is booted, its first task is to learn who its neighbors are. 
It accomplishes this goal by sending a special HELLO packet on each point-to-point line. The router on the other end is expected to send back a reply giving its name.

--- Slide 21 ---
Setting Link Costs
The link state routing algorithm requires each link to have a distance or cost metric for finding shortest paths. 
The cost to reach neighbors can be set automatically, or configured by the network operator.
 A common choice is to make the cost inversely proportional to the bandwidth of the link.
If the network is geographically spread out, the delay of the links may be factored into the cost so that paths over shorter links are better choices.

--- Slide 22 ---
Building Link State Packets
Once the information needed for the exchange has been collected, the next step is for each router to build a packet containing all the data. 
The packet starts with the identity of the sender, followed by a sequence number and age and a list of neighbors. The cost to each neighbor is also given.

--- Slide 23 ---
Distributing the Link State Packets
The fundamental idea is to use flooding to distribute the link state packets to all routers. 
To keep the flood in check, each packet contains a sequence number that is incremented for each new packet sent.
 Routers keep track of all the (source router, sequence) pairs they see. 
When a new link state packet comes in, it is checked against the list of packets already seen. 
If it is new, it is forwarded on all lines except the one it arrived on.
 If it is a duplicate, it is discarded. 
If a packet with a sequence number lower than the highest one seen so far ever arrives, it is rejected as the router has more recent data.

--- Slide 24 ---

Include the age of each packet after the sequence number and decrement it once per second. 
When the age hits zero, the information from that router is discarded. 
The Age field is also decremented by each router during the initial flooding process, to make sure no packet can get lost and live for an indefinite period of time.

--- Slide 25 ---
Computing the New Routes
Once a router has accumulated a full set of link state packets, it can construct the entire network graph because every link is represented. 
Every link is, represented twice, once for each direction. 
Dijkstra’s algorithm can be run locally to construct the shortest paths to all possible destinations.
OSPF (Open Shortest Path First) is the other main link state protocol.

--- Slide 26 ---
Hierarchical Routing 
At a certain point, the network may grow to the point where it is no longer feasible for every  router to have an entry for every other router, so the routing will have to be done hierarchically, as it is in the telephone network. 
When hierarchical routing is used, the routers are divided into what we will call regions. 
Each router knows all the details about how to route packets to destinations within its own region but knows nothing about the internal structure of other regions. 
For huge networks, a two level hierarchy may be insufficient; it may be necessary to group the regions into clusters, the clusters into zones, the zones into groups, and so on, 

--- Slide 27 ---
Ex. Consider a 720 routers subnet.Without hierarchy each router required 720 entries. Total entries will be 720 x 720, with hierarchy, if the subnet is portioned into 24 regions and 30 routers/region, then each router needs 30+23 = 53 entries only.

--- Slide 28 ---
CONGESTION CONTROL ALGORITHMS-What is Congestion?
Too many packets present in (a part of) the network causes packet delay and loss that degrades performance. This situation is called congestion.
The network and transport layers share the responsibility for handling congestion. Since congestion occurs within the network, it is the network layer that directly experiences it and must ultimately determine what to do with the excess packets. 
However, the most effective way to control congestion is to reduce the load that the transport layer is placing on the network. 

--- Slide 29 ---
When the number of packets hosts send into the network is well within its carrying capacity, the number delivered is proportional to the number sent. 
If twice as many are sent, twice as many are delivered. However, as the offered load approaches the carrying capacity, bursts of traffic occasionally fill up the buffers inside routers and some packets are lost. These lost packets consume some of the capacity, so the number of delivered packets falls below the ideal curve. The network is now congested.

--- Slide 30 ---
What factors will lead to congestion?
1. Three or four input lines and only one output line, queue will build up.
If there is insufficient memory to hold all of them, packets will lost.
Adding infinite memory congestion gets worse, because by the time packets get into the front of the queue, the time out and duplicates have been sent.
2. Slow processors (routers) can cause congestion.
A slow processor perform tasks very slow, queues will build up.
3. Low band-width lines also cause congestion
Upgrading lines but not changing the processor and vice-versa shifts the bottleneck.

--- Slide 31 ---

In flow control, rate of traffic received from a sender can be controlled by a receiver. 
Prevents buffer overflow: by regulating the rate at which data is sent from the sender to the receiver.
Helps in handling different data rates: by regulating the flow of data to match the capacity of the receiving device.
Efficient use of network resources: by avoiding packet loss and reducing the need for retransmissions.


--- Slide 32 ---

On the other hand, In congestion control, rate of traffic from sender to the network is controlled. 
Prevents network congestion: by regulating the rate at which data is sent from the sender to the receiver.
Efficient use of network resources: by reducing the number of lost packets and retransmissions.
Fair allocation of network resources: by regulating the rate of data flow for all sources.


--- Slide 33 ---
General principle of congestion control
Open loop Congestion Control
Open loop congestion control policies are applied to prevent congestion before it happens. The congestion control is handled either by the source or the destination.

Closed Loop Congestion Control
Closed loop congestion control techniques are used to treat or alleviate congestion after it happens. 


--- Slide 34 ---
Congestion Prevention Policiesopen loop congestion control
Retransmission Policy : 
It is the policy in which retransmission of the packets are taken care of. 
If the sender feels that a sent packet is lost or corrupted, the packet needs to be retransmitted. This transmission may increase the congestion in the network. 
Retransmission timers must be designed to prevent congestion and also able to optimize efficiency. 


--- Slide 35 ---

2. Window Policy : 
The type of window at the sender’s side may also affect the congestion.
Several packets in the Go-back-N window are re-sent, although some packets may be received successfully at the receiver side. This duplication may increase the congestion in the network and make it worse. 
Therefore, Selective repeat window should be adopted as it sends the specific packet that may have been lost

3.Discarding Policy : A good discarding policy adopted by the routers is that the routers may prevent congestion and at the same time partially discard the corrupted or less sensitive packages and also be able to maintain the quality of a message. 



--- Slide 36 ---

4. Acknowledgment Policy : 
The receiver should send acknowledgement for N packets rather than sending acknowledgement for a single packet. 
The receiver should send an acknowledgment only if it has to send a packet or a timer expires. 

5. Admission Policy : 
Switches should first check the resource requirement of a network flow before transmitting it further. 
If there is a chance of a congestion or there is a congestion in the network, router should deny establishing a virtual network connection to prevent further congestion.


--- Slide 37 ---
Congestion Prevention PoliciesClosed loop congestion control
Backpressure : 
Backpressure is a technique in which a congested node stops receiving packets from upstream node. 
This may cause the upstream node or nodes to become congested and reject receiving data from above nodes. 
Backpressure is a node-to-node congestion control technique that propagate in the opposite direction of data flow.


--- Slide 38 ---
2. Implicit Signaling : In implicit signaling, there is no communication between the congested nodes and the source. The source guesses that there is congestion in a network. 
Ex: when sender sends several packets and there is no acknowledgment for a while, one assumption is that there is a congestion
3. Explicit Signaling : In explicit signaling, if a node experiences congestion it can explicitly sends a packet to the source or destination to inform about congestion. 
Forward Signaling :a signal is sent in the direction of the congestion. The destination is warned about congestion. The receiver in this case adopt policies to prevent further congestion.
Backward Signaling : a signal is sent in the opposite direction of the congestion. The source is warned about congestion and it needs to slow down.


--- Slide 39 ---
Congestion control in virtual circuit subnet
Admission control:
This technique is used to track the congestion control after it occurred.
Once the congestion occurs in network do not set up any more virtual connection until the congestion is removed.
Alternate approach:
You can add a new connection to the node other than congestion node.

--- Slide 40 ---
Congestion Control in Datagram Subnets
1.Warning bit
A special bit in the packet header is set by the router to warn the source when congestion is detected. 
The bit is copied and piggy-backed on the ACK and sent to the sender. 
The sender monitors the number of ACK packets it receives with the warning bit set and adjusts its transmission rate accordingly. 


--- Slide 41 ---
 2.Choke packet
A choke packet is a packet sent by a node to the source to inform about congestion.
A more direct way of telling the source to slow down. 
A choke packet is a control packet generated at a congested node and transmitted to restrict traffic flow. 
The source, on receiving the choke packet must reduce its transmission rate by a certain percentage. 
An example of a choke packet is the ICMP Source Quench Packet. 

--- Slide 42 ---

Hop-by-Hop Choke Packets 
Over long distances or at high speeds choke packets are not very effective. 
A more efficient method is to send to choke packets hop-by-hop. 
This requires each hop to reduce its transmission even before the choke packet arrive at the source 


--- Slide 43 ---
3.Hop-by-Hop Choke Packets

--- Slide 44 ---
Load Shedding
Load shedding is defined as an approach of discarding the packets when the buffer is full .
The selection of packets to discard is an important task. Many times packets with less importance and old packets are discarded.
To implement an intelligent discard policy, applications must mark their packets to indicate to the network how important they are. Then, when packets have to be discarded, routers can first drop packets from the least important class, then the next most important class, and so on.



--- Slide 45 ---
Random Early detection
Randomly early detection is an approach in which packets are discarded before the buffer space becomes full. 
When the buffer is empty set queue size.
Therefore the situation of congestion is controlled earlier. In this approach, the router initially maintains a specific queue length for the outgoing lines. 
When this average set line is exceeded it warns for congestion and discards the packets.


--- Slide 46 ---
Jitter Control
Jitter is an inconsistent delay in the data packets.
Due to network congestion, poor hardware, or lack of packet prioritization, the steady stream of data packets gets disrupted, and the interval between the packets gets uneven, the result is jitter. 
The jitter can be bounded by computing the expected transit time for each hop along the path.
When a packet arrives at router, the router will check to see whether the packet is ahead or behind.
If the packet is early router will kept is hold.
If it is late it will send as soon as possible.


--- Slide 47 ---

The algorithm for determining which of several packets competing for an output line should go next can always choose the packet furthest behind in its schedule. In this way, packets that are ahead of schedule get slowed down and packets that are behind schedule get speeded up, in both cases reducing the amount of jitter.
In some applications, such as video on demand, jitter can be eliminated by buffering at the receiver and then fetching data for display from the buffer instead of from the network in real time. 
However, for other applications, especially those that require real-time interaction between people such as Internet telephony and video conferencing, the delay inherent in buffering is not acceptable.
(a) High jitter. (b) Low jitter.


================================================================================
FILE: module 3.pptx
================================================================================

--- Slide 1 ---
Module 3-Network Layer


--- Slide 2 ---

Quality of Service: Application Requirements, Traffic Shaping, Packet Scheduling, Admission Control. 
Internetworking: How networks differ, How Networks Can Be Connected, Tunneling, Internetwork Routing, Fragmentation; The Network Layer in the Internet: The IPv4 Protocol, IP Addresses, IPv6, Internet Control Protocols. 	
Chapter 5: 5.4, 5.5, 5.6: 5.6.1-5.6.4, 5.6.6-5.6.8 	


--- Slide 3 ---
Quality of Service
Requirements:
A stream of packets from a source to a destination is called a flow.
In a connection-oriented network, all the packets belonging to a flow follow the same route; in a connectionless network, they may follow different routes. 
The needs of each flow can be characterized by four primary parameters: reliability, delay, jitter, and bandwidth. Together these determine the QoS (Quality of Service) the flow requires.

--- Slide 4 ---
Techniques for Achieving Good Quality of Service
Overprovisioning
An easy solution is to provide so much router capacity, buffer space, and bandwidth that the packets just fly through easily. The trouble with this solution is that it is expensive. 
Buffering
Flows can be buffered on the receiving side before being delivered. Buffering them does not affect the reliability or bandwidth, and increases the delay, but it smooths out the jitter. 

--- Slide 5 ---
At t = 10 sec, playback begins. At this time, packets 1 through 6 have been buffered so that they can be removed from the buffer at uniform intervals for smooth play. Unfortunately, packet 8 has been delayed so much that it is not available when its play slot comes up, so playback must stop until it arrives, creating an annoying gap in the music or movie. This problem can be alleviated by delaying the starting time even more, although doing so also requires a larger buffer. Commercial Web sites that contain streaming audio or video all use players that buffer for about 10 seconds before starting to play.

--- Slide 6 ---

Traffic Shaping
1. Another method of congestion control is to “shape” the traffic before it enters the network. traffic shaping, which smooths out the traffic on the server side, rather than on the client side.
2. Traffic shaping is about regulating the average rate (and burstiness) of data transmission. Used in ATM and Integrated Services networks. 
3. At connection set-up time, the sender and carrier negotiate a traffic pattern (shape). 
Monitoring a traffic flow is called traffic policing.

Two traffic shaping algorithms are: 
Leaky Bucket 
Token Bucket 

--- Slide 7 ---
The Leaky Bucket(LB) Algorithm
Imagine a bucket with a small hole in the bottom. 
No matter at what rate water enters the bucket, the outflow is at a constant rate when there is any water in the bucket, and zero when the bucket is empty. 
Also, once the bucket is full, any additional water entering it spills over the sidesand is lost.

--- Slide 8 ---

The Leaky Bucket Algorithm used to control rate in a network. It is implemented as a single-server queue with constant service time. If the bucket (buffer) overflows then packets are discarded.
The leaky bucket enforces a constant output rate  (average rate) regardless of the burstiness of the input. Does nothing when input is idle.
 The host injects one packet per clock tick onto the network. This results in a uniform flow of packets, smoothing out bursts and reducing congestion.
When packets are the same size , the one packet per tick is okay. For variable length packets though, it is better to allow a fixed number of bytes per tick. E.g. 1024 bytes per tick will allow one 1024-byte packet or two 512-byte packets or four 256-byte packets on 1 tick. 


--- Slide 9 ---
The Leaky Bucket(LB) Algorithm

--- Slide 10 ---
The Token Bucket(TB) Algorithm
In contrast to the LB, the Token Bucket Algorithm, allows the output rate to vary, depending on the size of the burst. 
In the TB algorithm, the bucket holds tokens.  To transmit a packet, the host must capture and destroy one token.
Tokens are generated by a clock at the rate of one token every t sec.
Idle hosts can capture and save up tokens (up to the max size of the bucket) in order to send larger bursts later.


--- Slide 11 ---
The Token Bucket(TB) Algorithm

--- Slide 12 ---
Leaky Bucket vs Token Bucket
LB discards packets; TB does not. TB discards tokens.
With TB, a packet can only be transmitted if there are enough tokens to cover its length in bytes.
LB sends packets at an average rate. TB allows for large bursts to be sent faster by speeding up the output.
TB allows saving up tokens (permissions) to send large bursts. LB does not allow saving.


--- Slide 13 ---
Resource Reservation
Once we have a specific route for a flow, it becomes possible to reserve resources along that route to make sure the needed capacity is available. Three different kinds of resources can potentially be reserved:
1. Bandwidth.
2. Buffer space.
3. CPU cycles.
CPU cycles are also a scarce resource. It takes router CPU time to process a packet, so a router can process only a certain number of packets per second. 
Making sure that the CPU is not overloaded is needed to ensure timely processing of each packet.

--- Slide 14 ---
Admission Control
When a flow is offered to a router, it has to decide, based on its capacity and how many commitments it has already made for other flows, whether to admit or reject the flow.
Because many parties may be involved in the flow negotiation (the sender, the receiver, and all the routers along the path between them), flows must be described accurately in terms of specific parameters that can be negotiated. A set of such parameters is called a flow specification.

--- Slide 15 ---
Proportional Routing
A different approach that has been proposed to provide a higher quality of service is to split the traffic for each destination over multiple paths.
A simple method is to divide the traffic equally or in proportion to the capacity of the outgoing links.

--- Slide 16 ---
Packet Scheduling
Fair queueing algorithm: 
The essence of the algorithm is that routers have separate queues for each output line, one for each flow. 
When a line becomes idle, the router scans the queues round robin, taking the first packet on the next queue. 
In this way, with n hosts competing for a given output line, each host gets to send one out of every n packets. 

--- Slide 17 ---


--- Slide 18 ---
Internetworking
Issues that arise when two or more networks are connected to form an internet.
First of all, the installed base of different networks is large.
Second, as computers and networks get cheaper, the place where decisions get made moves downward in organizations.
Third, different networks have different technology, so as new hardware developments occur, new software will be created to fit the new hardware.

--- Slide 19 ---
Collection of interconnected networks

--- Slide 20 ---
How Networks Differ
Problems can occur at the interfaces between networks.
The differing maximum packet sizes used by different networks can be a major issue.
Error, flow, and congestion control often differ among different networks.

--- Slide 21 ---


--- Slide 22 ---
How Networks Can Be Connected
In the physical layer, networks can be connected by repeaters or hubs, which just move the bits from one network to an identical network.
One layer up we find bridges and switches, which operate at the data link layer. They can accept frames, examine the MAC addresses, and forward the frames to a different network.
In the network layer, we have routers that can connect two networks. If two networks have dissimilar network layers, the router may be able to translate between the packet formats
A router that can handle multiple protocols is called a multiprotocol router.
In the transport layer we find transport gateways, which can interface between two transport connections. 
In the application layer, application gateways translate message semantics.

--- Slide 23 ---

Two ways of internetworking is possible.(i) a connection-oriented concatenated virtual subnets and (ii) datagram internet. 
In the past most networks were connection oriented. Then with the rapid acceptance of the Internet, datagrams became more popular.
In the concatenated virtual-circuit model a sequence of virtual circuit is set up from the source through one or more gateways to the destination. Each gateway maintains tables telling which virtual circuit pass through it.
In datagrams from one host to other host the packets will be routed in different routes through the inter network. A routing decision is made separately for each packet, possibly depending on the traffic at the moment the packet is sent. This strategy can use multiple routes and thus achieve a higher bandwidth than the concatenated virtual circuit model.

--- Slide 24 ---
The source machine,S, wants to send a packet to the destination machine, D. These machines are on different Ethernets, connected by a switch. S encapsulates the packet in a frame and sends it on its way. The frame arrives at the switch, which then determines that the frame has to go to LAN 2 by looking at its MAC address. The switch just removes the frame from LAN 1 and deposits it on LAN 2.

--- Slide 25 ---
Tunneling
Making two different networks interwork is exceedingly difficult. 
This case is where the source and destination hosts are on the same type of network, but there is a different network in between. The solution to this problem is a technique called tunneling.
To send an IP packet to host 2, host 1 constructs the packet containing the IP address of host 2, inserts it into an Ethernet frame addressed to the Paris multiprotocol router, and puts it on the Ethernet. 
When the multiprotocol router gets the frame, it removes the IP packet, inserts it in the payload field of the WAN network layer packet, and addresses the latter to the WAN address of the London multiprotocol router. 
When it gets there, the London router removes the IP packet and sends it to host 2 inside an Ethernet frame.

--- Slide 26 ---


--- Slide 27 ---


--- Slide 28 ---
Internetwork Routing
Once the graph has been constructed, known routing algorithms, such as the distance vector and link state algorithms, can be applied to the set of multiprotocol routers. 
This gives a two level routing algorithm: within each network an interior gateway protocol is used, but between the networks, an exterior gateway protocol is used (''gateway'' is an older term for ''router''). 
Because each network in an internetwork is independent of all the others, it is often referred to as an Autonomous System (AS).

--- Slide 29 ---
Fragmentation
Break up packets into fragments, sending each fragment as a separate internet packet

--- Slide 30 ---
Transparent fragmentation.:
In this approach, the small-packet network has gateways that interface to other networks. 
When an oversized packet arrives at a gateway, the gateway breaks it up into fragments. 
Each fragment is addressed to the same exit gateway, where the pieces are recombined. 
In this way passage through the small-packet network has been made transparent. Subsequent networks are not even aware that fragmentation has occurred.

--- Slide 31 ---

Problem:
when it has received all the pieces, so either a count field or an ''end of packet'' bit must be provided. 
For another thing, all packets must exit via the same gateway.
A last problem is the overhead required to repeatedly reassemble and then refragment a large packet passing through a series of small-packet networks. 

--- Slide 32 ---

Nontransparent fragmentation:
The other fragmentation strategy is to refrain from recombining fragments at any intermediate gateways. 
Once a packet has been fragmented, each fragment is treated as though it were an original packet. 
Recombination occurs only at the destination host. IP works this way.


--- Slide 33 ---
Problem:
it requires every host to be able to do reassembly. 
 another problem is that when a large packet is fragmented, the total overhead increases because each fragment must have a header. 
An advantage :
multiple exit gateways can now be used and higher performance can be achieved. 

--- Slide 34 ---


--- Slide 35 ---


--- Slide 36 ---
Integrated Services 
Integrated Services (IntServ) was developed by the IETF between 1995 and 1997 to support streaming multimedia, such as video and audio, over the Internet.
It aimed to provide Quality of Service (QoS) by reserving network resources for specific data flows.
The system was designed for both unicast (one-to-one) and multicast (one-to-many) communication.
In multicast, users can join or leave a group dynamically—like people entering or exiting a video conference.
Because of these changing group memberships, pre-reserving bandwidth for all receivers is impractical, especially for large audiences.

--- Slide 37 ---
RSVP—The Resource reSerVation Protocol
To solve this, the IETF introduced the Resource reSerVation Protocol (RSVP), described in RFC 2205.
RSVP handles the reservation of resources such as bandwidth along the communication path but does not transmit data itself.
It allows multiple senders and receivers to communicate efficiently while avoiding network congestion.
RSVP operates over multicast routing, where each group is assigned a group address and packets are sent along a spanning tree connecting all members.
The main difference from normal multicast is that RSVP sends extra control messages to routers so they can maintain the necessary data structures for QoS reservations.

--- Slide 38 ---

As an example, consider the network of Fig. (a) . Hosts 1 and 2 are multicast senders, and hosts 3, 4, and 5 are multicast receivers. In this example, the senders and receivers are disjoint, but in general, the two sets may overlap. The multicast trees for hosts 1 and 2 are shown in Fig. (b) and Fig. (c) , respectively. 

--- Slide 39 ---

Any receiver in a multicast group can send a reservation message toward the sender to request better reception and avoid congestion.
This message travels up the spanning tree using the reverse path forwarding algorithm, and each router along the way reserves the required bandwidth.
If all routers along the path can reserve the needed bandwidth, a complete end-to-end reservation is established; otherwise, the receiver is informed of the failure.

--- Slide 40 ---
An example of such a reservation is shown in Fig. 5-38(a) . Here host 3 has requested a channel to host 1. Once it has been established, packets can flow from 1 to 3 without congestion. Now consider what happens if host 3 next reserves a channel to the other sender, host 2, so the user can watch two television programs at once. A second path is reserved, as illustrated in Fig. 5-38(b) . Note that two separate channels are needed from host 3 to router E because two independent streams are being transmitted. 
Finally, in Fig. 5-38(c) , host 5 decides to watch the program being transmitted by host 1 and also makes a reservation. First, dedicated bandwidth is reserved as far as router H. However, this router sees that it already has a feed from host 1, so if the necessary bandwidth has already been reserved, it does not have to reserve any more. Note that hosts 3 and 5 might have asked for different amounts of bandwidth (e.g., 3 has a black-and-white television set, so it does not want the color information), so the capacity reserved must be large enough to satisfy the greediest receiver. 

--- Slide 41 ---

When making a reservation, a receiver can specify which source(s) it wants to receive data from and indicate whether these sources are fixed or can be changed later.
Routers use this information to plan bandwidth efficiently—shared paths are created only if all receivers agree not to change sources later.
In the dynamic case, reserved bandwidth is independent of the source, allowing receivers to switch between sources (like different video streams) without needing a new reservation.


--- Slide 42 ---
The Network Layer in the Internet
Principles of Network Layer:
1. Make sure it works. Do not finalize the design or standard until multiple prototypes have successfully communicated with each other.
2. Keep it simple. When in doubt, use the simplest solution.
3. Make clear choices. If there are several ways of doing the same thing, choose one. Having two or more ways to do the same thing is looking for trouble.
4. Exploit modularity. This principle leads directly to the idea of having protocol stacks, each of whose layers is independent of all the other ones. In this way, if circumstances that require one module or layer to be changed, the other ones will not be affected.

--- Slide 43 ---

5. Expect heterogeneity. Different types of hardware, transmission facilities, and applications will occur on any large network. To handle them, the network design must be simple, general, and flexible.
6. Avoid static options and parameters. If parameters are unavoidable (e.g.,maximum packet size), it is best to have the sender and receiver negotiate a value than defining fixed choices.
7. Look for a good design; it need not be perfect. Often the designers have a good design but it cannot handle some weird special case. Rather than messing up the design, the designers should go with the good design and put the burden of working around it on the people with the strange requirements.

--- Slide 44 ---

8. Be strict when sending and tolerant when receiving. In other words, only send packets that rigorously comply with the standards
9. Think about scalability. If the system is to handle millions of hosts and billions of users effectively, no centralized databases of any kind are tolerable and load must be spread as evenly as possible over the available resources.
10. Consider performance and cost. If a network has poor performance or outrageous costs, nobody will use it.

--- Slide 45 ---
IP (Internet Protocol)
The glue that holds the whole Internet together is the network layer protocol, IP (Internet Protocol).
Its job is to provide a best-efforts way to transport datagrams from source to destination, without regard to whether these machines are on the same network or whether there are other networks in between them.
Communication in the Internet works as follows:
Each datagram is transmitted, after getting from Transport layer, through the Internet, possibly being fragmented into smaller units as it goes. 
When all pieces finally get to the destination machine, they are reassembled by the network layer into the original datagram.


--- Slide 46 ---
The IP Protocol
IP transports data in packets called Datagrams, each of which is transported separately. 
Datagrams may travel along different routes and may arrive out of sequence or duplicated. IP does not create virtual circuits for delivery.
Packets in IP layer are called Datagrams. 



--- Slide 47 ---
IPV4
An IP datagram consists of a header part and a text part. 
The header has a 20-byte fixed part and a variable length optional part. 


--- Slide 48 ---


--- Slide 49 ---


--- Slide 50 ---


--- Slide 51 ---
Version 
The first field defines the version number of the IP. 
The current version is 4(IPv4),with binary value 0100.
Header length (HLEN)    
 The HLEN field defines the length of the header in multiples of four bytes .
The four bits can represent a number between 0 to 15,which,when multiplied by 4,gives a maximum of 60 bytes.
Service Type 
The service type field defines how datagram should be handled. 
It includes bits that define the priority of the datagram. Precedence (3 bits): Priority (0–7). D, T, R flags: Delay, Throughput, Reliability preferences.
It also contains bits that specify the type of service the sender desires such as the level of throughput, reliability, and delay
Total Length 
The total length field defines the total length of the IP datagram. 
It is a two-byte field (16 bits) and can define up to 65,535 bytes.


--- Slide 52 ---
Identification 
The identification field is used in fragmentation. 
A datagram, when passing through different networks, may be divided into fragments to match the network frame size. 
All fragments share the same identification number.
Flags
The bits in the flags field deal with fragmentation (the datagram can or can not be fragmented; can be first, middle, or last fragment; etc.).
DF (Don’t Fragment): Prevents routers from fragmenting the packet.
MF (More Fragments): Set on all fragments except the last.
Helps manage fragmentation and reassembly.
Fragmentation offset   
The fragmentation offset is a pointer that shows the offset of the data in the original datagram (if it is fragmented).
The Fragment offset tells where in the current datagram this fragment belongs.


--- Slide 53 ---
Time to live 
The time to live field defines the number of hops a datagram can travel before it is discarded. 
The source host, when it creates the datagram, sets this field to an initial value. 
Then, as the datagram travels through the Internet, router by router, each router decrements this value by 1. 
If this value becomes 0 before the datagram reaches its final destination, the datagram is discarded. 
This prevents a datagram from going back and forth forever between routers.
Protocol 
The protocol field defines which upper-layer protocol data are encapsulated in datagram (TCP, UDP, ICMP etc.).
Header Checksum 
Verifies errors in the header only.
This is a 16-bit field used to check the integrity of the header, not the rest of the packet.
Source address 
The source address field is a four-byte (32-bit) Internet address. 
It identifies the original source of the datagram.
Destination address 
The destination address field is a four-byte (32-bit) Internet address. 
It identifies the final destination of the datagram.
Options
 The options field gives more functionality to IP datagram. 
It can carry fields that control routing, timing, management, timestamp and alignment

--- Slide 54 ---
IP Addresses
IP address is a numeric identifier assigned to each machine on the internet. 
IP address consists of two parts: network ID(NID) and host ID(HID). 
NID identifies the network to which the host is connected. All the hosts connected to the same network have the same NID. 
HID is used to uniquely identify a host on that network. 
HID is assigned by the network-administrator at the local site. 
NID for an organization may be assigned by the ISP (Internet Service Provider). 
IPv4 uses 32-bit addresses, i.e., approximately 4 billion addresses (232). 
IP addresses are usually written in dotted-decimal notation. The address is broken into four bytes. 
For example, an IP address of 10000000 10000111 01000100 00000101 is written as 128.135.68.5 

--- Slide 55 ---

The combination is unique: in principle, no two machines on the Internet have the same IP address. 
IP address does not actually refer to a host. It really refers to a network interface, so if a host is on two networks, it must have two IP addresses. However, in practice, most hosts are on one network and thus have one IP address.
All IP addresses are 32 bits long and are used in the Source address and Destination address fields of IP packets. 
IP address can be classified as 
Classful IP addressing & Classless IP addressing (CIDR- Classless Inter Domain Routing)



--- Slide 56 ---
IPv4 Classful Addressing 
In classful addressing, the address space is divided into five classes: 
A, B, C, D and E. 
Classes A, B and C are used for unicast addressing. 
Class D was designed for multicasting and class E is reserved. 
The class A, B, C formats allow for up to 
128 networks with 16 million hosts each,
16,384 networks with up to 64K hosts, and 
2 million networks (e.g., LANs) with up to 256 hosts each. 
Addresses beginning with 1111 are reserved for future use.
Network numbers are managed by a nonprofit corporation called ICANN (Internet Corporation for Assigned Names and Numbers) to avoid conflicts. 
ICANN has delegated parts of the address space to various regional authorities, which then dole out IP addresses to ISPs and other companies.




--- Slide 57 ---


--- Slide 58 ---

Problem with classful addressing: 
Consider an organization has a Class B address which can support about 64,000 hosts. 
 It will be a huge task for the network-administrator to manage all 64,000 hosts. 
Solution: Use Subnetting(subnets)
Subnetting is the process or a technique of dividing  a large network into smaller, more manageable parts called as subnets
It reduces the total number of network-numbers by assigning a single network-number to many adjacent physical networks. Each adjacent physical network is referred to as subnet. 
All nodes on a subnet are configured with a subnet mask. For example: 255.255.255.0. 
The bitwise AND of IP address and its subnet mask gives the subnet number. 
Advantage: The subnet-addressing scheme is hidden to the network outside the organization. 
Inside the organization the network-administrator is free to choose any combination of lengths for the subnet & host ID fields. 

--- Slide 59 ---
Subnets

--- Slide 60 ---


--- Slide 61 ---
Subnets 
The individual smaller network created as a result of subnetting
As the network grows, it is allowed a network to be split into several parts for internal use but still act like a single network to the outside world. 
In the Internet literature, the parts of the network (in this case, Ethernets) are called subnets. 
To implement subnetting, the main router needs a subnet mask that indicates the split between network + subnet number and host, 
Subnet masks are also written in dotted decimal notation, with the addition of a slash followed by the number of bits in the network + subnet part. For the example of Fig. the subnet mask can be written as 255.255.252.0. An alternative notation is /22 to indicate that the subnet mask is 22 bits long. 

--- Slide 62 ---

Problem with classful IP addressing: 
Consider an organization needs about 500 hosts. 
Obviously, the organization will get a Class B license, even though it has far fewer than 64,000 hosts. 
At most, over 64,000 addresses can go unused. 
This results in inefficient usage of the available address-space. 
Solution: Use CIDR (Classless Inter Domain Routing). 
CIDR addresses 
 reduce the size of routing-tables 
make more IP addresses available within organizations. 


--- Slide 63 ---
CIDR (Classless Interdomain Routing) 
The basic idea behind CIDR, is to allocate the remaining IP addresses in variable-sized blocks, without regard to the classes. 
CIDR (Classless Inter-Domain Routing) is a system introduced in 1993 to replace the old classful IP addressing system (Classes A, B, and C).
It allows for flexible allocation of IP addresses and efficient routing of packets on the internet.
CIDR allows variable-length subnet masks, so you can choose exactly how many bits are used for the network and host parts.
Using CIDR, each IP address has a network prefix that identifies either one or several network gateways. The length of the network prefix in IPv4. 
CIDR is also specified as part of the IP address and varies depending on the number of bits needed, rather than any arbitrary class assignment structure. 



--- Slide 64 ---

CIDR is written as:
<IP address>/<prefix length>
Example:
192.168.1.0/24
/24 means the first 24 bits are network bits.
Subnet mask = 255.255.255.0


--- Slide 65 ---
NAT 
Network Address Translation (NAT) enables hosts to use Internet without the need to have globally unique addresses. 
NAT enables organization to have a large set of addresses internally and one address externally. 
The organization must have single connection to the Internet through a NAT-enabled router. 
NAT allows a single device (such as a router) to act as an agent b/w internet (or "public network") and local (or "private") network. 
This means only a single, unique IP address is required to represent an entire group of computers. 
The private addresses only have meaning to devices within a given network. 
The NAT-enabled router does not look like a router to the outside world. 
Instead, the NAT-enabled router behaves to the outside world as a single device with a single IP address. 



--- Slide 67 ---
Internet Control Protocols-Internet Control Message Protocol (ICMP) 
ICMP is used by hosts and routers to communicate network- layer information to each other. The most typical use of ICMP is for error reporting. 
ICMP is part of IP but architecturally it lies just above IP hence ICMP messages are carried inside IP datagrams. That is, ICMP messages are carried as IP payload.
ICMP messages have a type and a code field, and contain the header and the first 8 bytes of the IP datagram
The well-known ping program sends an ICMP type 8 code 0 message to the specified host. The destination host, seeing the echo request, sends back a type 0 code 0 ICMP echo reply. 
Congested router send an ICMP source quench message to a host to force that host to reduce its transmission rate. 


--- Slide 68 ---


--- Slide 69 ---


--- Slide 70 ---

Obtaining a Host Address: DHCP 
Two ways to assign an IP address to a host: 

1) Manual Configuration 
Operating systems allow system-administrator to manually configure IP address. 
2) Dynamic Host Configuration Protocol (DHCP) 
DHCP enables auto-configuration of IP address to host. 

--- Slide 71 ---
DHCP Protocol 
DHCP enables auto-configuration of IP address to host. 
DHCP assigns dynamic IP addresses to devices on a network. 
Dynamic address allocation is required when a host moves from one network to another or when a host is connected to a network for the first time. 
Because of DHCP’s ability to automate the network-related aspects of connecting a host into a network, it is often referred to as a plug-and-play protocol. 
DHCP is a client-server protocol. 
A client is typically a newly arriving host wanting to obtain network configuration information, including an IP address for itself. 
In the simplest case, each subnet will have a DHCP server. 
If no server is present on the subnet, a DHCP relay agent (typically a router) that knows the address of a DHCP server for that network.
DHCP server attached to subnet 223.1.2/24, with the router serving as the relay agent for arriving clients attached to subnets 223.1.1/24 and 223.1.3/24. 

--- Slide 72 ---


--- Slide 73 ---

DHCP server discovery. 
The first task of a newly arriving host is to find a DHCP server with which to interact. 
This is done using a DHCP discover message, which a client sends within a UDP packet to port 67. 
The UDP packet is encapsulated in an IP datagram. 
DHCP client creates an IP datagram containing its DHCP discover message along with the broadcast destination IP address of 255.255.255.255 and a “this host” source IP address of 0.0.0.0. 
The DHCP client passes the IP datagram to the link layer, which then broadcasts this frame to all nodes attached to the subnet. 


--- Slide 74 ---

DHCP server offer(s). 
A DHCP server receiving a DHCP discover message responds to the client with a DHCP offer message that is broadcast to all nodes on the subnet, again using the IP broadcast address of 255.255.255.255. 
DHCP server broadcasts DHCPOFFER message containing 
1. Client's IP address 
2. Network mask 
3. IP address lease time (i.e. the amount of time for which the IP address will be valid). 


--- Slide 75 ---
DHCP request. 
The newly arriving client will choose from among one or more server offers and respond to its selected offer with a DHCP request message, echoing back the configuration parameters. 
DHCP ACK. 
The server responds to the DHCP request message with a DHCP ACK message, confirming the requested parameters. 


--- Slide 76 ---
ARP—The Address Resolution Protocol
ARP is used to map an IP address to a physical (MAC) address on a local network.
It is defined in RFC 826 and is used by almost every machine on the Internet.
ARP simplifies configuration since only IP addresses and subnet masks need to be assigned.
When a host sends a packet, ARP helps find the receiver’s Ethernet address and builds the frame for transmission.
Once a mapping is found, it is stored in an ARP cache to avoid repeating the same broadcast.

--- Slide 77 ---

Hosts can learn each other’s IP-to-MAC mappings from ARP replies, reducing future broadcasts.
When a machine boots, it can broadcast its mapping to fill ARP caches and detect duplicate IP addresses.
ARP cache entries automatically expire after a few minutes to allow updates if hardware changes.
If the destination is on another network, a router can respond to ARP requests on behalf of remote hosts—this is proxy ARP.
For distant networks, packets are sent to the default router, which uses routing tables and ARP on other networks to deliver them to the final host.

--- Slide 78 ---
small university with several class C (now called /24) networks is illustrated. Here we have two Ethernets, one in the Computer Science Dept., with IP address 192.31.65.0 and one in Electrical Engineering, with IP address 192.31.63.0. 
These are connected by a campus backbone ring (e.g., FDDI) with IP address 192.31.60.0. Each machine on an Ethernet has a unique Ethernet address, labeled E1 through E6, and each machine on the FDDI ring has an FDDI address, labeled F1 through F3.

--- Slide 79 ---

A better solution is for host 1 to output a broadcast packet onto the Ethernet asking: Who owns IP address 192.31.65.5? 
The broadcast will arrive at every machine on Ethernet 192.31.65.0, and each one will check its IP address. Host 2 alone will respond with its Ethernet address (E2). 
In this way host 1 learns that IP address 192.31.65.5 is on the host with Ethernet address E2. The protocol used for asking this question and getting the reply is called ARP (Address Resolution Protocol). Almost every machine on the Internet runs it.
The advantage of using ARP over configuration files is the simplicity. The system manager does not have to do much except assign each machine an IP address and decide about subnet masks. ARP does the rest.

--- Slide 80 ---

At this point, the IP software on host 1 builds an Ethernet frame addressed to E2, puts the IP packet (addressed to 192.31.65.5) in the payload field, and dumps it onto the Ethernet. The Ethernet board of host 2 detects this frame, recognizes it as a frame for itself, scoops it up, and causes an interrupt. The Ethernet driver extracts the IP packet from the payload and passes it to the IP software, which sees that it is correctly addressed and processes it.
Ex: host 1 wants to send a packet to host 4 (192.31.63.8). Using ARP will fail because host 4 will not see the broadcast (routers do not forward Ethernet-level broadcasts). There are two solutions. First, the CS router could be configured to respond to ARP requests for network 192.31.63.0 (and possibly other local networks). In this case, host 1 will make an ARP cache entry of (192.31.63.8, E3) and happily send all traffic for host 4 to the local router. This solution is called proxy ARP.

--- Slide 81 ---
OSPF—The Interior Gateway Routing Protocol 
The Internet consists of many autonomous systems (ASes), each managed by different organizations using their own internal routing methods.
Routing within an AS uses an Interior Gateway Protocol (IGP), while routing between ASes uses an Exterior Gateway Protocol (EGP).
The original IGP used in the Internet was RIP (Routing Information Protocol), a distance vector protocol based on the Bellman-Ford algorithm.
RIP worked for small networks but had issues like slow convergence and the count-to-infinity problem as networks grew larger.
To overcome these issues, RIP was replaced in 1979 by a link state protocol, and later improved to OSPF (Open Shortest Path First) in 1990.
OSPF was developed by the Internet Engineering Task Force (IETF) and is defined in RFC 2328.

--- Slide 82 ---
Requirements for OSPF
First, the algorithm had to be published in the open literature, hence the ''O'' in OSPF. publicly available, not proprietary.
Second, the new protocol had to support a variety of distance metrics, including physical distance, delay, and so on. 
Third, it had to be a dynamic algorithm, one that adapted to changes in the topology automatically and quickly.
Fourth, and new for OSPF, it had to support routing based on type of service. The new protocol had to be able to route real-time traffic one way and other traffic a different way. 
Fifth, and related to the above, the new protocol had to do load balancing, splitting the load over multiple lines
Sixth, support for hierarchical systems was needed.
Seventh, some level of security was required

--- Slide 83 ---

Area is a network or a set of contiguous networks.
Every AS has a backbone area, called area 0. All areas are connected to the backbone, possibly by tunnels,
OSPF distinguishes four classes of routers:
1. Internal routers are wholly within one area.
2. Area border routers connect two or more areas.
3. Backbone routers are on the backbone.
4. AS boundary routers talk to routers in other ASes.

--- Slide 84 ---


--- Slide 85 ---

OSPF represents the entire network as a directed graph, where routers and networks are nodes connected by arcs with assigned costs such as distance or delay.
It calculates the shortest path between routers using the link costs to determine the most efficient routes.
Large networks are divided into areas, each containing routers and networks that are close together to simplify routing management.
Every OSPF system has a backbone area (area 0) that connects all other areas, and all interarea communication passes through this backbone.
Routers that connect multiple areas are known as area border routers, while those on the backbone are called backbone routers.
OSPF supports three types of routing: intra-area (within an area), interarea (between areas), and inter-AS (between different autonomous systems).

--- Slide 86 ---
Using flooding, each router informs all the other routers in its area of its neighbors and costs. 
This information allows each router to construct the graph for its area(s) and compute the shortest path. The backbone area does this too. 
In addition, the backbone routers accept information from the area border routers in order to compute the best route from each backbone router to every other router. This information is propagated back to the area border routers, which advertise it within their areas.

--- Slide 87 ---
BGP—The Exterior Gateway Routing Protocol 
BGP stands for Border Gateway Protocol, which is used to exchange routing information between different Autonomous Systems (ASes) on the Internet.
It acts as an Exterior Gateway Protocol (EGP), meaning it operates between organizations or administrative domains, not within them.
In contrast, Interior Gateway Protocols (IGPs) like OSPF or RIP are used inside a single AS to manage internal routing efficiently.
The main objective of BGP is to manage routing between organizations that have their own policies, rather than just finding the shortest or quickest path.
BGP takes into account political, economic, and security considerations when selecting routes between different networks.

--- Slide 88 ---

For instance, some networks may refuse to carry transit traffic between foreign networks or may only carry traffic for paying customers.
Such routing decisions are manually configured by network administrators and are not automatically handled by the BGP protocol itself.
From a BGP router’s point of view, the Internet looks like a graph of multiple ASes interconnected through border routers.
Two ASes are considered connected if there is a physical or logical link between their border routers.
BGP networks are divided into three categories based on how they handle transit traffic: stub, multiconnected, and transit networks.
Stub networks have only one connection to another AS and therefore cannot carry traffic for other networks.
Multiconnected networks have multiple external connections but do not allow transit traffic to pass through them.
Transit networks, such as Internet backbones, allow data from other networks to pass through, often for commercial reasons.

--- Slide 89 ---
BGP routers exchange routing information using TCP connections, which ensure reliable delivery and error-free communication.
Unlike traditional distance vector protocols such as RIP, BGP advertises the entire AS path to a destination rather than just the cost or distance.
This path information allows routers to clearly identify the route that data will take and helps in detecting routing loops.
When multiple routes are available, BGP uses a scoring system based on local administrative preferences to select the best path.
Any route that violates an organization’s policy is given an infinite cost and is automatically discarded.
Because BGP routers know complete paths, they can easily detect loops and avoid the count-to-infinity problem common in simpler distance vector protocols.
BGP serves as the policy-based backbone of interdomain routing, allowing millions of networks to interconnect globally while following their own business, political, and security policies — as formally defined in RFCs 1771 to 1774.

--- Slide 90 ---

After all the paths come in from the neighbors, F examines them to see which is the best. It quickly discards the paths from I and E, since these paths pass through F itself. The choice is then between using B and G. Every BGP router contains a module that examines routes to a given destination and scores them, returning a number for the ''distance'' to that destination for each route.

--- Slide 91 ---
IPv6
Its major goals were:
1. Support billions of hosts, even with inefficient address space allocation.
2. Reduce the size of the routing tables.
3. Simplify the protocol, to allow routers to process packets faster.
4. Provide better security (authentication and privacy) than current IP.
5. Pay more attention to type of service, particularly for real-time data.
6. Aid multicasting by allowing scopes to be specified.
7. Make it possible for a host to roam without changing its address.
8. Allow the protocol to evolve in the future.
9. Permit the old and new protocols to coexist for years.

--- Slide 92 ---

A modified combined version of the Deering and Francis proposals, by now called SIPP (Simple Internet Protocol Plus) was selected and given the designation IPv6.
IPv6 meets the goals fairly well. It maintains the good features of IP, discards or deemphasizes the bad ones, and adds new ones where needed. 
In general, IPv6 is not compatible with IPv4, but it is compatible with the other auxiliary Internet protocols, including TCP, UDP, ICMP, IGMP, OSPF, BGP, and DNS, sometimes with small modifications being required

--- Slide 93 ---
The main features of IPv6:
1)IPv6 has longer addresses than IPv4. They are 16 bytes long, which solves the problem that IPv6 set out to solve: provide an effectively unlimited supply of Internet addresses. 
2) simplification of the header. It contains only seven fields (versus 13 in IPv4). This change allows routers to process packets faster and thus improve throughput and delay.
3)The third major improvement was better support for options. This change was essential with the new header because fields that previously were required are now optional. In addition, the way options are represented is different, making it simple for routers to skip over options not intended for them. This feature speeds up packet processing time.
4) IPv6 represents a big advance is in security.
5)more attention has been paid to quality of service.


--- Slide 94 ---


--- Slide 95 ---

The Version field is always 6 for IPv6 (and 4 for IPv4).
 The Traffic class field is used to distinguish between packets with different real-time delivery requirements.
The Flow label field provides a way for a source and destination to mark groups of packets that have the same requirements and should be treated in the same way by the network,

--- Slide 96 ---

The Payload length field tells how many bytes follow the 40-byte header .The name was changed from the IPv4 Total length field because the meaning was changed slightly: the 40 header bytes are no longer counted as part of the length.
The Next header field :The reason the header could be simplified is that there can be additional (optional) extension headers. This field tells which of the (currently) six extension headers, if any, follow this one. If this header is the last IP header, the Next header field tells which transport protocol handler (e.g., TCP, UDP) to pass the packet to.

--- Slide 97 ---

The Hop limit field is used to keep packets from living forever. It is, in practice, the same as the Time to live field in IPv4, namely, a field that is decremented on each hop. 
Next come the Source address and Destination address fields. Deering's original proposal, SIP, used 8-byte addresses, but during the review process many people felt that with 8-byte addresses IPv6 would run out of addresses within a few decades, whereas with 16-byte addresses it would never run out.
Finally, the Checksum field is gone because calculating it greatly reduces performance


================================================================================
FILE: module 4.pptx
================================================================================

--- Slide 1 ---
Module 4The Transport Layer

--- Slide 2 ---

The Transport Service: Services Provided to the Upper Layers, Transport Service Primitives, An Example of Socket Programming. Elements of Transport Protocols: Addressing, Connection Establishment, Connection Release. The Internet Transport Protocols (UDP and TCP): Introduction to UDP, Introduction to TCP, The TCP Service Model, The TCP Protocol, The TCP Segment Header, TCP Connection Establishment, TCP Connection Release, and Sliding Window protocols. 
Chapter 6: 6.1,6.2,6.4,6.5

--- Slide 3 ---
Transport Service-Services Provided to the Upper Layers 
Together with the network layer, the transport layer is the heart of the protocol hierarchy.
The network layer provides end-to-end packet delivery using datagrams or virtual circuits. The transport layer builds on the network layer to provide data transport from a process on a source machine to a process on a destination machine with a desired level of reliability that is independent of the physical networks currently in use.
It provides the abstractions that applications need to use the network.
The ultimate goal of the transport layer is to provide efficient, reliable, and cost-effective service to its users, normally processes in the application layer.
To achieve this goal, the transport layer makes use of the services provided by the network layer. 
The hardware and/or software within the transport layer that does the work is called the transport entity. 
The transport entity can be located in the operating system kernel, in a separate user process, in a library package bound into network applications, or on the network interface card.

--- Slide 4 ---
Transport Service-Services Provided to the Upper Layers 
The bottom four layers can be seen as the transport service provider, whereas the upper layer(s) are the transport service user.
To allow users to access the transport service, the transport layer must provide some operations to application programs, that is, a transport service interface. Each transport service has its own interface.
TPDU (Transport Protocol Data Unit) used for messages sent from transport entity to transport entity.
there are two types of network service, connection-oriented and connectionless, there are also two types of transport service. 
The connection-oriented transport service is similar to the connection-oriented network service in many ways. 
In both cases, connections have three phases: establishment, data transfer, and release. 
Addressing and flow control are also similar in both layers. 
Furthermore, the connectionless transport service is also very similar to the connectionless network service. 

--- Slide 5 ---


--- Slide 6 ---
Transport Service Primitives
Packets are contained in frames .When a frame arrives, the data link layer processes the frame header and passes the contents of the frame payload field up to the network entity. 
The network entity processes the packet header and passes the contents of the packet payload up to the transport entity.

--- Slide 7 ---

To allow users to access the transport service, the transport layer must provide some operations to application programs, that is, a transport service interface. Each transport service has its own interface. 
The transport service is similar to the network service, but there are also some important differences. The main difference is that the network service is intended to model the service offered by real networks and all. Real networks can lose packets, so the network service is generally unreliable. 
The connection-oriented transport service, in contrast, is reliable. Of course, real networks are not error-free, but that is precisely the purpose of the transport layer—to provide a reliable service on top of an unreliable network.
A second difference between the network service and transport service is that the services are intended for. The network service is used only by the transport entities. Few users write their own transport entities, and thus few users or programs ever (meaning always/forever/still) see the bare network service




--- Slide 9 ---
Sockets were first released as part of the Berkeley UNIX 4.2BSD software distribution in 1983. They quickly became popular. The primitives are now widely used for Internet programming on many operating system.
Socket Programming is a method to connect two nodes over a network to establish a means of communication between those two nodes. A node represents a computer or a physical device with an internet connection. 
A socket is the endpoint used for connecting to a node. The signals required to implement the connection between two nodes are sent and received using the sockets on each node respectively.

Berkeley Sockets

--- Slide 10 ---
Berkeley Sockets
the socket primitives used in Berkeley UNIX for TCP, These primitives are widely used for Internet programming

--- Slide 11 ---
Server side
The SOCKET primitive creates a new end point and allocates table space for it within the transport entity.
A successful SOCKET call returns an ordinary file descriptor for use in succeeding calls.
Newly-created sockets do not have network addresses. These are assigned using the BIND primitive. Once a server has bound an address to a socket, remote clients can connect to it.
Next comes the LISTEN call, which allocates space to queue incoming calls for the case that several clients try to connect at the same time. 

--- Slide 12 ---

To block waiting for an incoming connection, the server executes an ACCEPT primitive. When a TPDU asking for a connection arrives, the transport entity creates a new socket with the same properties as the original one and returns a file descriptor for it.
ACCEPT returns a normal file descriptor, which can be used for reading and writing in the standard way, the same as for files.

--- Slide 13 ---
Client side
a socket must first be created using the SOCKET primitive, but BIND is not required since the address used does not matter to the server.
The CONNECT primitive blocks the caller and actively starts the connection process. When it completes (i.e., when the appropriate TPDU is received from the server), the client process is unblocked and the connection is established.
Both sides can now use SEND and RECV to transmit and receive data over the full-duplex connection. The standard UNIX READ and WRITE system calls can also be used if none of the special options of SEND and RECV are required.
Connection release with sockets is symmetric. When both sides have executed a CLOSE primitive, the connection is released.

--- Slide 14 ---
An example for socket programming(lab program)
The nodes are divided into two types, server node and client node.
The client node sends the connection signal and the server node receives the connection signal sent by the client node.
The connection between a server and client node is established using the socket over the transport layer of the internet.
After a connection has been established, the client and server nodes can share information between them using the read and write commands.
After sharing of information is done, the nodes terminate the connection.


--- Slide 15 ---


--- Slide 16 ---
Elements of Transport Protocols
For another thing, the process of establishing a connection over the wire is simple: the other end is always there . 
In the transport layer, initial connection establishment is more complicated.
difference between the data link layer and the transport layer is the potential existence of storage capacity in the subnet.
A final difference between the data link and transport layers is ,In the transport layer, the larger number of connections that must be managed

--- Slide 17 ---
(a) Environment of the data link layer. (b) Environment of the transport layer.

--- Slide 18 ---

Addressing
Data Link Layer: Each outgoing line connects to a specific router, so it doesn’t need to specify an address—the destination is implied.
Transport Layer: Must explicitly specify the destination address, since multiple processes or applications may be communicating.
Connection Establishment
Data Link Layer: Establishing a connection is simple—the other end is always there unless it has failed.
Transport Layer: More complex, as it must handle initial handshakes, error checking, and possibly negotiate parameters before communication.
Storage and Delay in the Subnet
Data Link Layer: Frames are either delivered or lost; they don’t get delayed unpredictably.
Transport Layer: Packets can be stored temporarily in the network (due to adaptive routing or congestion) and delivered late, which can disrupt communication. Special protocols are needed to handle such cases.
Buffering and Flow Control
Data Link Layer: Usually deals with a small number of lines, so fixed buffers per line are manageable.
Transport Layer: Handles many simultaneous connections, so dynamic buffer allocation and more sophisticated flow control mechanisms are needed.

--- Slide 19 ---
Elements of Transport Protocols
Addressing
Connection Establishment
Connection Release 
Flow Control and Buffering 
Multiplexing
Crash Recovery

--- Slide 20 ---
1.Connection Establishment
Three-way handshake:This establishment protocol does not require both sides to begin sending with the same sequence number, so it can be used with synchronization methods other than the global clock method.
Three protocol scenarios for establishing a connection  using a three-way handshake. CR denotes CONNECTION REQUEST. 
(a) Normal operation. 
(b) Old duplicate CONNECTION REQUEST appearing out of nowhere. 
(c) Duplicate CONNECTION REQUEST and duplicate ACK.

--- Slide 21 ---


--- Slide 22 ---

Case1:Host 1 chooses a sequence number, x, and sends a CONNECTION REQUEST TPDU containing it to host 2. Host 2 replies with an ACK TPDU acknowledging x and announcing its own initial sequence number, y. Finally, host 1 acknowledges host 2's choice of an initial sequence number in the first data TPDU that it sends.
Case 2:first TPDU is a delayed duplicate CONNECTION REQUEST from an old connection. This TPDU arrives at host 2 without host 1's knowledge. Host 2 reacts to this TPDU by sending host 1 an ACK TPDU, in effect asking for verification that host 1 was indeed trying to set up a new connection. When host 1 rejects host 2's attempt to establish a connection, host 2 realizes that it was tricked by a delayed duplicate and abandons the connection. In this way, a delayed duplicate does no damage.
Case 3:host 2 gets a delayed CONNECTION REQUEST and replies to it. At this point it is crucial to realize that host 2 has proposed using y as the initial sequence number for host 2 to host 1 traffic, knowing full well that no TPDUs containing sequence number y or acknowledgements to y are still in existence. When the second delayed TPDU arrives at host 2, the fact that z has been acknowledged rather than y tells host 2 that this, too, is an old duplicate. 

--- Slide 23 ---
2.Connection Release
There are two styles of terminating a connection: asymmetric release and symmetric release. 
Asymmetric release is the way the telephone system works: when one party hangs up, the connection is broken. 
Symmetric release treats the connection as two separate unidirectional connections and requires each one to be released separately.
EX: After the connection is established, host 1 sends a TPDU that arrives properly at host 2. Then host 1 sends another TPDU. Unfortunately, host 2 issues a DISCONNECT before the second TPDU arrives. The result is that the connection is released and data are lost.

--- Slide 24 ---
Four protocol scenarios for releasing a connection. (a) Normal case of three-way handshake. (b) Final ACK lost. (c) Response lost. (d) Response lost and subsequent DRs lost.

--- Slide 25 ---

Case 1:normal case in which one of the users sends a DR (DISCONNECTION REQUEST) TPDU to initiate the connection release. When it arrives, the recipient sends back a DR TPDU, too, and starts a timer, just in case its DR is lost. When this DR arrives, the original sender sends back an ACK TPDU and releases the connection. Finally, when the ACK TPDU arrives, the receiver also releases the connection. Releasing a connection means that the transport entity removes the information about the connection from its table of currently open connections and signals the connection's owner
Case 2:Now consider the case of the second DR being lost. The user initiating the disconnection will not receive the expected response, will time out, and will start all over again. If the final ACK TPDU is lost, the situation is saved by the timer. When the timer expires, the connection is released anyway.
 Case 3: assuming that the second time no TPDUs are lost and all TPDUs are delivered correctly and on time.
Case 4: assuming that all the repeated attempts to retransmit the DR also fail due to lost TPDUs. After N retries, the sender just gives up and releases the connection. Meanwhile, the receiver times out and also exits.

--- Slide 26 ---
3.Addressing
When an application process (such as a user program) wants to communicate with a remote application, it must specify which process on the remote system to connect to. This applies to both connection-oriented and connectionless transport services — each message or connection must know where it’s going.
Transport Addresses (TSAPs):
To handle this, transport protocols define transport addresses, also called Transport Service Access Points (TSAPs).
Each process that wishes to receive communication listens on a specific TSAP.
In the Internet, these are known as ports.
In ATM networks, they are called AAL-SAPs. Thus, “TSAP” is a general term for these transport-level endpoints.
The corresponding concept in the network layer is the Network Service Access Point (NSAP) — for example, IP addresses serve as NSAPs.
IP address → identifies which device (host) on the network.
Port number → identifies which process or service on that device.
TSAP = IP address + Port number → identifies exactly where the data should go



--- Slide 27 ---
1. A time of day server process on host 2 attaches itself to TSAP 1522 to wait for an incoming call. A call such as our LISTEN might be used, 
2. An application process on host 1 wants to find out the time-of-day, so it issues a CONNECT request specifying TSAP 1208 as the source and TSAP 1522 as the destination. This action ultimately results in a transport connection being established between the application process on host 1 and server 1 on host 2.
3. The application process then sends over a request for the time.
4. The time server process responds with the current time.
5. The transport connection is then released.

--- Slide 28 ---
4.Flow Control and Buffering
After establishing a connection, the next important task is managing the data flow between the sender and receiver. This involves flow control and buffering — ensuring that data is sent at a rate that the receiver can handle without being overwhelmed.

--- Slide 29 ---
Flow Control Concept
Flow control prevents a fast sender from overrunning a slow receiver.
Both the data link layer and transport layer use mechanisms like sliding window protocols for this purpose.
However, there’s a major difference:
In the data link layer, routers have few lines to manage.
In the transport layer, a host may have many simultaneous connections, making it impractical to assign fixed buffers for each connection.


--- Slide 30 ---
Buffering in the Transport Layer
(a) Data Link Layer Buffering
In data link protocols both sender and receiver routers keep a fixed number of buffers per line.
(b) Transport Layer Buffering
The sender must buffer all outgoing Transport Protocol Data Units (TPDUs) until they are acknowledged, in case they need retransmission.
The receiver may use:
Dedicated buffers for each connection, or
A shared buffer pool for all connections.
If no buffer is available when a TPDU arrives, it may be discarded. The sender will simply retransmit it later, since it already keeps a copy.


--- Slide 31 ---

Sender vs Receiver Buffering
For low-bandwidth, bursty traffic (like interactive terminal sessions):→ Better to buffer at the sender.→ Buffers are allocated dynamically as needed.
For high-bandwidth, steady traffic (like file transfers):→ Better to buffer at the receiver.→ The receiver dedicates a full window of buffers to keep data flowing smoothly.

With an unreliable network service, the sender must buffer all sent TPDUs until acknowledged.
With a reliable network service, buffering strategy can vary:
If the sender knows the receiver always has space, it can avoid keeping copies.
But if the receiver may run out of buffers, the sender must still buffer, since a network-level acknowledgment only means arrival, not acceptance by the receiver.


--- Slide 32 ---

Buffer Size Management
The question of how large buffers should be depends on TPDU sizes and traffic types.
Types of Buffering Approaches:
Fixed-size buffers:
One TPDU per buffer (good for uniform sizes).
Wastes space when TPDUs are small.
Needs multiple buffers for large TPDUs.
Variable-size buffers:
Better memory efficiency.
More complex buffer management.
Circular buffer per connection:
Uses memory efficiently for busy connections.
Wasteful if some connections are idle.


--- Slide 33 ---
5.Multiplexing
Multiplexing means sharing one connection or link among multiple conversations.It helps different processes or applications use the same network interface efficiently.
Upward Multiplexing:When a host has only one network address, multiple transport connections must use that same address.Incoming packets are then separated and delivered to the correct process.
Downward Multiplexing:Sometimes a single network connection cannot provide enough bandwidth.To increase capacity, multiple network connections are opened and used together.
In downward multiplexing, data is split across multiple connections (e.g., round-robin sending).This increases the effective bandwidth.
Example:An ISDN line offers two 64 kbps channels.Using both channels simultaneously gives the user 128 kbps total bandwidth through downward multiplexing.

--- Slide 34 ---
6.Crash Recovery
•When data transfers take a long time (like downloading big files), sometimes a host (computer) or a router (network device) might crash. The system must then figure out how to recover the connection without starting everything from the beginning.
Router or network crashes are easier to handle:
If routers or parts of the network fail, packets may get lost.
The transport layer (like TCP) in the hosts already knows how to handle lost packets by retransmitting them, so this recovery is manageable.
Host crashes are harder to handle:
If a host (like a client or server) crashes, the connection state (like sequence numbers, buffers, etc.) is lost.
When the host comes back (reboots), it no longer remembers the old connection.
This causes problems for long-lived connections, because the other side (the peer) may still think the connection is active.
Desirable behavior:
Ideally, after a server crash and quick reboot, clients should be able to resume their session without having to start over completely.
This requires special mechanisms for connection recovery and state synchronization after a crash.



--- Slide 35 ---
The Internet Transport Protocols 

The Internet has two main protocols in the transport layer, a connectionless protocol and a connection- oriented one. The protocols complement each other. 
The connectionless protocol is UDP. It does almost nothing beyond sending packets between applications, letting applications build their own protocols on top as needed. 
The connection-oriented protocol is TCP. It does almost everything. It makes connections and adds reliability with retransmissions, along with flow control and congestion control, all on behalf of the applications that use it. 

--- Slide 36 ---
 UDP 
The Internet protocol suite supports a connectionless transport protocol called UDP(User Datagram Protocol). 
UDP provides a way for applications to send encapsulated IPdatagrams without having to establish a connection.
UDP transmits segments consisting of an 8-byte header followed by the payload. 
The two ports serve to identify the end-points within the source and destination machines. 
When a UDP packet arrives, its payload is handed to the process attached to the destination port. With them, it delivers the embedded segment to the correct application.


--- Slide 37 ---

Source port, destination port: Identifies the end points within the source and destination machines. 
UDP length: Includes 8-byte header and the data 
UDP checksum: Includes the UDP header, the UDP data padded out to an even number of bytes if need be. It is an optional field

--- Slide 38 ---
REMOTE PROCEDURE CALL 
In a certain sense, sending a message to a remote host and getting a reply back is like making a function call in a programming language. This is to arrange request-reply interactions on networks to be cast in the form of procedure calls.
RPC is used to call remote programs using the procedural call. 
When a process on machine 1 calls a procedure on machine 2, the calling process on 1 is suspended and execution of the called procedure takes place on 2.
Information can be transported from the caller to the callee in the parameters and can come back in the procedure result. No message passing is visible to the application programmer. This technique is known as RPC (Remote Procedure Call) and has become the basis for many networking applications.

--- Slide 39 ---

Traditionally, the calling procedure is known as the client and the called procedure is known as the server.
In the simplest form, to call a remote procedure, the client program must be bound with a small library procedure, called the client stub, that represents the server procedure in the client’s address space. 
Similarly, the server is bound with a procedure called the server stub. These procedures hide the fact that the procedure call from the client to the server is not local.


--- Slide 40 ---
Step 1 is the client calling the client stub. This call is a local procedure call, with the parameters pushed onto the stack in the normal way. 
Step 2 is the client stub packing the parameters into a message and making a system call to send the message. Packing the parameters is called marshaling. 
Step 3 is the operating system sending the message from the client machine to the server machine.
Step 4 is the operating system passing the incoming packet to the server stub. 
Step 5 is the server stub calling the server procedure with the unmarshaled parameters. The reply traces the same path in the other direction. 

--- Slide 41 ---


--- Slide 42 ---
UDP Applications 
UDP does not provide error control; it provides an unreliable service. 
UDP is suitable for a process that requires simple request-response communication with little concern for flow and error control
UDP is suitable for a process with internal flow- and error-control mechanisms. 
UDP is a suitable transport protocol for multicasting. Multicasting capability is embedded in the UDP software
UDP is used for management processes such as SNMP.(simple network management protocol)
UDP is used for some route updating protocols such as Routing Information Protocol(RIP)
UDP is normally used for interactive real-time applications that cannot tolerate uneven delay between sections of a received message


--- Slide 43 ---
TCP 
It was specifically designed to provide a reliable end-to end byte stream over an unreliable network. 
It was designed to adapt dynamically to properties of the inter network and to be robust in the face of many kinds of failures. 
Each machine supporting TCP has a TCP transport entity, which accepts user data streams from local processes, breaks them up into pieces not exceeding 64kbytes and sends each piece as a separate IP datagram. 
When these datagrams arrive at a machine, they are given to TCP entity, which reconstructs the original byte streams. 
It is up to TCP to time out and retransmits them as needed, also to reassemble datagrams into messages in proper sequence. 

--- Slide 44 ---

Characteristics
connection oriented: 3-way handshaking
full duplex: bidirectional, Full duplex means that traffic can go in both directions at the same time.
point-point: Point-to-point means that each connection has exactly two endpoints. 
A TCP connection is a byte stream, not a message stream.
piggyback: data+ack, go back and selective repeat
error control: Checksums (detect errors)
flow control: TCP uses Sliding Window Protocol
congestion control: Slow Start, Congestion Avoidance
Selective acknowledgements 
repurposing of header fields for quality of service 
improved retransmission timers 
explicit congestion notification.


--- Slide 45 ---
The TCP Service Model 
TCP service is obtained by having both the sender and receiver create end points called SOCKETS
Each socket has a socket number(address)consisting of the IP address of the host, called a “PORT” ( = TSAP )
To obtain TCP service a connection must be explicitly established between a socket on the sending machine and a socket on the receiving machine
All TCP connections are full duplex and point to point i.e., multicasting or broadcasting is not supported.
A TCP connection is a byte stream, not a message stream i.e., the data is delivered as chunks


--- Slide 46 ---


--- Slide 48 ---
The TCP Protocol 
1. TCP assigns a unique 32-bit sequence number to every byte
TCP is designed so that each byte of data sent in a connection has its own sequence number.This helps in ordering, reliability, and detecting lost or duplicate data.
2. TCP data is transmitted in variable-size segments
Data is sent as segments, each containing:
A 20-byte header (minimum)
Optional fields
A block of data
TCP decides how much data to put into each segment (merge or split depending on size).
3. Segment size is limited by IP payload and MTU(Maximum Transmission Unit)
Two limits determine how big a TCP segment can be:
IP payload limit → 65,515 bytes
MTU  is the maximum data size a network link can carry in one frame -usually 1500 bytes on Ethernet, So in practice, the MTU (1500 bytes) is the main limit.
If TCP tries to send a segment larger than the MTU:
The IP layer must fragment it into many smaller pieces
This is inefficient and increases the chance of packet loss



--- Slide 49 ---

4. TCP uses the sliding window protocol for reliable delivery
TCP sends segments and starts a timer.If an acknowledgement (ACK) arrives before timeout → good.If timeout happens → TCP retransmits the segment.
5. TCP handles out-of-order, delayed, and retransmitted segments
Data may arrive:
Out of order
Late
Repeated (due to retransmission)
TCP must track which bytes are received correctly and reorder them based on sequence numbers.
6. TCP includes many optimized algorithms to improve performance
Over time, TCP has been enhanced with techniques for:
Faster recovery
Efficient retransmission
Better congestion handling
These help TCP remain reliable even on problematic networks.


--- Slide 50 ---
The TCP Segment Header 
Every segment begins with a fixed-format, 20-byte header. 
The fixed header may be followed by header options. 
After the options, if any, up to 65,535 - 20 - 20 = 65,495 data bytes may follow, where the first 20 refer to the IP header and the second to the TCP header. 
Segments without any data are legal and are commonly used for acknowledgements and control messages.

--- Slide 51 ---


--- Slide 52 ---

Source Port, Destination Port : Identify local end points of the connections 
Sequence number: Specifies the sequence number of the segment 
Acknowledgement Number: Specifies the next byte expected. 
TCP header length: Tells how many 32-bit words are contained in TCP header 
URG: It is set to 1 if URGENT pointer is in use, which indicates start of urgent data. 
ACK: It is set to 1 to indicate that the acknowledgement number is valid. 
PSH: Indicates pushed data 
RST: It is used to reset a connection that has become confused due to reject an invalid segment 
FIN: Used to release a connection. 
SYN: Used to establish connections. 
Window size: field tells how many bytes may be sent starting at the byte acknowledged.
Checksum: is also provided for extra reliability.
Options: field provides a way to add extra facilities

--- Slide 53 ---
TCP Connection Establishment 
To establish a connection, one side, the server, passively waits for an incoming connection by executing the LISTEN and ACCEPT primitives, either specifying a specific source or nobody in particular. 
The other side, say, the client, executes a CONNECT primitive, specifying the IP address and port to which it wants to connect
The CONNECT primitive sends a TCP segment with the SYN bit on and ACK bit off and waits for a response.

The connection establishment in TCP is called three-way handshaking which is explained before in Elements of Transport Layer. An application program, called the client, wants to make a connection with another application program, called the server, using TCP as the transport-layer protocol. The process starts with the server. The server program tells its TCP that it is ready to accept a connection. This request is called a passive open. Although the server TCP is ready to accept a connection from any machine in the world, it cannot make the connection itself. The client program issues a request for an active open. A client that wishes to connect to an open server tells its TCP to connect to a particular server. TCP can now start the three-way handshaking process.

--- Slide 54 ---
a) TCP Connection establishment in the normal case b) Call Collision 

--- Slide 55 ---
TCP Connection Release 
Although TCP connections are full duplex, to understand how connections are released it is best to think of them as a pair of simplex connections.
Each simplex connection is released independently of its sibling. To release a connection, either party can send a TCP segment with the FIN bit set, which means that it has no more data to transmit.
When the FIN is acknowledged, that direction is shut down for new data. Data may continue to flow indefinitely in the other direction, however.
When both directions have been shut down, the connection is released.
Normally, four TCP segments are needed to release a connection, one FIN and one ACK for each direction. However, it is possible for the first ACK and the second FIN to be contained in the same segment, reducing the total count to three.


--- Slide 56 ---
Sliding Window Protocol
This protocol allows sharing multiple data frames from the sender before receiving any acknowledgment from the receiver side.
The data frames shared in the channel are defined by the window size mentioned in the network model, which defines the maximum number of frames that can be transmitted at a time from the sender to the receiver side before expecting any acknowledgment.
Each of the frames in the network model is assigned a sequence number to increase the transmission efficiency.
The data frames shared from the sender to the receiver side are enclosed within a virtual sliding window, which represents that these are awaiting acknowledgment from the receiver side. Requirements are:
Sender and the receiver side
Window Size
The total data frames to be transmitted
Proper sequencing of the frames


--- Slide 57 ---


--- Slide 58 ---
Steps for the Sender Side
To begin with, the sender side will share data frames with the receiver side per the window size assigned to the model.
The sliding window will appear on the frames transmitted over to the receiver side.
Then the sender will wait for an acknowledgment from the receiver side for the shared frames, as mentioned in figure1.



--- Slide 59 ---
Steps for the Receiver Side
On receiving the data frames from the sender side, the receiver will use the frames in the network model.
After the receiver uses the frame, it will transmit the acknowledgement to the sender side for that data frame.
Then, the receiver side will receive the next data frame from the sender side, as mentioned in figure2.


--- Slide 60 ---
Advantages and Disadvantages of Sliding Window Protocol
Advantages
Higher efficiency: The sender can transmit multiple frames before waiting for an acknowledgment, which increases channel utilization.
Reduced waiting time: Since multiple frames are sent consecutively, the overall time delay is lower compared to stop-and-wait systems.
Supports full-duplex communication: Both sender and receiver can simultaneously send and receive frames, improving throughput.
Frame management: Requires frame sorting and sequencing at the receiver, which improves reliability and orderly processing.

Disadvantages
Inefficiency during lost acknowledgments: If the sender does not receive an acknowledgment, it may retransmit many frames, reducing performance.
Bandwidth wastage: Loss of any frame results in retransmission of multiple frames, leading to bandwidth wastage.
Higher complexity: Maintaining sequence numbers, buffers, and sorting mechanisms increases system complexity compared to simple protocols.

--- Slide 61 ---
Transmission policy(Window Management)
Receiver has a 4096-byte buffer, so TCP uses a sliding window to avoid overflow.
Sender first sends 2048 bytes; receiver ACKs and advertises remaining 2048 bytes.
Sender sends the next 2048 bytes; buffer becomes full and receiver advertises a window of 0.
When window = 0, the sender must stop sending more data.
Receiver frees space when the application reads data, so later it can advertise a larger window again.
To avoid deadlock when window = 0, sender can send urgent data or a 1-byte probe to make receiver announce updated window.
TCP allows both sender and receiver to delay sending data/ACKs to create larger, more efficient segments.



--- Slide 62 ---
When the receiver’s buffer becomes full, it advertises a window size of 0, so the sender must stop sending data.
The receiver’s application reads only 1 byte, so the receiver now has just 1 byte of free space and advertises a 1-byte window.
The sender sends a packet carrying only 1 byte of data with full TCP/IP headers, which is highly inefficient.
After receiving that 1 byte, the receiver’s buffer becomes full again, and the same cycle repeats, which is exactly what the figure shows.

Interactive applications may send many tiny packets, causing bandwidth wastage.
TCP may delay ACKs for about 500 ms to combine ACK/window updates with outgoing data.
Nagle’s algorithm sends one byte immediately and buffers the rest until the previous data is acknowledged to avoid tiny packets.
Silly Window Syndrome is prevented by making the receiver advertise a larger window (MSS or half buffer) instead of 1 byte, improving efficiency.




--- Slide 63 ---
TCP CONGESTION CONTROL
Congestion occurs in a network when the amount of data sent is more than what the network can handle, causing packets to be delayed or lost.
TCP deals with congestion mainly by slowing down the data transmission rate, because reducing speed is the only way to avoid overwhelming the routers.
TCP follows the idea similar to “conservation of packets,” meaning the sender should inject a new packet into the network only after an old packet has successfully left, helping avoid overload.
Timeouts are used as a signal of congestion. Since modern links rarely lose packets due to noise, TCP assumes most timeouts indicate congestion in the network.
Each TCP sender maintains two limits: one from the receiver (receiver window) and one based on network conditions (congestion window). The actual amount sent is the minimum of these two windows

--- Slide 64 ---

•A connection begins with the congestion window set to one MSS (maximum segment size). If ACKs arrive successfully, the congestion window grows exponentially by adding one MSS for each ACK—this is the slow start phase.
The sender keeps doubling its congestion window as long as packets are acknowledged, until either a timeout happens or it reaches the receiver’s allowed window.
When a timeout occurs, TCP assumes the network is congested, cuts the congestion window to one MSS, and reduces a threshold value to half of the previous congestion window.
After a timeout, TCP again increases the congestion window using slow start until it reaches the threshold; beyond the threshold, it increases the window linearly, one MSS per round, allowing smooth growth without overloading the network again.


--- Slide 65 ---

In fig (a): We see a thick pipe leading to a small- capacity receiver. As long as the sender does not send more water than the bucket can contain, no water will be lost. 
In fig (b): The limiting factor is not the bucket capacity, but the internal carrying capacity of the n/w. if too much water comes in too fast, it will backup and some will be lost. 


================================================================================
FILE: module 5.pdf
================================================================================

--- Page 1 ---
 
1 
 Module 5 The Application Layer  
 
The Domain Name System DNS  
 
computers on a network can theoretically access resources such as web pages and email 
accounts using numerical network addresses (like IP addresses), this approach is not ideal for 
human users. IP  addresses are difficult to remember and are not convenient for everyday use. 
For example, accessing a company's website using an address like: 128.111.24.41 would be 
inconvenient and impractical. Additionally, if the company moves its website to another s erver 
with a different IP address, every user would need to be informed of the new address.  
 
To solve this issue, high -level, human -friendly names (called domain names ) were introduced. 
These names allow users to refer to resources using familiar text lab els rather than long numeric 
sequences.  
Example:  
www.cs.washington.edu  
This name remains the same even if the underlying server’s IP address changes. Since the 
network itself can only understand numerical addresses, a mechanism is required to translate 
readable names into machine -level IP addresses. This process is known as name resolution  
and is handled by the Domain Name System (DNS) . 
 
What is mean by Domain Name Space  
 DNS (Domain Name System)  is a hierarchical and distributed naming system used on the 
Internet to translate human -readable domain names (such as www.google.com ) into 
machine -readable IP addresses (like 142.250.190.78 ). 
 
 Managing a large and continuously changing collection of host names across the Internet 
is a complex task. To solve this, DN S (Domain Name System) uses a hierarchical naming 
structure , similar to how postal addressing works.  
 
 For the Internet, the top of the naming hierarchy is managed by an organization called 
ICANN  (Internet Corporation for Assigned Names and Numbers).  
 
It organizes the global namespace into a hierarchy of domains. At the highest level, there are 
top-level domains (TLDs) . There are more than 250 TLDs , such as:  
 .com  
 .edu 
 .gov 
 .org 
 Country codes (e.g., .in, .uk, .jp)  
Each top -level domain is divided into subdoma ins, and subdomains may be further divided, 
forming a tree -like structure.  

--- Page 2 ---
 
2 
  
 
 Top-level domains are divided into two main categories:  
1. Generic Top -Level Domains (gTLDs)  
These include original Internet domains created in the 1980s (such as .com, .edu, .go v, .org, 
.net).  
 
Additional generic domains have since been introduced through applications submitted to 
ICANN.  
More gTLDs may continue to be added in the future  
2. Country Code Top -Level Domains (ccTLDs)  
Each country receives a unique two -letter code, bas ed on ISO 3166.  
 Examples:  
.in (India) .uk (United Kingdom) .jp (Japan)  
In 2010, internationalized domain names (IDNs) were introduced, allowing domains to be 
written in non -Latin scripts such as: Arabic , Cyrillic, Chinese and Other native languages . 
 DNS as signs names to domains based on their position in a hierarchical naming tree. Each 
domain name identifies its location in the hierarchy by listing its components from the leaf 
up to the root, separated by periods ( .), which are read as "dot". Example eng.c isco.com.  
DNS Resource Records  
 In DNS, every domain —whether it represents a single host or an entire top -level domain —
contains a set of resource records (RRs) . These records collectively form the DNS 
database . 
Purpose of Resource Records  
 Resource records s tore information about a domain. The most common record stores the IP 
address of a host, but DNS supports many other record types as well.  
 When a resolver  queries DNS with a domain name (example: www.example.com ), DNS 
returns the resource records  associate d with that name.  The format is as follows:  Domain 
name, Time to live, Class, Type, Value.  
 The Domain name tells the domain  to which this record applies. Normally, many records 
exist for each domain and each copy of the database holds information about mul tiple 
domains. This field is thus the primary search key used to satisfy queries. The order of the 
records in the database is not significant.  
 The Time to live  field gives an indication of how stable the record is. Information that is 
highly stable is assi gned a large value, such as 86400 (the number of seconds in 1 day). 


--- Page 3 ---
 
3 
 Information that is highly volatile is assigned a small value, such as 60 (1 minute).  
 The third field of every resource record is the Class . For Internet information, it is always 
IN. For non-Internet information, other codes can be used, but in practice these are rarely 
seen.  
 The Type field  tells what kind of record this is. There are many kinds of DNS records.  
 
Name Servers  
 
 DNS namespace is logically divided into multiple nonoverlapping zones . Each zone is 
responsible for storing and maintaining the resource records for its portion of the DNS 
hierarchy.  
 The placement of zone boundaries  in the DNS hierarchy is determined by the 
administrator of the zone . The decision usually depends on:  
 How many name servers are needed?  
 Where those servers will be located  
 How administrative responsibilities are divided  
 In the example shown: washington.edu is one zone. It includes eng.washington.edu. 
However, cs.washington.edu is a separate zone with its own  name servers. This separation 
may occur because: Some departments (e.g., English) may not want to manage their own 
DNS server. Others (e.g., Computer Science) may have the expertise and need to manage 
their own zone.  
 
 
 
 
 The act of mapping a domain name to an IP address is called name resolution . 
How It Works:  
1. A resolver  (usually part of the OS or application) receives a query.  
2. It forwards the query to a local DNS name server . 
3. If the name falls within the zone managed by that server (e.g., top.cs.vu.nl  belongs to 
cs.vu.nl ), the server returns the answer.  


--- Page 4 ---
 
4 
  An authoritative record  is one that comes from the authority that manages the record and 
is thus always correct. Authoritative records are in contrast to cached records , which may 
be out of date.  
 
 When a u ser wants to find the IP address of a domain such as robot.cs.washington.edu , 
the DNS performs a step -by-step lookup across multiple name servers. If the local server 
has no cached information available, it follows a remote resolution process , as shown in 
Figure 7 -6. 
 
 
 
 
 Step -by-Step Resolution (Based on the Figure)  
 
1. The user's computer (resolver) sends a query to the local name server (cs.vu.nl).  
2. The local name server sends a query to a root name server.  
3. The root name server responds with the name and IP of the .edu top -level domain (TLD) 
name server.  
4. The local server sends the query to the edu name server.  
5. The edu name server replies with the name server for washington.edu.  
6. The local name server sends the request to the University of Washington (UW) name 
server.  
7. UW responds with the name server for the cs.washington.edu department.  
8. The local name server queries the UW Computer Science (UWCS) name server.  
9. UWCS returns the final IP address of robot.cs.washington.edu.  
10. The local server forwards the answer to t he originating host.  
 
 The name has now been resolved.  
 Caching in DNS:  Caching is used to speed up responses and reduce network load.  All DNS 
responses, including partial answers, are stored temporarily Future queries for the same 
domain or related domains may be resolved much faster.  
 Example benefits:  
 A second lookup for robot.cs.washington.edu is immediate.  
 A lookup for galah.cs.washington.edu goes directly to the authoritative UWCS 
server.  
 
Electronic Mail  
 
 Electronic mail (commonly called e -mail)  is a me thod of creating, sending, receiving, 


--- Page 5 ---
 
5 
 and storing digital messages using computer networks, especially the Internet. It allows 
users to exchange information quickly and efficiently without needing physical mail.  
 It is a digital communication system  that re places traditional postal mail.  
 Messages may include text, images, files, hyperlinks, and multimedia attachments . 
 Email uses a client -server model , where messages are stored on email servers and accessed 
by users through email applications (e.g., Gmail, Ou tlook).  
 How It Works (Simple Flow):  - Sender → Email Server → Internet → Recipient's Email 
Server → Recipient  
 
Architecture and Services  
 
 Electronic mail systems are organized into different components that work together to send, 
receive, and manage messages over a network. The general arch itecture of an email system 
is illustrated in Figure 7 -7 and consists of two main subsystems:  
1. User Agents (UA)  
2. Message Transfer Agents (MTA)  
1. User Agents (UA)  
A user agent  is the software that users interact with directly to manage their email. Examples 
include Gmail, Outlook, Thunderbird , and mobile mail apps.  
Functions of a User Agent:  
 Compose new messages  
 Read received messages  
 Reply to, forward, delete, and organize mail  
 Search mail folders and archives  
 Provide either a graphical interface (GUI) or a text-based/command -line interface  
The process of sending a message from the user agent into the mail system for delivery is 
known as mail submission . 
2. Message Transfer Agents (MTA)  
 
A Message Transfer Agent , also called a mail server , is responsible for transferring email 
messages across the network from the sender to the recipient.  
Examples include servers using SMTP (Simple Mail Transfer Protocol) . 
 
The MTA forwards messages through one or more intermediate servers until they reach the 
destination mail server, where the recipient can retrieve them using a user agent.  

--- Page 6 ---
 
6 
  
SMTP (Simple Mail Transfer Protocol)  
 SMTP handles message transfer between mail servers.  
 Defined initially in RFC 821  and updated to RFC 5321 . 
 Provides delivery status and error reporting  
Mailboxes and Message Access  
 Email is stored in mailboxes  located on mail servers.  
 User agents access mailbox content by sending commands to the server.  
 Retrieval of stored mail is considered the final step in message delivery . 
Multiple user agents (phone,  laptop, webmail) can access the same mailbox , allowing flexible 
usage.  
Email Message Format  
Email messages follow a standard structure.  
 Originally defined by RFC 822  
 Updated to RFC 5322  
 Extended using MIME  (Multipurpose Internet Mail Extensions) for:  
o Imag es 
o Audio/video  
o Non-English text  
o Attachments  
A key idea in the message format is the distinction between the envelope and its contents. The 
envelope encapsulates the message. It contains all the information needed for transporting the 
message, such as the d estination address, priority, and security level, all of which are distinct 
from the message itself. The message transport agents use the envelope for routing, just as the 
post office does.  
 
The message inside the envelope consists of two separate parts: t he header and the body. The 
header contains control information for the user agents. The body is entirely for the human 
recipient.  
 


--- Page 7 ---
 
7 
  
 
The User Agent  
 
 A user agent is a program (sometimes called an email reader) that accepts a variety 
of commands for compo sing, receiving, and replying to messages, as well as for 
manipulating mailboxes.  
 There are many popular user agents, including Google Gmail, Microsoft Outlook, Mozilla 
Thunderbird, and Apple Mail.  
 Most user agents have a menu - or icon driven graphical int erface that requires a mouse, or 
a touch interface on smaller mobile devices.  
 The typical elements of a user agent interface are shown in Fig. 7 -9. Your mail reader is 
likely to be much flashier, but probably has equivalent functions.  
 When a user agent is started, it will usually present a summary of the messages in the user’s 
mailbox. Often, the summary will have one line for each message in some sorted order. It 
highlights key fields of the message that are extracted from the message envelope or header.  
 The lines use the from, Subject, and Received fields, in that order, to display who sent the 
message, what it is about, and when it was received. All the information is formatted in a 
user-friendly way rather than displaying the literal contents of the mess age fields, but it is 
based on the message fields. Thus, people who fail to include a Subject field often discover 
that responses to their emails tend not to get the highest priority.  
 


--- Page 8 ---
 
8 
  
 
 User agents must also be able to display incoming messages as needed  so that people 
can read their email. After a message has been read, the user can decide what to do with 
it. This is called message disposition . Options include deleting the message, sending a 
reply, forwarding the message to another user, and keeping the message for later 
reference. Most user agents can manage one mailbox for incoming mail with multiple 
folders for saved mail.  
 
Message Format  
 
RFC5322 —The Internet Message Format  
 
 RFC 5322 is a standard that defines the format of internet messages, such as email 
messages. It specifies the structure and content of email messages, including the 
headers, body, and attachments.  
 The standard is maintained by the Internet Engineering Task Force (IETF) and is an 
important reference for anyone working with email or  other internet messages. It is also 
known as the Internet Message Format Standard.  
 The principal header fields related to message transport are listed in Fig. 7 -10. 
 
 
 
 
 


--- Page 9 ---
 
9 
  The To: field gives the DNS address of the primary recipient. Having multiple 
recipi ents is also allowed. The Cc: field gives the addresses of any secondary recipients. 
In terms of delivery, there is no distinction between the primary and secondary 
recipients. It is entirely a psychological difference that may be important to the people 
involved but is not important to the mail system. The term Cc: (Car bon copy) is a bit 
dated, since computers do not use carbon paper, but it is well established. The Bcc: 
(Blind carbon copy) field is like the Cc: field, except that this line is deleted fro m all 
the copies sent to the primary and secondary recipients. This feature allows people to 
send copies to third parties without the primary and secondary recipients knowing this.  
 The next two fields, From: and Sender: tell who wrote and sent the message,  
respectively. These need not be the same. For example, a business executive may write 
a message, but her assistant may be the one who actually transmits it. In this case, the 
executive would be listed in the From: field and the assistant in the Sender: fi eld. The 
From: field is required, but the Sender: field may be omit ted if it is the same as the 
From: field. These fi elds are needed in case the mes sage is undeliverable and must be 
returned to the sender.  
 
 A line containing Received: is added by each mes sage transfer agent along the way. 
The line contains the agent’s identity, the date and time the message was received, and 
other information that can be used for debugging the routing system. The Return -Path: 
field is added by the final message transfer ag ent and was intended to tell how to get 
back to the sender. In theory, this information can be gathered from all the Received: 
headers (except for the name of the sender’s mail box), but it is rarely filled in as such 
and typically just contains the sender ’s ad dress.  
 
MIME—The Multipurpose Internet Mail Extensions  
 
 Email has a simple structure, but it is limited to sending messages in 7 -bit ASCII format, 
which restricts its use for non -English languages and prevents sending binary files, 
video, or audio da ta. 
 Multipurpose Internet Mail Extensions (MIME) is a supplementary protocol that allows 
non-ASCII data to be sent through e -mail. MIME transforms non -ASCII data at the 
sender site to NVT ASCII data and delivers it to the client MTA to be sent through the 
Internet. The message at the receiving site is transformed back to the original data. 
MIME is a set of software functions that transforms non -ASCII data to ASCII data and 
vice versa.  
 
 MIME Headers: - MIME defines five headers, which can be added to the or iginal e -
mail header section to define the transformation parameters:  


--- Page 10 ---
 
10 
  
 MIME -Version  -This header defines the version of MIME used. The current version 
is 1.1. Content -Type -This header defines the type of data used in the body of the 
message. The content type and the content subtype are separated by a slash. Depending 
on the subtype, the header may contain other parameters. MIME allows seven different 
types of data, listed in Table  
 
Content -Transfer -Encoding This header defines the method used to encode t he 
messages into 0s and 1s for transport. The five types of encoding methods are listed in 
Table  
 
 
 Content -ID - This header uniquely identifies the whole message in a multiple message 
environment.  
  Content -Description  -This header defines whether the body  is image, audio, or video  
 
Message Transfer  
 
 The simplest way to move messages is to establish a transport connection from the 
source machine to the destination machine and then just transfer the message. This is 
how SMTP originally worked.  


--- Page 11 ---
 
11 
  
SMTP  (Simple Mail Transfer Protocol)  
 
 Message Transfer Agent: SMTP an e -mail is an application that needs three uses of 
client -server paradigms to accomplish its task. It is important that we distinguish these 
three when we are dealing with e -mail. Figure shows these three client -server 
applications.  
 We refer to the first and the second as Message Transfer Agents (MTAs), the third as 
Message Access Agent (MAA).  
 The formal protocol that defines the MTA client and server in the Internet is called 
Simple Mail Transfer P rotocol (SMTP)  
 
 Commands and Responses: - SMTP uses commands and responses to transfer 
messages between an MTA client and an MTA server. The command is from an MTA 
client to an MTA server; the response is from an MTA server to the MTA client. Each 
command  or reply is terminated by a two character (carriage return and line feed) end -
of-line token.  
 Mail Transfer Phases : - The process of transferring a mail message occurs in three 
phases: connection establishment, mail transfer, and connection termination.  
 Connection Establishment : -After a client has made a TCP connection to the well -
known port 25, the SMTP server starts the connection phase. This phase involves the 
following three steps:  
1. The server sends code 220 (service ready) to tell the client that it is ready to 
receive mail. If the server is not ready, it sends code 421 (service not available).  
2. The client sends the HELO message to identify itself, using its domain name 
address. This step is necessary to inform the server of the domain name of t he 
client.  
 3. The server responds with code 250 (request command completed) or some 
other code depending on the situation.  
 Message Transfer : - After connection has been established between the SMTP client and 
server, a single message between a sender and one or more recipients can be exchanged. 
This phase involves eight steps. Steps 3 and 4 are repeated if there is more than one 
recipient.  
1. The client sends the MAIL FROM message to introduce the sender of the message. 
It includes the mail address of the  sender (mailbox and the domain name). This step is 
needed to give the server the return mail address for returning errors and reporting 
messages.  
2. The server responds with code 250 or some other appropriate code.  
3. The client sends the RCPT TO (recip ient) message, which includes the mail address 
of the recipient.  
 4. The server responds with code 250 or some other appropriate code.  
5. The client sends the DATA message to initialize the message transfer.  


--- Page 12 ---
 
12 
 6. The server responds with code 354 (start ma il input) or some other appropriate 
message.  
7. The client sends the contents of the message in consecutive lines. Each line is 
terminated by a two -character end -of-line token (carriage return and line feed). The 
message is terminated by a line containing just one period.  
 8. The server responds with code 250 (OK) or some other appropriate code.  
 
 Connection Termination : - After the message is transferred successfully, the client 
terminates the connection. This phase involves two steps.  
1. The client sends the QUIT command.  
 2. The server responds with code 221 or some other appropriate code.  
 
 
 
 
IMAP—The Internet Message Access Protocol  
 
 IMAP4 Another mail access protocol is Internet Mail Access Protocol, version 4 (IMAP4). 
IMAP4 is similar to POP3, but it has more features; IMAP4 is more powerful and more 
complex.  
 POP3 is deficient in several ways. It does not allow the user to organize her mail on the 
server; the user cannot have different folders on the server. In addition, POP3 does not 
allow the user t o partially check the contents of the mail before downloading. IMAP4 
provides the following extra functions:  
 • A user can check the e -mail header prior to downloading.  
 • A user can search the contents of the e -mail for a specific string of characters pri or to 
downloading.  
 • A user can partially download e -mail. This is especially useful if bandwidth is limited 
and the e -mail contains multimedia with high bandwidth requirements.  
• A user can create, delete, or rename mailboxes on the mail server.  
• A use r can create a hierarchy of mailboxes in a folder for e -mail storage.  
 
Web -Based Mail   
 
 E-mail is such a common application that some websites today provide this service to 
anyone who accesses the site. Three common sites are Hotmail, Yahoo, and Google mai l. 
The idea is very simple. Figure shows two cases:  
 


--- Page 13 ---
 
13 
  Case I: - In this scenario, Alice uses a traditional mail server to send an email to Bob, who 
has an account on a web -based server. The email is transferred from Alice's browser to her 
mail server via S MTP, and from the sending mail server to the receiving mail server through 
SMTP as well. However, when the message reaches Bob's web server, it is transferred to 
Bob’s browser via HTTP, not POP3 or IMAP4. Bob requests his emails through HTTP by 
logging int o the website (e.g., Hotmail). Once logged in, the web server sends a list of 
emails in HTML format, and Bob can browse and retrieve his emails using more HTTP 
transactions.  
 
 
 Case II: - In this case, both Alice and Bob use web servers, but not necessaril y the same 
one. Alice sends her email to her web server using HTTP, with Bob's mailbox address as 
the URL. The Alice server then forwards the message to Bob's server using SMTP. Bob 
receives the email through HTTP transactions, but the transfer between ser vers still occurs 
via SMTP.  
 
The World Wide Web  
 
 The idea of the Web was first proposed by Tim Berners -Lee in 1989 at CERN†, the 
European Organization for Nuclear Research, to allow several researchers at different 
locations throughout Europe to access eac h other’s’ researches.  
 The commercial Web started in the early 1990s.  
 Today, the Web is a global information space, where documents (called web pages) are 
spread across the world and connected through links.  
  The Web’s growth and popularity are tied to t wo key ideas: "distributed" and "linked."  
1. Distributed: Any web server worldwide can add new pages, which helps expand the 
Web without overwhelming a few servers.  
2. Linked: Web pages can reference other pages on different servers, creating a 
network of inte rconnected information.  
 This linking is done through hypertext, a concept from before the Internet. It allows a 
document to automatically access another linked document. The Web made this possible 
electronically by letting users click a link to retrieve a  connected document.  
  The term hypertext evolved to hypermedia, meaning web pages can include not only text 
but also images, audio, and video.  
  The Web’s purpose has grown beyond sharing documents; it now supports online 
shopping, gaming, and on -demand ac cess to radio and TV programs.  
 
Architecture  


--- Page 14 ---
 
14 
  The WWW today is a distributed client -server service, in which a client using a browser 
can access a service using a server. However, the service provided is distributed over many 
locations called sites. Each s ite holds one or more web pages. A web page can be simple or 
composite. A simple web page has no links to other web pages; a composite web page has 
one or more links to other web pages. Each web page is a file with a name and address.  
 Web Client (Browser):  - A variety of vendors offer commercial browsers that interpret 
and display a web page, and all of them use nearly the same architecture. Each browser 
usually consists of three parts: a controller, client protocols, and interpreters.  
 
 The controller rece ives input from the keyboard or the mouse and uses the client programs 
to access the document.  
 After the document has been accessed, the controller uses one of the interpreters to display 
the document on the screen  
 The client protocol can be one of the pr otocols described later, such as HTTP or FTP.  
 The interpreter can be HTML, Java, or JavaScript, depending on the type of document.  
 Some commercial browsers include Internet Explorer, Netscape Navigator, and Firefox.  
 The web page is stored at the server. Ea ch time a request arrives, the corresponding 
document is sent to the client.  
 To improve efficiency, servers normally store requested files in a cache in memory; 
memory is faster to access than a disk.  
 A server can also become more efficient through multi threading or multiprocessing. In this 
case, a server can answer more than one request at a time.  Some popular web servers 
include Apache and Microsoft Internet Information Server . 
Uniform Resource Locator (URL)  
  A web page, as a file, needs to have a uniq ue identifier to distinguish it from other web 
pages. To define a web page, four main parts are needed:  
1. Protocol: This is like choosing the "vehicle" or method to reach the web page. 
Commonly, this is HTTP (Hypertext Transfer Protocol), which lets the brow ser 
access and display web pages. However, other methods, like FTP (File Transfer 
Protocol), can also be used for different types of access.  
2. Host: The host tells us where the web page is stored. It can be written as an IP 
address (e.g., 64.23.56.17) or as a domain name, like "example.com," which makes 
it easier to identify servers.  
3. Port: The port number is a specific “entry point” on the server. For example, port 
80 is usually used for HTTP, while HTTPS uses port 443. Most of the time, the port 
is standard  and doesn’t need to be written, but if a different port is used, it can be 
specified in the address.  
4. Path: The path gives the exact location of the web page file within the server. It 
shows the series of folders and th e file name, like “/folder1/folder2/filename.” This 
tells the server exactly where to look to find and deliver the web page.  
 
 
 


--- Page 15 ---
 
15 
 Web Documents   
 The documents in the WWW can be grouped into three bro ad categories: static, dynamic  
 
Static Documents  
 Static documents are fixed -content documents that are created and stored in a server. When 
a client accesses the document, a copy of the document is sent. The user can then use a 
browser to see the document. Static documents are prepared using one of severa l languages: 
Hypertext  Mark -up Language (HTML), Extensible Mark -up Language (XML), Extensible 
Style Language (XSL), and Extensible Hypertext Mark -up Language (XHTML).  
 
Dynamic Documents   
 A dynamic document is created by a web server whenever a browser requests the document. 
When a request arrives, the web server runs an application program or a script that creates 
the dynamic document. The server returns the result of the program or script as a response 
to the browser that requested the document. Because a fresh  document is created for each 
request, the contents of a dynamic document may vary from one request to another. A very 
simple example of a dynamic document is the retrieval of the time and date from a server.  
 
HTML—The Hypertext  MarkupLanguage  
 
 lows user s to produce Web pages that include text, graphics, video, pointers to other Web 
pages, and more. HTML is a mark -up language, or language for describing how documents 
are to be formatted. The term ‘‘ mark -up’’ comes from the old days when copyeditors 
actually  marked up documents to tell the printer — in those days, a human being —which 
fonts to use, and so on. Markup languages thus contain explicit commands for formatting. 
For example, in HTML, means start boldface mode, and means leave boldface mode. 
LaTeX and TeX are other examples of markup languages that are well known to most 
academic authors.  
 HTML provides various mechanisms for making lists, including nested lists Unordered 
lists, like the ones in Fig. 7 -23 are started with <ul>, with <li> used to mark the start of 
items. There is also an <ol> tag to starts an ordered list.  

--- Page 16 ---
 
16 
  
AJAX—Asynchronous JavaScript and XML  
 Compelling Web applications need responsive user interfaces and seamless access to 
data stored on remote Web servers. Scripting on the client (e.g., with JavaScript) and 
the server (e.g., with PHP)  are basic technologies that provide pieces of the solution. 
These technologies are commonly used with several other key technologies in a 


--- Page 17 ---
 
17 
 combination called AJAX (Asynchronous JavaScript  and Xml). Many full -featured 
Web applications, such as Google’s Gmai l, Maps, and Docs, are written with AJAX.  
 
 AJAX is somewhat confusing because it is not a language. It is a set of tech nologies 
that work together to enable Web applications that are every bit as responsive and 
powerful as traditional desktop application s. The technologies are:  
 
 1. HTMLandCSS to present  information as pages.  
 
 2. DOM ( Document Object Model) to change parts of pages while they are 
viewed.  
 
3. XML (eXtensible Markup Language) to let programs exchange ap plication 
data with the server.  
 
 4. An asynchronous  way for programs to send and retrieve XML data.  
 
5. JavaScript as a language to bind all this functionality together.  
 DOM (Document Object Model) is a representation of an HTML page that is accessible 
to programs. This representation is structured as a tree that reflects the structure of the 
HTML elements.  
 This element is the parent of the body element, which is in turn parent to a form element. 
The form has two attributes that are drawn to the right -hand side, one for the form 
method (a POST) and one for the form action (the URL to request). This element has 
three children, reflecting the two para graph tags and one input tag that are contained 
within the form. At the bottom of the tree are leaves that contain either elements or 
literals, such as text strings.  
 
 Hypertext  Transfer Protocol (HTTP)  
 
 The Hyper Text Transfer Protocol (HTTP), the Web ’s appli cation -layer protocol, is at 
the heart of the Web.  
 
   HTTP is implemented in two programs: a client program and a server program. The 
client program and server program, executing on different end systems, talk to each 
other by exchanging HTTP messages. HTTP  defines the structure of these messages 
and how the client and server exchange the messages.  


--- Page 18 ---
 
18 
  
 A Web page consists of objects. An object is simply a file like HTML file, a JPEG 
image, a Java applet, or a video clip —that is addressable by a single URL.  
 
  Most Web pages consist of a base HTML file and several referenced objects.  
 
  The base HTML file references the other objects in the page with the objects ’ URLs.  
 
 HTTP defines how Web clients request Web pages from Web servers and how servers 
transfer Web p ages to clients.  
 
 When a user requests a Web page (for example, clicks on a hyperlink), the browser 
sends HTTP request messages for the objects in the page to the server. The server 
receives the requests and responds with HTTP response messages that conta in the 
objects.  
 
 HTTP uses TCP as its underlying transport protocol. The HTTP client first initiates a 
TCP connection with the server. Once the connection is established, the browser and 
the server processes access TCP through their socket interfaces Non -Persistent and 
Persistent Connections If Separate TCP connection is used for each request and 
response, then the connection is said to be non -persistent. If same TCP connection is 
used for series of related request and response, then the connection is said  to be 
persistent.  
 
Nonpersistent Connections  
 
 In a nonpersistent connection, one TCP connection is made for each request/response. 
The following lists the steps in this strategy:  
1. The client opens a TCP connection and sends a request.  
2. The server send s the response and closes the connection.  
3. The client reads the data until it encounters an end -of-file marker; it then 
closes the connection.  
 In this strategy, if a file contains links to N different pictures in different files (all 
located on the same server), the connection must be opened and closed N + 1 times. 
The nonpersistent strategy imposes high overhead on the server because the server 
needs N + 1 different buffers each time a connection is opened.  
 Round -trip time (RTT) is the time it takes f or a small packet to travel from client to 
server and then back to the client.  
 The RTT includes packet -propagation delays, packet queuing delays in intermediate 
routers and switches, and packet -processing delays.  
  When a user clicks on a hyperlink, the browser initiates a TCP connection between the 
browser and the Web server; this involves a “three -way handshake” —the client sends 
a small TCP segment to the server, the server acknowledges and responds with a small 
TCP segment, and, finally, the client ack nowledges back to the server.  

--- Page 19 ---
 
19 
  
 
  The first two parts of the three -way handshake take one RTT.  
 After completing the first two parts of the handshake, the client sends the HTTP request 
message combined with the third part of the three -way handshake (the 
acknowledgment) into the TCP connection.  
 Once the request message arrives at the server, the server sends the HTML file into the 
TCP connection. This HTTP request/response eats up another RTT. Thus, roughly, the 
total response time is two RTTs plus the tr ansmission time at the server of the HTML 
file. 
Persistent Connections   
 HTTP version 1.1 specifies a persistent connection by default. Non -persistent 
connections have some shortcomings.  
1. A brand -new connection must be established and maintained for each  
requested object. This can place a significant burden on the Web server, which 
may be serving requests from hundreds of different clients simultaneously.  
2. Each object suffers a delivery delay of two RTTs — one RTT to establish the 
TCP connection and one RTT to request and receive an object.  
 With persistent connections, the server leaves the TCP connection open after sending a 
response. Subsequent requests and responses between the same client and server can be 
sent over the same connection. In particular,  an entire Web page can be sent over a 
single persistent TCP connection. Moreover, multiple Web pages residing on the same 
server can be sent from the server to the same client over a single persistent TCP 
connection.  
 Only one connection establishment a nd connection termination is used, but the request 
for the image is sent separately  
 
 


--- Page 20 ---
 
20 
  
 
 Request Message Method: There are five HTTP methods:  
 ⮚ GET: The GET method is used wh en the browser requests an object, with the 
requested object identified in the URL field.  
 ⮚ POST: With a POST message, the user is still requesting a Web page from the server, 
but the specific contents of the Web page depend on what the user entered into t he form 
fields. If the value of the method field is POST, then the entity body contains what the 
user entered into the form fields.  
 ⮚ PUT: The PUT method is also used by applications that need to upload objects to 
Web servers.  
 ⮚ HEAD: Used to retrieve head er information. It is used for debugging purpose.  
 ⮚ DELETE: The DELETE method allows a user, or an application, to delete an object 
on a Web server. URL: Specifies URL of the requested object Version: This field 
represents HTTP version, usually HTTP/1.1 . 
 
Web Caching   
A Web cache —also called a proxy server —is a network entity that satisfies HTTP requests 
on the behalf of an origin Web server.  
 ⮚ The Web cache has its own disk storage and keeps copies of recently requested objects 
in this storage.  
 ⮚ A user ’s browser can be configured so that all of the user’s HTTP requests are first  
directed to the Web cache.  
Ex Suppose a browser is requesting the object http://www.someschool.edu/campus.gif.  
Here is what happens:  
 1. The browser establishes a TCP connection to the Web cache and sends an HTTP request 
for the object to the Web cache.  
2. The Web cache checks to see if it has a copy of the object stored locally. If it does, the 
Web cache returns the object within an HTTP response message to the clien t browser  
3. If the Web cache does not have the object, the Web cache opens a TCP connection to the 
origin server, that is, to www.someschool.edu. The Web cache then sends an HTTP request 
for the object into the cache -to-server TCP connection.  
4. After rec eiving this request, the origin server sends the object within an HTTP response 
to the Web cache.  


--- Page 21 ---
 
21 
  5. When the Web cache receives the object, it stores a copy in its local storage and sends 
a copy, within an HTTP response message, to the client browser (ove r the existing TCP 
connection between the client browser and the Web cache).  
 
Web Search  
 
 In 1998, Sergey Brin and Larry Page, then graduate students at Stanford, formed a 
start up  called Google to build a bet ter Web search engine. They were armed with 
the then -radic al idea that a search algorithm that counted how many times each page 
was pointed to by other pages was a better measure of its importance than how many 
times it contained the key words being sought. For instance, many pages’  link to 
the main Cisco page, wh ich makes this page more important to a user searching for 
‘‘Cisco’’ than a page out side of the company that happens to use the word ‘‘Cisco’’ 
many times . 
 In one sense, search is simply another Web application, albeit one of the most 
mature Web applications because it has been under development since the early 
days of the Web. However, Web search has proved indispensable  in everyday 
usage. Over one billion Web searches are estimated to be done each day. People 
looking for all manner of  information use search as a starting point. For example, 
to find out where to buy Vegemite in Seattle, there is no obvious Web site to use as 
a starting point. But chances are that a search engine knows of a page with the 
desired information and can quick ly direct you to the answer.  
 To perform a Web search in the traditional ma nner, the user directs her brow ser to 
the URL of a Web search site. The major search sites include Google, Yahoo!, and 
Bing. Next, the user submits search terms using a form. This  act causes the search 
engine to perform a query on its database for relevant pages or images, or whatever 
kind of resource is being searched for, and return the result as a dynamic page. The 
user can then follow links to the pages that have been found.  
 Web search is an interesting topic for discussion because it has implications for the 
design and use of networks. First, there is the question of how Web search finds 
pages. The Web search engine must have a database of pages to run a query. Each 
HTML page  may contain links to ot her pages, and everything inter esting (or at least 
searchable) is linked somewhere.  This means that it is theoreti cally possible to start 
with a handful of pages and find all other pages on the Web by doing a traversal of 
all page s and links. This process is called Web crawling. All Web search engines 
use Web crawlers.  
 
